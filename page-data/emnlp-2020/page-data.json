{"componentChunkName":"component---node-modules-lekoarts-gatsby-theme-minimal-blog-core-src-templates-post-query-tsx","path":"/emnlp-2020","result":{"data":{"post":{"__typename":"MdxPost","slug":"/emnlp-2020","title":"EMNLP 2020","date":"21.12.2020","tags":[],"description":null,"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"EMNLP 2020\",\n  \"date\": \"2020-12-21T00:00:00.000Z\",\n  \"tags\": [],\n  \"author\": \"janaab11\"\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"We recently attended the all remote \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://2020.emnlp.org/\"\n  }), \"EMNLP\\n2020\"), \". Each of us made notes on what they did\\noverall. But instead of posting those or going with a\\nwhat-we-think-about-the-conference style post, we thought to just ask the team\\nwhat interested them the most in a few sentences. Here are the individual\\nresponses:\"), mdx(\"p\", null, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://ltbringer.github.io/blog\"\n  }), \"Amresh\"), \" says\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"I have recently been following the branch of model explainability for practical\\npurposes. I was delighted to know EMNLP was experiencing a surge of similar\\nresearch. I encountered Minumum Description Length (MDL) as a measure to\\nunderstand a model's ability to capture linguistic properties. The core idea\\nbeing changing the probing task of identifying labels to transmitting data.\")), mdx(\"hr\", null), mdx(\"p\", null, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/karthik19967829\"\n  }), \"Karthik\"), \" says\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"The Dialogue and Interactive systems track in EMNLP was very interesting and\\nintroduced novel techniques and approaches to some of the ML problems that I am\\ncurrently working on for example, MAD-X: a framework for effective transfer\\nlearning to new languages using adapter base architecture , TOD-BERT:\\nPre-training Transformer LMs on open-source dialogue data-sets for better\\nfew-short learning capability this could be helpful to mitigate cold-start\\nproblem of SLU module. Also the generative approach based papers for dialogue\\nstate tracking were an interesting approach that might have few-shot learning\\ncapability as compared to discriminative ones.\")), mdx(\"hr\", null), mdx(\"p\", null, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/lohith-anandan\"\n  }), \"Lohith\"), \" says\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"\\u201CProductising\\u201D ML Models has become one of the primary answers for most of the\\ncomplex problem we face in day to day life, and explaining how they work, has\\nbecome a bigger concern. I was happy to see a lot of papers and demos in that\\ndirection, like the LIT tool, which helps both the developer and the user to\\nunderstand the underlying workings of an ML model and how it looks at each input\\nand how they help in the decision making process. I was glad to see a lot of\\npapers working with various NLP techniques for better and efficient Health Care\\nfor people, which we can all say is more important than ever, given what we have\\nseen this year.\")), mdx(\"hr\", null), mdx(\"p\", null, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/janaab11\"\n  }), \"Manas\"), \" says\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"The Insights from Negative Results in NLP, Workshop was a highlight for me. It\\nrevolved around ideas of what an interesting question is and how to connect\\nideas that didn\\u2019t work out. These questions feel central to our research efforts\\nin-team, and the keynotes offered a rewarding and scientific route to exploring\\nopen problems in speech tech.\")), mdx(\"hr\", null), mdx(\"p\", null, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/swarajdalmia\"\n  }), \"Swaraj\"), \" says\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"The papers i liked from this year\\u2019s EMNLP were : \\u201CIncremental Processing in the\\nAge of Non-Incremental Encoders\\u201D by Madureira, B., & Schlangen, D (2020), which\\nwas similar to how humans incrementally process natural language and provided a\\nway to probe the workings of transformer encoders; and \\u201CDigital Voicing of\\nSilent Speech\\u201D by Gaddy, D., & Klein, D. (2020) which was presented very well\\nand i felt they did a good job modelling the EMG features and got good\\nimprovements on silent speech. There were a lot of papers and workshops on\\ninterpretability of models which is essential considering the direction where\\nthe field is heading and the gather sessions did a good job of ensuring one\\ndoesn\\u2019t miss out on the social aspects of attending a conference.\")));\n}\n;\nMDXContent.isMDXComponent = true;","excerpt":"We recently attended the all remote  EMNLP\n2020 . Each of us made notes on what they did\noverall. But instead of posting those or going withâ€¦","timeToRead":2,"banner":null}},"pageContext":{"slug":"/emnlp-2020","formatString":"DD.MM.YYYY"}}}