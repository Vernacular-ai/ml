<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Machine Learning at Vernacular.ai]]></title><description><![CDATA[Notes from the Machine Learning team at Vernacular.ai]]></description><link>https://vernacular-ai.github.io/ml</link><generator>GatsbyJS</generator><lastBuildDate>Thu, 21 Jan 2021 05:00:45 GMT</lastBuildDate><item><title><![CDATA[EMNLP 2020]]></title><link>https://vernacular-ai.github.io/ml/emnlp-2020</link><guid isPermaLink="false">https://vernacular-ai.github.io/ml/emnlp-2020</guid><pubDate>Sun, 20 Dec 2020 18:30:00 GMT</pubDate><content:encoded>&lt;style data-emotion-css=&quot;1xz4htx&quot;&gt;body{--theme-ui-colors-transparent:var(--theme-ui-colors-transparent,transparent);--theme-ui-colors-black:var(--theme-ui-colors-black,#000);--theme-ui-colors-white:var(--theme-ui-colors-white,#fff);--theme-ui-colors-gray-0:var(--theme-ui-colors-gray-0,null);--theme-ui-colors-gray-1:var(--theme-ui-colors-gray-1,#f7fafc);--theme-ui-colors-gray-2:var(--theme-ui-colors-gray-2,#edf2f7);--theme-ui-colors-gray-3:var(--theme-ui-colors-gray-3,#e2e8f0);--theme-ui-colors-gray-4:var(--theme-ui-colors-gray-4,#cbd5e0);--theme-ui-colors-gray-5:var(--theme-ui-colors-gray-5,#a0aec0);--theme-ui-colors-gray-6:var(--theme-ui-colors-gray-6,#718096);--theme-ui-colors-gray-7:var(--theme-ui-colors-gray-7,#4a5568);--theme-ui-colors-gray-8:var(--theme-ui-colors-gray-8,#2d3748);--theme-ui-colors-gray-9:var(--theme-ui-colors-gray-9,#1a202c);--theme-ui-colors-red-0:var(--theme-ui-colors-red-0,null);--theme-ui-colors-red-1:var(--theme-ui-colors-red-1,#fff5f5);--theme-ui-colors-red-2:var(--theme-ui-colors-red-2,#fed7d7);--theme-ui-colors-red-3:var(--theme-ui-colors-red-3,#feb2b2);--theme-ui-colors-red-4:var(--theme-ui-colors-red-4,#fc8181);--theme-ui-colors-red-5:var(--theme-ui-colors-red-5,#f56565);--theme-ui-colors-red-6:var(--theme-ui-colors-red-6,#e53e3e);--theme-ui-colors-red-7:var(--theme-ui-colors-red-7,#c53030);--theme-ui-colors-red-8:var(--theme-ui-colors-red-8,#9b2c2c);--theme-ui-colors-red-9:var(--theme-ui-colors-red-9,#742a2a);--theme-ui-colors-orange-0:var(--theme-ui-colors-orange-0,null);--theme-ui-colors-orange-1:var(--theme-ui-colors-orange-1,#fffaf0);--theme-ui-colors-orange-2:var(--theme-ui-colors-orange-2,#feebc8);--theme-ui-colors-orange-3:var(--theme-ui-colors-orange-3,#fbd38d);--theme-ui-colors-orange-4:var(--theme-ui-colors-orange-4,#f6ad55);--theme-ui-colors-orange-5:var(--theme-ui-colors-orange-5,#ed8936);--theme-ui-colors-orange-6:var(--theme-ui-colors-orange-6,#dd6b20);--theme-ui-colors-orange-7:var(--theme-ui-colors-orange-7,#c05621);--theme-ui-colors-orange-8:var(--theme-ui-colors-orange-8,#9c4221);--theme-ui-colors-orange-9:var(--theme-ui-colors-orange-9,#7b341e);--theme-ui-colors-yellow-0:var(--theme-ui-colors-yellow-0,null);--theme-ui-colors-yellow-1:var(--theme-ui-colors-yellow-1,#fffff0);--theme-ui-colors-yellow-2:var(--theme-ui-colors-yellow-2,#fefcbf);--theme-ui-colors-yellow-3:var(--theme-ui-colors-yellow-3,#faf089);--theme-ui-colors-yellow-4:var(--theme-ui-colors-yellow-4,#f6e05e);--theme-ui-colors-yellow-5:var(--theme-ui-colors-yellow-5,#ecc94b);--theme-ui-colors-yellow-6:var(--theme-ui-colors-yellow-6,#d69e2e);--theme-ui-colors-yellow-7:var(--theme-ui-colors-yellow-7,#b7791f);--theme-ui-colors-yellow-8:var(--theme-ui-colors-yellow-8,#975a16);--theme-ui-colors-yellow-9:var(--theme-ui-colors-yellow-9,#744210);--theme-ui-colors-green-0:var(--theme-ui-colors-green-0,null);--theme-ui-colors-green-1:var(--theme-ui-colors-green-1,#f0fff4);--theme-ui-colors-green-2:var(--theme-ui-colors-green-2,#c6f6d5);--theme-ui-colors-green-3:var(--theme-ui-colors-green-3,#9ae6b4);--theme-ui-colors-green-4:var(--theme-ui-colors-green-4,#68d391);--theme-ui-colors-green-5:var(--theme-ui-colors-green-5,#48bb78);--theme-ui-colors-green-6:var(--theme-ui-colors-green-6,#38a169);--theme-ui-colors-green-7:var(--theme-ui-colors-green-7,#2f855a);--theme-ui-colors-green-8:var(--theme-ui-colors-green-8,#276749);--theme-ui-colors-green-9:var(--theme-ui-colors-green-9,#22543d);--theme-ui-colors-teal-0:var(--theme-ui-colors-teal-0,null);--theme-ui-colors-teal-1:var(--theme-ui-colors-teal-1,#e6fffa);--theme-ui-colors-teal-2:var(--theme-ui-colors-teal-2,#b2f5ea);--theme-ui-colors-teal-3:var(--theme-ui-colors-teal-3,#81e6d9);--theme-ui-colors-teal-4:var(--theme-ui-colors-teal-4,#4fd1c5);--theme-ui-colors-teal-5:var(--theme-ui-colors-teal-5,#38b2ac);--theme-ui-colors-teal-6:var(--theme-ui-colors-teal-6,#319795);--theme-ui-colors-teal-7:var(--theme-ui-colors-teal-7,#2c7a7b);--theme-ui-colors-teal-8:var(--theme-ui-colors-teal-8,#285e61);--theme-ui-colors-teal-9:var(--theme-ui-colors-teal-9,#234e52);--theme-ui-colors-blue-0:var(--theme-ui-colors-blue-0,null);--theme-ui-colors-blue-1:var(--theme-ui-colors-blue-1,#ebf8ff);--theme-ui-colors-blue-2:var(--theme-ui-colors-blue-2,#bee3f8);--theme-ui-colors-blue-3:var(--theme-ui-colors-blue-3,#90cdf4);--theme-ui-colors-blue-4:var(--theme-ui-colors-blue-4,#63b3ed);--theme-ui-colors-blue-5:var(--theme-ui-colors-blue-5,#4299e1);--theme-ui-colors-blue-6:var(--theme-ui-colors-blue-6,#3182ce);--theme-ui-colors-blue-7:var(--theme-ui-colors-blue-7,#2b6cb0);--theme-ui-colors-blue-8:var(--theme-ui-colors-blue-8,#2c5282);--theme-ui-colors-blue-9:var(--theme-ui-colors-blue-9,#2a4365);--theme-ui-colors-indigo-0:var(--theme-ui-colors-indigo-0,null);--theme-ui-colors-indigo-1:var(--theme-ui-colors-indigo-1,#ebf4ff);--theme-ui-colors-indigo-2:var(--theme-ui-colors-indigo-2,#c3dafe);--theme-ui-colors-indigo-3:var(--theme-ui-colors-indigo-3,#a3bffa);--theme-ui-colors-indigo-4:var(--theme-ui-colors-indigo-4,#7f9cf5);--theme-ui-colors-indigo-5:var(--theme-ui-colors-indigo-5,#667eea);--theme-ui-colors-indigo-6:var(--theme-ui-colors-indigo-6,#5a67d8);--theme-ui-colors-indigo-7:var(--theme-ui-colors-indigo-7,#4c51bf);--theme-ui-colors-indigo-8:var(--theme-ui-colors-indigo-8,#434190);--theme-ui-colors-indigo-9:var(--theme-ui-colors-indigo-9,#3c366b);--theme-ui-colors-purple-0:var(--theme-ui-colors-purple-0,null);--theme-ui-colors-purple-1:var(--theme-ui-colors-purple-1,#faf5ff);--theme-ui-colors-purple-2:var(--theme-ui-colors-purple-2,#e9d8fd);--theme-ui-colors-purple-3:var(--theme-ui-colors-purple-3,#d6bcfa);--theme-ui-colors-purple-4:var(--theme-ui-colors-purple-4,#b794f4);--theme-ui-colors-purple-5:var(--theme-ui-colors-purple-5,#9f7aea);--theme-ui-colors-purple-6:var(--theme-ui-colors-purple-6,#805ad5);--theme-ui-colors-purple-7:var(--theme-ui-colors-purple-7,#6b46c1);--theme-ui-colors-purple-8:var(--theme-ui-colors-purple-8,#553c9a);--theme-ui-colors-purple-9:var(--theme-ui-colors-purple-9,#44337a);--theme-ui-colors-pink-0:var(--theme-ui-colors-pink-0,null);--theme-ui-colors-pink-1:var(--theme-ui-colors-pink-1,#fff5f7);--theme-ui-colors-pink-2:var(--theme-ui-colors-pink-2,#fed7e2);--theme-ui-colors-pink-3:var(--theme-ui-colors-pink-3,#fbb6ce);--theme-ui-colors-pink-4:var(--theme-ui-colors-pink-4,#f687b3);--theme-ui-colors-pink-5:var(--theme-ui-colors-pink-5,#ed64a6);--theme-ui-colors-pink-6:var(--theme-ui-colors-pink-6,#d53f8c);--theme-ui-colors-pink-7:var(--theme-ui-colors-pink-7,#b83280);--theme-ui-colors-pink-8:var(--theme-ui-colors-pink-8,#97266d);--theme-ui-colors-pink-9:var(--theme-ui-colors-pink-9,#702459);--theme-ui-colors-grayDark:var(--theme-ui-colors-grayDark,#2d3748);--theme-ui-colors-text:var(--theme-ui-colors-text,#2d3748);--theme-ui-colors-background:var(--theme-ui-colors-background,#fff);--theme-ui-colors-primary:var(--theme-ui-colors-primary,#6b46c1);--theme-ui-colors-primaryHover:var(--theme-ui-colors-primaryHover,#2c5282);--theme-ui-colors-secondary:var(--theme-ui-colors-secondary,#5f6c80);--theme-ui-colors-muted:var(--theme-ui-colors-muted,#e2e8f0);--theme-ui-colors-success:var(--theme-ui-colors-success,#9ae6b4);--theme-ui-colors-info:var(--theme-ui-colors-info,#63b3ed);--theme-ui-colors-warning:var(--theme-ui-colors-warning,#faf089);--theme-ui-colors-danger:var(--theme-ui-colors-danger,#feb2b2);--theme-ui-colors-light:var(--theme-ui-colors-light,#f7fafc);--theme-ui-colors-dark:var(--theme-ui-colors-dark,#2d3748);--theme-ui-colors-textMuted:var(--theme-ui-colors-textMuted,#718096);--theme-ui-colors-toggleIcon:var(--theme-ui-colors-toggleIcon,#2d3748);--theme-ui-colors-heading:var(--theme-ui-colors-heading,#000);--theme-ui-colors-divide:var(--theme-ui-colors-divide,#cbd5e0);color:var(--theme-ui-colors-text,var(--theme-ui-colors-text,#2d3748));background-color:var(--theme-ui-colors-background,var(--theme-ui-colors-background,#fff));}body.theme-ui-dark{--theme-ui-colors-text:var(--theme-ui-colors-modes-dark-text,#cbd5e0);--theme-ui-colors-primary:var(--theme-ui-colors-modes-dark-primary,#9f7aea);--theme-ui-colors-secondary:var(--theme-ui-colors-modes-dark-secondary,#7f8ea3);--theme-ui-colors-toggleIcon:var(--theme-ui-colors-modes-dark-toggleIcon,#cbd5e0);--theme-ui-colors-background:var(--theme-ui-colors-modes-dark-background,#1A202C);--theme-ui-colors-heading:var(--theme-ui-colors-modes-dark-heading,#fff);--theme-ui-colors-divide:var(--theme-ui-colors-modes-dark-divide,#2d3748);--theme-ui-colors-muted:var(--theme-ui-colors-modes-dark-muted,#2d3748);}&lt;/style&gt;&lt;style data-emotion-css=&quot;1bkk5q4&quot;&gt;.css-1bkk5q4{font-size:1rem;-webkit-letter-spacing:-0.003em;-moz-letter-spacing:-0.003em;-ms-letter-spacing:-0.003em;letter-spacing:-0.003em;line-height:1.625;--baseline-multiplier:0.179;--x-height-multiplier:0.35;}@media screen and (min-width:640px){.css-1bkk5q4{font-size:1rem;}}@media screen and (min-width:768px){.css-1bkk5q4{font-size:1.25rem;}}&lt;/style&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;We recently attended the all remote &lt;style data-emotion-css=&quot;1od09yo&quot;&gt;.css-1od09yo{color:var(--theme-ui-colors-primary,#6b46c1);-webkit-text-decoration:none;text-decoration:none;}.css-1od09yo:hover{-webkit-text-decoration:underline;text-decoration:underline;}&lt;/style&gt;&lt;a href=&quot;https://2020.emnlp.org/&quot; class=&quot;css-1od09yo&quot;&gt;EMNLP
2020&lt;/a&gt;. Each of us made notes on what they did
overall. But instead of posting those or going with a
what-we-think-about-the-conference style post, we thought to just ask the team
what interested them the most in a few sentences. Here are the individual
responses:&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://ltbringer.github.io/blog&quot; class=&quot;css-1od09yo&quot;&gt;Amresh&lt;/a&gt; says&lt;/p&gt;&lt;style data-emotion-css=&quot;1gtwvjp&quot;&gt;.css-1gtwvjp{border-left-color:var(--theme-ui-colors-primary,#6b46c1);border-left-style:solid;border-left-width:6px;margin-left:0;margin-right:0;padding-left:2rem;}.css-1gtwvjp p{font-style:italic;}&lt;/style&gt;&lt;blockquote class=&quot;css-1gtwvjp&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;I have recently been following the branch of model explainability for practical
purposes. I was delighted to know EMNLP was experiencing a surge of similar
research. I encountered Minumum Description Length (MDL) as a measure to
understand a model&amp;#x27;s ability to capture linguistic properties. The core idea
being changing the probing task of identifying labels to transmitting data.&lt;/p&gt;&lt;/blockquote&gt;&lt;style data-emotion-css=&quot;1ldi06f&quot;&gt;.css-1ldi06f{background-color:var(--theme-ui-colors-muted,#e2e8f0);border:0;height:1px;margin:1rem;}&lt;/style&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://github.com/karthik19967829&quot; class=&quot;css-1od09yo&quot;&gt;Karthik&lt;/a&gt; says&lt;/p&gt;&lt;blockquote class=&quot;css-1gtwvjp&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;The Dialogue and Interactive systems track in EMNLP was very interesting and
introduced novel techniques and approaches to some of the ML problems that I am
currently working on for example, MAD-X: a framework for effective transfer
learning to new languages using adapter base architecture , TOD-BERT:
Pre-training Transformer LMs on open-source dialogue data-sets for better
few-short learning capability this could be helpful to mitigate cold-start
problem of SLU module. Also the generative approach based papers for dialogue
state tracking were an interesting approach that might have few-shot learning
capability as compared to discriminative ones.&lt;/p&gt;&lt;/blockquote&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://github.com/lohith-anandan&quot; class=&quot;css-1od09yo&quot;&gt;Lohith&lt;/a&gt; says&lt;/p&gt;&lt;blockquote class=&quot;css-1gtwvjp&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;“Productising” ML Models has become one of the primary answers for most of the
complex problem we face in day to day life, and explaining how they work, has
become a bigger concern. I was happy to see a lot of papers and demos in that
direction, like the LIT tool, which helps both the developer and the user to
understand the underlying workings of an ML model and how it looks at each input
and how they help in the decision making process. I was glad to see a lot of
papers working with various NLP techniques for better and efficient Health Care
for people, which we can all say is more important than ever, given what we have
seen this year.&lt;/p&gt;&lt;/blockquote&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://github.com/janaab11&quot; class=&quot;css-1od09yo&quot;&gt;Manas&lt;/a&gt; says&lt;/p&gt;&lt;blockquote class=&quot;css-1gtwvjp&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;The Insights from Negative Results in NLP, Workshop was a highlight for me. It
revolved around ideas of what an interesting question is and how to connect
ideas that didn’t work out. These questions feel central to our research efforts
in-team, and the keynotes offered a rewarding and scientific route to exploring
open problems in speech tech.&lt;/p&gt;&lt;/blockquote&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://github.com/swarajdalmia&quot; class=&quot;css-1od09yo&quot;&gt;Swaraj&lt;/a&gt; says&lt;/p&gt;&lt;blockquote class=&quot;css-1gtwvjp&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;The papers i liked from this year’s EMNLP were : “Incremental Processing in the
Age of Non-Incremental Encoders” by Madureira, B., &amp;amp; Schlangen, D (2020), which
was similar to how humans incrementally process natural language and provided a
way to probe the workings of transformer encoders; and “Digital Voicing of
Silent Speech” by Gaddy, D., &amp;amp; Klein, D. (2020) which was presented very well
and i felt they did a good job modelling the EMG features and got good
improvements on silent speech. There were a lot of papers and workshops on
interpretability of models which is essential considering the direction where
the field is heading and the gather sessions did a good job of ensuring one
doesn’t miss out on the social aspects of attending a conference.&lt;/p&gt;&lt;/blockquote&gt;</content:encoded></item><item><title><![CDATA[Part 1 - Introducing Normalizing Flows]]></title><link>https://vernacular-ai.github.io/ml/part-1-introducing-normalizing-flows</link><guid isPermaLink="false">https://vernacular-ai.github.io/ml/part-1-introducing-normalizing-flows</guid><pubDate>Fri, 18 Dec 2020 18:30:00 GMT</pubDate><content:encoded>&lt;style data-emotion-css=&quot;1xz4htx&quot;&gt;body{--theme-ui-colors-transparent:var(--theme-ui-colors-transparent,transparent);--theme-ui-colors-black:var(--theme-ui-colors-black,#000);--theme-ui-colors-white:var(--theme-ui-colors-white,#fff);--theme-ui-colors-gray-0:var(--theme-ui-colors-gray-0,null);--theme-ui-colors-gray-1:var(--theme-ui-colors-gray-1,#f7fafc);--theme-ui-colors-gray-2:var(--theme-ui-colors-gray-2,#edf2f7);--theme-ui-colors-gray-3:var(--theme-ui-colors-gray-3,#e2e8f0);--theme-ui-colors-gray-4:var(--theme-ui-colors-gray-4,#cbd5e0);--theme-ui-colors-gray-5:var(--theme-ui-colors-gray-5,#a0aec0);--theme-ui-colors-gray-6:var(--theme-ui-colors-gray-6,#718096);--theme-ui-colors-gray-7:var(--theme-ui-colors-gray-7,#4a5568);--theme-ui-colors-gray-8:var(--theme-ui-colors-gray-8,#2d3748);--theme-ui-colors-gray-9:var(--theme-ui-colors-gray-9,#1a202c);--theme-ui-colors-red-0:var(--theme-ui-colors-red-0,null);--theme-ui-colors-red-1:var(--theme-ui-colors-red-1,#fff5f5);--theme-ui-colors-red-2:var(--theme-ui-colors-red-2,#fed7d7);--theme-ui-colors-red-3:var(--theme-ui-colors-red-3,#feb2b2);--theme-ui-colors-red-4:var(--theme-ui-colors-red-4,#fc8181);--theme-ui-colors-red-5:var(--theme-ui-colors-red-5,#f56565);--theme-ui-colors-red-6:var(--theme-ui-colors-red-6,#e53e3e);--theme-ui-colors-red-7:var(--theme-ui-colors-red-7,#c53030);--theme-ui-colors-red-8:var(--theme-ui-colors-red-8,#9b2c2c);--theme-ui-colors-red-9:var(--theme-ui-colors-red-9,#742a2a);--theme-ui-colors-orange-0:var(--theme-ui-colors-orange-0,null);--theme-ui-colors-orange-1:var(--theme-ui-colors-orange-1,#fffaf0);--theme-ui-colors-orange-2:var(--theme-ui-colors-orange-2,#feebc8);--theme-ui-colors-orange-3:var(--theme-ui-colors-orange-3,#fbd38d);--theme-ui-colors-orange-4:var(--theme-ui-colors-orange-4,#f6ad55);--theme-ui-colors-orange-5:var(--theme-ui-colors-orange-5,#ed8936);--theme-ui-colors-orange-6:var(--theme-ui-colors-orange-6,#dd6b20);--theme-ui-colors-orange-7:var(--theme-ui-colors-orange-7,#c05621);--theme-ui-colors-orange-8:var(--theme-ui-colors-orange-8,#9c4221);--theme-ui-colors-orange-9:var(--theme-ui-colors-orange-9,#7b341e);--theme-ui-colors-yellow-0:var(--theme-ui-colors-yellow-0,null);--theme-ui-colors-yellow-1:var(--theme-ui-colors-yellow-1,#fffff0);--theme-ui-colors-yellow-2:var(--theme-ui-colors-yellow-2,#fefcbf);--theme-ui-colors-yellow-3:var(--theme-ui-colors-yellow-3,#faf089);--theme-ui-colors-yellow-4:var(--theme-ui-colors-yellow-4,#f6e05e);--theme-ui-colors-yellow-5:var(--theme-ui-colors-yellow-5,#ecc94b);--theme-ui-colors-yellow-6:var(--theme-ui-colors-yellow-6,#d69e2e);--theme-ui-colors-yellow-7:var(--theme-ui-colors-yellow-7,#b7791f);--theme-ui-colors-yellow-8:var(--theme-ui-colors-yellow-8,#975a16);--theme-ui-colors-yellow-9:var(--theme-ui-colors-yellow-9,#744210);--theme-ui-colors-green-0:var(--theme-ui-colors-green-0,null);--theme-ui-colors-green-1:var(--theme-ui-colors-green-1,#f0fff4);--theme-ui-colors-green-2:var(--theme-ui-colors-green-2,#c6f6d5);--theme-ui-colors-green-3:var(--theme-ui-colors-green-3,#9ae6b4);--theme-ui-colors-green-4:var(--theme-ui-colors-green-4,#68d391);--theme-ui-colors-green-5:var(--theme-ui-colors-green-5,#48bb78);--theme-ui-colors-green-6:var(--theme-ui-colors-green-6,#38a169);--theme-ui-colors-green-7:var(--theme-ui-colors-green-7,#2f855a);--theme-ui-colors-green-8:var(--theme-ui-colors-green-8,#276749);--theme-ui-colors-green-9:var(--theme-ui-colors-green-9,#22543d);--theme-ui-colors-teal-0:var(--theme-ui-colors-teal-0,null);--theme-ui-colors-teal-1:var(--theme-ui-colors-teal-1,#e6fffa);--theme-ui-colors-teal-2:var(--theme-ui-colors-teal-2,#b2f5ea);--theme-ui-colors-teal-3:var(--theme-ui-colors-teal-3,#81e6d9);--theme-ui-colors-teal-4:var(--theme-ui-colors-teal-4,#4fd1c5);--theme-ui-colors-teal-5:var(--theme-ui-colors-teal-5,#38b2ac);--theme-ui-colors-teal-6:var(--theme-ui-colors-teal-6,#319795);--theme-ui-colors-teal-7:var(--theme-ui-colors-teal-7,#2c7a7b);--theme-ui-colors-teal-8:var(--theme-ui-colors-teal-8,#285e61);--theme-ui-colors-teal-9:var(--theme-ui-colors-teal-9,#234e52);--theme-ui-colors-blue-0:var(--theme-ui-colors-blue-0,null);--theme-ui-colors-blue-1:var(--theme-ui-colors-blue-1,#ebf8ff);--theme-ui-colors-blue-2:var(--theme-ui-colors-blue-2,#bee3f8);--theme-ui-colors-blue-3:var(--theme-ui-colors-blue-3,#90cdf4);--theme-ui-colors-blue-4:var(--theme-ui-colors-blue-4,#63b3ed);--theme-ui-colors-blue-5:var(--theme-ui-colors-blue-5,#4299e1);--theme-ui-colors-blue-6:var(--theme-ui-colors-blue-6,#3182ce);--theme-ui-colors-blue-7:var(--theme-ui-colors-blue-7,#2b6cb0);--theme-ui-colors-blue-8:var(--theme-ui-colors-blue-8,#2c5282);--theme-ui-colors-blue-9:var(--theme-ui-colors-blue-9,#2a4365);--theme-ui-colors-indigo-0:var(--theme-ui-colors-indigo-0,null);--theme-ui-colors-indigo-1:var(--theme-ui-colors-indigo-1,#ebf4ff);--theme-ui-colors-indigo-2:var(--theme-ui-colors-indigo-2,#c3dafe);--theme-ui-colors-indigo-3:var(--theme-ui-colors-indigo-3,#a3bffa);--theme-ui-colors-indigo-4:var(--theme-ui-colors-indigo-4,#7f9cf5);--theme-ui-colors-indigo-5:var(--theme-ui-colors-indigo-5,#667eea);--theme-ui-colors-indigo-6:var(--theme-ui-colors-indigo-6,#5a67d8);--theme-ui-colors-indigo-7:var(--theme-ui-colors-indigo-7,#4c51bf);--theme-ui-colors-indigo-8:var(--theme-ui-colors-indigo-8,#434190);--theme-ui-colors-indigo-9:var(--theme-ui-colors-indigo-9,#3c366b);--theme-ui-colors-purple-0:var(--theme-ui-colors-purple-0,null);--theme-ui-colors-purple-1:var(--theme-ui-colors-purple-1,#faf5ff);--theme-ui-colors-purple-2:var(--theme-ui-colors-purple-2,#e9d8fd);--theme-ui-colors-purple-3:var(--theme-ui-colors-purple-3,#d6bcfa);--theme-ui-colors-purple-4:var(--theme-ui-colors-purple-4,#b794f4);--theme-ui-colors-purple-5:var(--theme-ui-colors-purple-5,#9f7aea);--theme-ui-colors-purple-6:var(--theme-ui-colors-purple-6,#805ad5);--theme-ui-colors-purple-7:var(--theme-ui-colors-purple-7,#6b46c1);--theme-ui-colors-purple-8:var(--theme-ui-colors-purple-8,#553c9a);--theme-ui-colors-purple-9:var(--theme-ui-colors-purple-9,#44337a);--theme-ui-colors-pink-0:var(--theme-ui-colors-pink-0,null);--theme-ui-colors-pink-1:var(--theme-ui-colors-pink-1,#fff5f7);--theme-ui-colors-pink-2:var(--theme-ui-colors-pink-2,#fed7e2);--theme-ui-colors-pink-3:var(--theme-ui-colors-pink-3,#fbb6ce);--theme-ui-colors-pink-4:var(--theme-ui-colors-pink-4,#f687b3);--theme-ui-colors-pink-5:var(--theme-ui-colors-pink-5,#ed64a6);--theme-ui-colors-pink-6:var(--theme-ui-colors-pink-6,#d53f8c);--theme-ui-colors-pink-7:var(--theme-ui-colors-pink-7,#b83280);--theme-ui-colors-pink-8:var(--theme-ui-colors-pink-8,#97266d);--theme-ui-colors-pink-9:var(--theme-ui-colors-pink-9,#702459);--theme-ui-colors-grayDark:var(--theme-ui-colors-grayDark,#2d3748);--theme-ui-colors-text:var(--theme-ui-colors-text,#2d3748);--theme-ui-colors-background:var(--theme-ui-colors-background,#fff);--theme-ui-colors-primary:var(--theme-ui-colors-primary,#6b46c1);--theme-ui-colors-primaryHover:var(--theme-ui-colors-primaryHover,#2c5282);--theme-ui-colors-secondary:var(--theme-ui-colors-secondary,#5f6c80);--theme-ui-colors-muted:var(--theme-ui-colors-muted,#e2e8f0);--theme-ui-colors-success:var(--theme-ui-colors-success,#9ae6b4);--theme-ui-colors-info:var(--theme-ui-colors-info,#63b3ed);--theme-ui-colors-warning:var(--theme-ui-colors-warning,#faf089);--theme-ui-colors-danger:var(--theme-ui-colors-danger,#feb2b2);--theme-ui-colors-light:var(--theme-ui-colors-light,#f7fafc);--theme-ui-colors-dark:var(--theme-ui-colors-dark,#2d3748);--theme-ui-colors-textMuted:var(--theme-ui-colors-textMuted,#718096);--theme-ui-colors-toggleIcon:var(--theme-ui-colors-toggleIcon,#2d3748);--theme-ui-colors-heading:var(--theme-ui-colors-heading,#000);--theme-ui-colors-divide:var(--theme-ui-colors-divide,#cbd5e0);color:var(--theme-ui-colors-text,var(--theme-ui-colors-text,#2d3748));background-color:var(--theme-ui-colors-background,var(--theme-ui-colors-background,#fff));}body.theme-ui-dark{--theme-ui-colors-text:var(--theme-ui-colors-modes-dark-text,#cbd5e0);--theme-ui-colors-primary:var(--theme-ui-colors-modes-dark-primary,#9f7aea);--theme-ui-colors-secondary:var(--theme-ui-colors-modes-dark-secondary,#7f8ea3);--theme-ui-colors-toggleIcon:var(--theme-ui-colors-modes-dark-toggleIcon,#cbd5e0);--theme-ui-colors-background:var(--theme-ui-colors-modes-dark-background,#1A202C);--theme-ui-colors-heading:var(--theme-ui-colors-modes-dark-heading,#fff);--theme-ui-colors-divide:var(--theme-ui-colors-modes-dark-divide,#2d3748);--theme-ui-colors-muted:var(--theme-ui-colors-modes-dark-muted,#2d3748);}&lt;/style&gt;&lt;style data-emotion-css=&quot;1cr8ha5&quot;&gt;.css-1cr8ha5{font-family:inherit;font-weight:700;line-height:1.25;margin:0;margin-bottom:0.25rem;font-size:2.25rem;margin-top:0.5rem;color:var(--theme-ui-colors-heading,#000);}@media screen and (min-width:640px){.css-1cr8ha5{font-size:3rem;}}@media screen and (min-width:768px){.css-1cr8ha5{font-size:4rem;}}&lt;/style&gt;&lt;h1 class=&quot;css-1cr8ha5&quot;&gt;Introducing Normalizing Flows&lt;/h1&gt;&lt;style data-emotion-css=&quot;1bkk5q4&quot;&gt;.css-1bkk5q4{font-size:1rem;-webkit-letter-spacing:-0.003em;-moz-letter-spacing:-0.003em;-ms-letter-spacing:-0.003em;letter-spacing:-0.003em;line-height:1.625;--baseline-multiplier:0.179;--x-height-multiplier:0.35;}@media screen and (min-width:640px){.css-1bkk5q4{font-size:1rem;}}@media screen and (min-width:768px){.css-1bkk5q4{font-size:1.25rem;}}&lt;/style&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Normalizing flows, popularized by &lt;style data-emotion-css=&quot;1od09yo&quot;&gt;.css-1od09yo{color:var(--theme-ui-colors-primary,#6b46c1);-webkit-text-decoration:none;text-decoration:none;}.css-1od09yo:hover{-webkit-text-decoration:underline;text-decoration:underline;}&lt;/style&gt;&lt;a href=&quot;https://arxiv.org/abs/1505.05770&quot; class=&quot;css-1od09yo&quot;&gt;(Rezende, &amp;amp; Mohamed, 2015)&lt;/a&gt;, are techniques used in machine learning to transform simple probability distribution functions into complicated ones. One of the popular use cases is in generative modelling - an unsupervised learning method - where the goal is to model a probability distribution given samples drawn from that distribution. &lt;/p&gt;&lt;style data-emotion-css=&quot;1bzbprl&quot;&gt;.css-1bzbprl{font-family:inherit;font-weight:700;line-height:1.25;margin:0;margin-bottom:0.25rem;font-size:1.875rem;margin-top:0.5rem;color:var(--theme-ui-colors-heading,#000);}@media screen and (min-width:640px){.css-1bzbprl{font-size:2.25rem;}}@media screen and (min-width:768px){.css-1bzbprl{font-size:3rem;}}&lt;/style&gt;&lt;h2 class=&quot;css-1bzbprl&quot;&gt;Motivation : Why bother about normalizing flows ?&lt;/h2&gt;&lt;style data-emotion-css=&quot;15rlv7r&quot;&gt;.css-15rlv7r li{font-size:1rem;-webkit-letter-spacing:-0.003em;-moz-letter-spacing:-0.003em;-ms-letter-spacing:-0.003em;letter-spacing:-0.003em;line-height:1.625;--baseline-multiplier:0.179;--x-height-multiplier:0.35;}@media screen and (min-width:640px){.css-15rlv7r li{font-size:1rem;}}@media screen and (min-width:768px){.css-15rlv7r li{font-size:1.25rem;}}&lt;/style&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;They have been used in many TTS (text-to-speech) models, memorably in the &lt;a href=&quot;http://proceedings.mlr.press/v80/oord18a/oord18a.pdf&quot; class=&quot;css-1od09yo&quot;&gt;Parallel WaveNet model&lt;/a&gt; (2017) where a clever application of normalizing flows resulted in a 1000 times faster generation of audio samples in comparison to the original &lt;a href=&quot;https://arxiv.org/abs/1609.03499&quot; class=&quot;css-1od09yo&quot;&gt;WaveNet&lt;/a&gt; model. The Parallel WaveNet model was also deployed on Google assistant for real-time generation of audio.&lt;/li&gt;&lt;/ul&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;Normally a back-propagation pass requires the activation value for each neuron to be stored in memory. This places a restriction on training deeper, wider models on single GPU’s(since GPU’s have limited memory) and forces one to use small batch sizes during training. In flow based networks, one does not need to store the activations at all, as they can be &lt;a href=&quot;https://ameroyer.github.io/reading-notes/architectures/2019/05/07/the_reversible_residual_network.html&quot; class=&quot;css-1od09yo&quot;&gt;reconstructed online&lt;/a&gt; during the back-propagation. This property was leveraged in the &lt;a href=&quot;https://arxiv.org/abs/1707.04585&quot; class=&quot;css-1od09yo&quot;&gt;RevNets paper&lt;/a&gt; (2017) which uses invertible residual blocks. Reducing the memory cost of storing activations significantly improve the ability to efficiently train wider and deeper networks.&lt;/li&gt;&lt;/ul&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/2005.05957.pdf&quot; class=&quot;css-1od09yo&quot;&gt;Flowtron&lt;/a&gt; (2020), an autoregressive flow based TTS model does a kind of representation learning using normalizing flows to learn an invertible mapping from a data space to a latent space which can be manipulated to control many aspects of speech synthesis (pitch, tone, speech rate, cadence, accent). Flowtron matches state-of-the-art TTS models in terms of speech quality and is able to transfer speech characteristics from a source speaker to a target speaker, making the target speaker sound more expressive.&lt;/li&gt;&lt;/ul&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;If you’ve ever thought about reversible networks, Normalizing flows do precisely that. Reversibility of flows also means that one can trivially encode images into the latent space for editing. They also have cool mathematical applications, for example their use in &lt;a href=&quot;https://arxiv.org/pdf/1806.07366.pdf&quot; class=&quot;css-1od09yo&quot;&gt;Neural ODE solvers&lt;/a&gt; (2019) which use continuous normalizing flows. &lt;/li&gt;&lt;/ul&gt;&lt;h2 class=&quot;css-1bzbprl&quot;&gt;Brief Introduction&lt;/h2&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;&lt;em class=&quot;css-0&quot;&gt;Definition&lt;/em&gt;&lt;/strong&gt; &lt;em class=&quot;css-0&quot;&gt;:&lt;/em&gt; A Normalizing Flow is a transformation of a simple probability distribution into a more complex distribution by a sequence of invertible and differentiable mappings.&lt;/p&gt;&lt;style data-emotion-css=&quot;1gtwvjp&quot;&gt;.css-1gtwvjp{border-left-color:var(--theme-ui-colors-primary,#6b46c1);border-left-style:solid;border-left-width:6px;margin-left:0;margin-right:0;padding-left:2rem;}.css-1gtwvjp p{font-style:italic;}&lt;/style&gt;&lt;blockquote class=&quot;css-1gtwvjp&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;&lt;em class=&quot;css-0&quot;&gt;Note&lt;/em&gt;&lt;/strong&gt;: The above formalism is a simplification, for a more precise definition one can consult [5]. The formalism allows piecewise continuous functions to be used in the construction of the flow which the above definition restricts. &lt;/p&gt;&lt;/blockquote&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Normalizing&lt;/strong&gt; since the transformed distribution needs to be normalized by the change of variables formula (discussed below). &lt;strong class=&quot;css-0&quot;&gt;Flow&lt;/strong&gt; refers to the series of invertible transformations which are composed with each other to create more complex invertible transformations.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;When applied as density estimators, some NFs provide a general way of constructing &lt;strong class=&quot;css-0&quot;&gt;flexible&lt;/strong&gt; probability distributions over continuous random variables starting from a simple probability distribution. By constraining the transformations to be invertible, Flow-based models provide a tractable method to calculate the exact likelihood for a wide variety of generative modeling problems.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Efficient inference and efficient synthesis:&lt;/strong&gt; Autoregressive models, such as the &lt;a href=&quot;https://arxiv.org/pdf/1606.05328.pdf&quot; class=&quot;css-1od09yo&quot;&gt;PixelCNN&lt;/a&gt;, are also reversible, however synthesis from such models is difficult to parallelize, and typically inefficient on parallel hardware. Flow-based generative models like &lt;a href=&quot;https://arxiv.org/abs/1807.03039&quot; class=&quot;css-1od09yo&quot;&gt;Glow&lt;/a&gt; (and RealNVP) are efficient to parallelize for both training and synthesis.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Exact latent-variable inference:&lt;/strong&gt;
Within the class of exact likelihood models, normalizing flows provide two key advantages: model flexibility and generation speed. Flows have been explored both to increase the flexibility of the variational posterior in the context of variational autoencoders (VAEs), and directly as a generative model.  With VAEs, one is able to infer only approximately the value of the latent variables that correspond to a datapoint. GAN’s have no encoder at all to infer the latents. In flow based generative models, this can be done exactly without approximation. Not only does this lead to accurate inference, it also enables optimization of the exact log-likelihood of the data, instead of a lower bound of it.&lt;/p&gt;&lt;h2 class=&quot;css-1bzbprl&quot;&gt;Mathematical Framework:&lt;/h2&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Let, $z&lt;em class=&quot;css-0&quot;&gt;0$ be a continuous random variable belonging to a simple probability distribution $p&lt;/em&gt;\theta(z_0)$ . Let it be a Gaussian with parameters $(\mu, \sigma) = (0,1)$.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;$$z&lt;em class=&quot;css-0&quot;&gt;0 \sim p&lt;/em&gt;\theta (z_0) = N(z_0;0,1)$$&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Normalizing flows transforms the simple distribution, into a desired output probability distribution with random variable $x$, with a sequence of invertible transformations, $f_i&amp;#x27;s$. &lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;$$z&lt;em class=&quot;css-0&quot;&gt;k = f&lt;/em&gt;\theta (z_0) = f_k...f_2.f_1(z_0)$$       s.t. each $f_i$ is invertible (bijective)&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;The composition of all the individual flows is represented by $f&lt;em class=&quot;css-0&quot;&gt;\theta$. Since each $f_i$ is bijective, so is $f&lt;/em&gt;\theta$. The new density $p&lt;em class=&quot;css-0&quot;&gt;\theta (z_k)$ is called a &lt;em class=&quot;css-0&quot;&gt;push forward&lt;/em&gt; of the initial density $p&lt;/em&gt;\theta(z&lt;em class=&quot;css-0&quot;&gt;0)$ by the function $f&lt;/em&gt;\theta.$&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;An example of a transformation obtained by a normalizing flow is shown below, which transforms a base gaussian distribution into a target multi-modal distribution with the help of a bijective function.  &lt;/p&gt;&lt;figure&gt;
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position:relative;display:block;margin-left:auto;margin-right:auto;max-width:960px&quot;&gt;
      &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom:27.916666666666668%;position:relative;bottom:0;left:0;background-image:url(&amp;#x27;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAGABQDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAG6AD//xAAUEAEAAAAAAAAAAAAAAAAAAAAQ/9oACAEBAAEFAn//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAQ/9oACAEBAAY/An//xAAWEAEBAQAAAAAAAAAAAAAAAAABABH/2gAIAQEAAT8h0W20v//aAAwDAQACAAMAAAAQ88//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAZEAEAAwEBAAAAAAAAAAAAAAABABEhMVH/2gAIAQEAAT8QKgNhhVWvYMcn/9k=&amp;#x27;);background-size:cover;display:block&quot;&gt;&lt;/span&gt;
  &lt;img class=&quot;gatsby-resp-image-image css-0&quot; alt=&quot;Can&amp;#x27;t See? Something went wrong!&quot; title=&quot;Can&amp;#x27;t See? Something went wrong!&quot; src=&quot;/ml/static/c1030f9ef0ee1521fe91c83d52f7e6c7/18e3b/normalizing_flow.jpg&quot; srcSet=&quot;/ml/static/c1030f9ef0ee1521fe91c83d52f7e6c7/46946/normalizing_flow.jpg 240w,/ml/static/c1030f9ef0ee1521fe91c83d52f7e6c7/55489/normalizing_flow.jpg 480w,/ml/static/c1030f9ef0ee1521fe91c83d52f7e6c7/18e3b/normalizing_flow.jpg 960w,/ml/static/c1030f9ef0ee1521fe91c83d52f7e6c7/60e21/normalizing_flow.jpg 1440w,/ml/static/c1030f9ef0ee1521fe91c83d52f7e6c7/b46c2/normalizing_flow.jpg 1600w&quot; sizes=&quot;(max-width: 960px) 100vw, 960px&quot; style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0&quot; loading=&quot;lazy&quot;/&gt;
    &lt;/span&gt;
  &lt;figcaption&gt;&lt;b class=&quot;css-0&quot;&gt;&lt;center&gt;Fig 1 : The transformation of a base distribution into a target distribution using a bijective function f.&lt;/center&gt;&lt;/b&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;The constrains of a distribution being a probability distribution is that $\int p_\theta (z_0) =1$. However, this doesn’t hold after applying a bijective function (for intuition consider $f_1 : z \rightarrow z^3$). &lt;/p&gt;&lt;h2 class=&quot;css-1bzbprl&quot;&gt;Change of Variables Formula&lt;/h2&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Consider the normalizing flow $f_1 : Z_0 \rightarrow Z_1$.  If we want the probability distribution of the random variable $z_1 \sim Z_1$, we need to consider the &lt;em class=&quot;css-0&quot;&gt;change of variables formula&lt;/em&gt; derived below. &lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Consider the event $z_0 \sim Z$, mapped to $z_1 \sim Z_1$ s.t. $f_1(z_0) = z_1$. Since, the mapping is bijective, the probabilities of the events are the same. Therefore, &lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;$$p&lt;em class=&quot;css-0&quot;&gt;\theta(z_1)*\partial z_1 = p&lt;/em&gt;\theta(z&lt;em class=&quot;css-0&quot;&gt;0)*\partial z_0$$
$$p&lt;/em&gt;\theta(z&lt;em class=&quot;css-0&quot;&gt;1) = p&lt;/em&gt;\theta(z&lt;em class=&quot;css-0&quot;&gt;0)* \frac{\partial z_0}{\partial z_1}$$&lt;br/&gt;$$p&lt;/em&gt;\theta(z&lt;em class=&quot;css-0&quot;&gt;1) = p&lt;/em&gt;\theta(z&lt;em class=&quot;css-0&quot;&gt;0)* |\frac{\partial z_0}{\partial z_1}|$$             (since probabilities are always &amp;gt; 0)
$$p&lt;/em&gt;\theta(z&lt;em class=&quot;css-0&quot;&gt;1) = p&lt;/em&gt;\theta(z&lt;em class=&quot;css-0&quot;&gt;0)* |\frac{\partial z_0}{\partial f_1(z_0)}|$$         ($z_1 = f_1(z_0)$)
$$p&lt;/em&gt;\theta(z&lt;em class=&quot;css-0&quot;&gt;1) = p&lt;/em&gt;\theta(z_0)* |\frac{\partial f_1(z_0)}{\partial z_0}|^{-1}$$&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;In the multivariate case ($R^D \rightarrow R^D$) this generalises to : &lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;$$p&lt;em class=&quot;css-0&quot;&gt;\theta(z_1) = p&lt;/em&gt;\theta(z_0)* |\det(\frac{\partial f_1(z_0)}{\partial z_0})|^{-1}$$ &lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Considering the sequence of compositional transformations $f_i&amp;#x27;s$, one obtains :&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;$$p&lt;em class=&quot;css-0&quot;&gt;\theta(z_k) = p&lt;/em&gt;\theta(z&lt;em class=&quot;css-0&quot;&gt;0)* \prod&lt;/em&gt;{i=1..k}|\det(\frac{\partial f&lt;em class=&quot;css-0&quot;&gt;i}{\partial z&lt;/em&gt;{i-1}})|^{-1}$$       &lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;The term on the right i.e. determinant of the Jacobian accounts for the change of $\delta$ volume induced by the transformation. It serves to normalize the transformed distribution locally, after each flow through a transformation, hence the name, Normalizing Flows. &lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Some Questions at this stage :  &lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;The sequence of flows need to be invertible and differentiable. What sort of constraints does it introduce in terms of the output distributions that can be reached ? Are there families of distributions that we can’t reach starting from a Gaussian ?&lt;/li&gt;&lt;/ul&gt;&lt;h2 class=&quot;css-1bzbprl&quot;&gt;Sampling&lt;/h2&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;In this case, the bijective functions and the initial distribution are given. Sampling points from the output distribution requires calculating the forward pass, i.e. an efficient calculation of the functions $f_i&amp;#x27;s$. &lt;/p&gt;&lt;h2 class=&quot;css-1bzbprl&quot;&gt;Density Estimation using Maximum Likelihood&lt;/h2&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;In this case a dataset ${a&lt;em class=&quot;css-0&quot;&gt;1, a_2,....,a_n}$ is provided and the objective is to learn the probability density function $p&lt;/em&gt;\theta(A)$ to which the points belong. An initial density $p_\theta(z_0)$ is chosen. &lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;For each $a_i$ we have : &lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;$$p&lt;em class=&quot;css-0&quot;&gt;\theta(a_i) = p&lt;/em&gt;\theta(z_i)* |\det(\frac{\partial f(z_i)}{\partial z_i})|^{-1}$$            where, $a_i = f(z_i)$&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;$$\prod&lt;em class=&quot;css-0&quot;&gt;{i=1}^n p&lt;/em&gt;\theta(a&lt;em class=&quot;css-0&quot;&gt;i) =\prod&lt;/em&gt;{i=1}^n [p_\theta(z_i)* |\det(\frac{\partial f(z_i)}{\partial z_i})|^{-1}]$$     &lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;We need to maximize the above over all possible flows $f$ to find the flow $\hat{f}$ that maximizes the probability.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;$$\hat{f} =\text{arg max}&lt;em class=&quot;css-0&quot;&gt;f \text{ }\prod&lt;/em&gt;{i=1}^n [p_\theta(z_i)* |\det(\frac{\partial f(z_i)}{\partial z_i})|^{-1}]$$ &lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Using log likelihood maximization we arrive at : &lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;$$\hat{f} =\text{arg max}&lt;em class=&quot;css-0&quot;&gt;f \text{ }\sum&lt;/em&gt;{i=1}^n [log(p_\theta(z_i)) - log(|\det(\frac{\partial f(z_i)}{\partial z_i})|)]$$&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;The equation shown above is used during training for density estimation. However, since we only know $a_i&amp;#x27;s$ the only way to find $z_i&amp;#x27;s$ which are used, is to find the inverse mapping i.e. $z_i = f^{-1}(a_i)$ .  So for density estimation and training, the calculation of both the inverse and determinant of the Jacobian are required. &lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;However, calculating the inverse and the determinant of the Jacobian of a sequence of high dimensional transformations can be very time consuming (for dimensionality d matrix, both are of complexity $O(d^3)$). There are various tricks that are used to reduce the complexity of these two operations, one of the popular ones being the use of triangular maps. &lt;/p&gt;&lt;h2 class=&quot;css-1bzbprl&quot;&gt;Triangular maps:&lt;/h2&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Let T be a normalizing flow, $T: z \rightarrow x$ where $x = (x_1, x_2 .... x_d)$ and $z = (z_1, z_2 .... z_d)$
More generally, one can decompose T into $T_1, T_2...T_d$   s.t.   $x_i = T_i(z_1,z_2.....z_d)$.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Now if we want to introduce an additional constraint on T i.e. for T to be a triangular map, each $T_j$ should be a function of $(z_1,z_2.....z_j)$ i.e. the first j elements and not all the d elements. &lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;For triangular maps/matrices, both the inverse and the determinant of the jacobian is easy to compute. The jacobian for a triangular map is shown below. The determinant is simply the product of the diagonals and has a complexity of $O(d)$ instead of $O(d^3)$. The complexity for the calculation of the inverse is $O(d^2)$ instead of $O(d^3)$.&lt;/p&gt;&lt;figure&gt;
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position:relative;display:block;margin-left:auto;margin-right:auto;max-width:612px&quot;&gt;
      &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom:69.58333333333333%;position:relative;bottom:0;left:0;background-image:url(&amp;#x27;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe5UNIP/xAAXEAEBAQEAAAAAAAAAAAAAAAABABAx/9oACAEBAAEFAliJw5//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAVEAEBAAAAAAAAAAAAAAAAAAAgIf/aAAgBAQAGPwKL/8QAGRAAAgMBAAAAAAAAAAAAAAAAABEBMUFR/9oACAEBAAE/Iam0kyhlCk7H/9oADAMBAAIAAwAAABBfz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABsQAQEAAwEBAQAAAAAAAAAAAAERACFBMWFx/9oACAEBAAE/EBSHhm8id9TzGpVrXc+4F8BuEXZazKnqtn7n/9k=&amp;#x27;);background-size:cover;display:block&quot;&gt;&lt;/span&gt;
  &lt;img class=&quot;gatsby-resp-image-image css-0&quot; alt=&quot;Can&amp;#x27;t See? Something went wrong!&quot; title=&quot;Can&amp;#x27;t See? Something went wrong!&quot; src=&quot;/ml/static/3e41c999019866df331c87315250e82b/c94a8/jacobian.jpg&quot; srcSet=&quot;/ml/static/3e41c999019866df331c87315250e82b/46946/jacobian.jpg 240w,/ml/static/3e41c999019866df331c87315250e82b/55489/jacobian.jpg 480w,/ml/static/3e41c999019866df331c87315250e82b/c94a8/jacobian.jpg 612w&quot; sizes=&quot;(max-width: 612px) 100vw, 612px&quot; style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0&quot; loading=&quot;lazy&quot;/&gt;
    &lt;/span&gt;
  &lt;figcaption&gt;&lt;b class=&quot;css-0&quot;&gt;&lt;center&gt;Fig 2 : The jacobian for a triangular map. This is taken from here.&lt;/center&gt;&lt;/b&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Note : For an increasing triangular map,  $\frac {\partial T_i}{\partial z_i} &amp;gt; 0$. This will be useful in Part - 2 where the different types/families of Normalizing flows will be considered.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;References : &lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1908.09257.pdf&quot; class=&quot;css-1od09yo&quot;&gt;Normalizing Flows: An Introduction and Review of Current Methods&lt;/a&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;a href=&quot;https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html#vae--flows&quot; class=&quot;css-1od09yo&quot;&gt;Flow-based Deep Generative Models&lt;/a&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=3KUvxIOJD0k&amp;amp;ab_channel=PascalPoupart&quot; class=&quot;css-1od09yo&quot;&gt;Lecture on NFs by Priyank Jaini&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[Interspeech 2020]]></title><link>https://vernacular-ai.github.io/ml/interspeech-2020</link><guid isPermaLink="false">https://vernacular-ai.github.io/ml/interspeech-2020</guid><pubDate>Mon, 30 Nov 2020 18:30:00 GMT</pubDate><content:encoded>&lt;style data-emotion-css=&quot;1xz4htx&quot;&gt;body{--theme-ui-colors-transparent:var(--theme-ui-colors-transparent,transparent);--theme-ui-colors-black:var(--theme-ui-colors-black,#000);--theme-ui-colors-white:var(--theme-ui-colors-white,#fff);--theme-ui-colors-gray-0:var(--theme-ui-colors-gray-0,null);--theme-ui-colors-gray-1:var(--theme-ui-colors-gray-1,#f7fafc);--theme-ui-colors-gray-2:var(--theme-ui-colors-gray-2,#edf2f7);--theme-ui-colors-gray-3:var(--theme-ui-colors-gray-3,#e2e8f0);--theme-ui-colors-gray-4:var(--theme-ui-colors-gray-4,#cbd5e0);--theme-ui-colors-gray-5:var(--theme-ui-colors-gray-5,#a0aec0);--theme-ui-colors-gray-6:var(--theme-ui-colors-gray-6,#718096);--theme-ui-colors-gray-7:var(--theme-ui-colors-gray-7,#4a5568);--theme-ui-colors-gray-8:var(--theme-ui-colors-gray-8,#2d3748);--theme-ui-colors-gray-9:var(--theme-ui-colors-gray-9,#1a202c);--theme-ui-colors-red-0:var(--theme-ui-colors-red-0,null);--theme-ui-colors-red-1:var(--theme-ui-colors-red-1,#fff5f5);--theme-ui-colors-red-2:var(--theme-ui-colors-red-2,#fed7d7);--theme-ui-colors-red-3:var(--theme-ui-colors-red-3,#feb2b2);--theme-ui-colors-red-4:var(--theme-ui-colors-red-4,#fc8181);--theme-ui-colors-red-5:var(--theme-ui-colors-red-5,#f56565);--theme-ui-colors-red-6:var(--theme-ui-colors-red-6,#e53e3e);--theme-ui-colors-red-7:var(--theme-ui-colors-red-7,#c53030);--theme-ui-colors-red-8:var(--theme-ui-colors-red-8,#9b2c2c);--theme-ui-colors-red-9:var(--theme-ui-colors-red-9,#742a2a);--theme-ui-colors-orange-0:var(--theme-ui-colors-orange-0,null);--theme-ui-colors-orange-1:var(--theme-ui-colors-orange-1,#fffaf0);--theme-ui-colors-orange-2:var(--theme-ui-colors-orange-2,#feebc8);--theme-ui-colors-orange-3:var(--theme-ui-colors-orange-3,#fbd38d);--theme-ui-colors-orange-4:var(--theme-ui-colors-orange-4,#f6ad55);--theme-ui-colors-orange-5:var(--theme-ui-colors-orange-5,#ed8936);--theme-ui-colors-orange-6:var(--theme-ui-colors-orange-6,#dd6b20);--theme-ui-colors-orange-7:var(--theme-ui-colors-orange-7,#c05621);--theme-ui-colors-orange-8:var(--theme-ui-colors-orange-8,#9c4221);--theme-ui-colors-orange-9:var(--theme-ui-colors-orange-9,#7b341e);--theme-ui-colors-yellow-0:var(--theme-ui-colors-yellow-0,null);--theme-ui-colors-yellow-1:var(--theme-ui-colors-yellow-1,#fffff0);--theme-ui-colors-yellow-2:var(--theme-ui-colors-yellow-2,#fefcbf);--theme-ui-colors-yellow-3:var(--theme-ui-colors-yellow-3,#faf089);--theme-ui-colors-yellow-4:var(--theme-ui-colors-yellow-4,#f6e05e);--theme-ui-colors-yellow-5:var(--theme-ui-colors-yellow-5,#ecc94b);--theme-ui-colors-yellow-6:var(--theme-ui-colors-yellow-6,#d69e2e);--theme-ui-colors-yellow-7:var(--theme-ui-colors-yellow-7,#b7791f);--theme-ui-colors-yellow-8:var(--theme-ui-colors-yellow-8,#975a16);--theme-ui-colors-yellow-9:var(--theme-ui-colors-yellow-9,#744210);--theme-ui-colors-green-0:var(--theme-ui-colors-green-0,null);--theme-ui-colors-green-1:var(--theme-ui-colors-green-1,#f0fff4);--theme-ui-colors-green-2:var(--theme-ui-colors-green-2,#c6f6d5);--theme-ui-colors-green-3:var(--theme-ui-colors-green-3,#9ae6b4);--theme-ui-colors-green-4:var(--theme-ui-colors-green-4,#68d391);--theme-ui-colors-green-5:var(--theme-ui-colors-green-5,#48bb78);--theme-ui-colors-green-6:var(--theme-ui-colors-green-6,#38a169);--theme-ui-colors-green-7:var(--theme-ui-colors-green-7,#2f855a);--theme-ui-colors-green-8:var(--theme-ui-colors-green-8,#276749);--theme-ui-colors-green-9:var(--theme-ui-colors-green-9,#22543d);--theme-ui-colors-teal-0:var(--theme-ui-colors-teal-0,null);--theme-ui-colors-teal-1:var(--theme-ui-colors-teal-1,#e6fffa);--theme-ui-colors-teal-2:var(--theme-ui-colors-teal-2,#b2f5ea);--theme-ui-colors-teal-3:var(--theme-ui-colors-teal-3,#81e6d9);--theme-ui-colors-teal-4:var(--theme-ui-colors-teal-4,#4fd1c5);--theme-ui-colors-teal-5:var(--theme-ui-colors-teal-5,#38b2ac);--theme-ui-colors-teal-6:var(--theme-ui-colors-teal-6,#319795);--theme-ui-colors-teal-7:var(--theme-ui-colors-teal-7,#2c7a7b);--theme-ui-colors-teal-8:var(--theme-ui-colors-teal-8,#285e61);--theme-ui-colors-teal-9:var(--theme-ui-colors-teal-9,#234e52);--theme-ui-colors-blue-0:var(--theme-ui-colors-blue-0,null);--theme-ui-colors-blue-1:var(--theme-ui-colors-blue-1,#ebf8ff);--theme-ui-colors-blue-2:var(--theme-ui-colors-blue-2,#bee3f8);--theme-ui-colors-blue-3:var(--theme-ui-colors-blue-3,#90cdf4);--theme-ui-colors-blue-4:var(--theme-ui-colors-blue-4,#63b3ed);--theme-ui-colors-blue-5:var(--theme-ui-colors-blue-5,#4299e1);--theme-ui-colors-blue-6:var(--theme-ui-colors-blue-6,#3182ce);--theme-ui-colors-blue-7:var(--theme-ui-colors-blue-7,#2b6cb0);--theme-ui-colors-blue-8:var(--theme-ui-colors-blue-8,#2c5282);--theme-ui-colors-blue-9:var(--theme-ui-colors-blue-9,#2a4365);--theme-ui-colors-indigo-0:var(--theme-ui-colors-indigo-0,null);--theme-ui-colors-indigo-1:var(--theme-ui-colors-indigo-1,#ebf4ff);--theme-ui-colors-indigo-2:var(--theme-ui-colors-indigo-2,#c3dafe);--theme-ui-colors-indigo-3:var(--theme-ui-colors-indigo-3,#a3bffa);--theme-ui-colors-indigo-4:var(--theme-ui-colors-indigo-4,#7f9cf5);--theme-ui-colors-indigo-5:var(--theme-ui-colors-indigo-5,#667eea);--theme-ui-colors-indigo-6:var(--theme-ui-colors-indigo-6,#5a67d8);--theme-ui-colors-indigo-7:var(--theme-ui-colors-indigo-7,#4c51bf);--theme-ui-colors-indigo-8:var(--theme-ui-colors-indigo-8,#434190);--theme-ui-colors-indigo-9:var(--theme-ui-colors-indigo-9,#3c366b);--theme-ui-colors-purple-0:var(--theme-ui-colors-purple-0,null);--theme-ui-colors-purple-1:var(--theme-ui-colors-purple-1,#faf5ff);--theme-ui-colors-purple-2:var(--theme-ui-colors-purple-2,#e9d8fd);--theme-ui-colors-purple-3:var(--theme-ui-colors-purple-3,#d6bcfa);--theme-ui-colors-purple-4:var(--theme-ui-colors-purple-4,#b794f4);--theme-ui-colors-purple-5:var(--theme-ui-colors-purple-5,#9f7aea);--theme-ui-colors-purple-6:var(--theme-ui-colors-purple-6,#805ad5);--theme-ui-colors-purple-7:var(--theme-ui-colors-purple-7,#6b46c1);--theme-ui-colors-purple-8:var(--theme-ui-colors-purple-8,#553c9a);--theme-ui-colors-purple-9:var(--theme-ui-colors-purple-9,#44337a);--theme-ui-colors-pink-0:var(--theme-ui-colors-pink-0,null);--theme-ui-colors-pink-1:var(--theme-ui-colors-pink-1,#fff5f7);--theme-ui-colors-pink-2:var(--theme-ui-colors-pink-2,#fed7e2);--theme-ui-colors-pink-3:var(--theme-ui-colors-pink-3,#fbb6ce);--theme-ui-colors-pink-4:var(--theme-ui-colors-pink-4,#f687b3);--theme-ui-colors-pink-5:var(--theme-ui-colors-pink-5,#ed64a6);--theme-ui-colors-pink-6:var(--theme-ui-colors-pink-6,#d53f8c);--theme-ui-colors-pink-7:var(--theme-ui-colors-pink-7,#b83280);--theme-ui-colors-pink-8:var(--theme-ui-colors-pink-8,#97266d);--theme-ui-colors-pink-9:var(--theme-ui-colors-pink-9,#702459);--theme-ui-colors-grayDark:var(--theme-ui-colors-grayDark,#2d3748);--theme-ui-colors-text:var(--theme-ui-colors-text,#2d3748);--theme-ui-colors-background:var(--theme-ui-colors-background,#fff);--theme-ui-colors-primary:var(--theme-ui-colors-primary,#6b46c1);--theme-ui-colors-primaryHover:var(--theme-ui-colors-primaryHover,#2c5282);--theme-ui-colors-secondary:var(--theme-ui-colors-secondary,#5f6c80);--theme-ui-colors-muted:var(--theme-ui-colors-muted,#e2e8f0);--theme-ui-colors-success:var(--theme-ui-colors-success,#9ae6b4);--theme-ui-colors-info:var(--theme-ui-colors-info,#63b3ed);--theme-ui-colors-warning:var(--theme-ui-colors-warning,#faf089);--theme-ui-colors-danger:var(--theme-ui-colors-danger,#feb2b2);--theme-ui-colors-light:var(--theme-ui-colors-light,#f7fafc);--theme-ui-colors-dark:var(--theme-ui-colors-dark,#2d3748);--theme-ui-colors-textMuted:var(--theme-ui-colors-textMuted,#718096);--theme-ui-colors-toggleIcon:var(--theme-ui-colors-toggleIcon,#2d3748);--theme-ui-colors-heading:var(--theme-ui-colors-heading,#000);--theme-ui-colors-divide:var(--theme-ui-colors-divide,#cbd5e0);color:var(--theme-ui-colors-text,var(--theme-ui-colors-text,#2d3748));background-color:var(--theme-ui-colors-background,var(--theme-ui-colors-background,#fff));}body.theme-ui-dark{--theme-ui-colors-text:var(--theme-ui-colors-modes-dark-text,#cbd5e0);--theme-ui-colors-primary:var(--theme-ui-colors-modes-dark-primary,#9f7aea);--theme-ui-colors-secondary:var(--theme-ui-colors-modes-dark-secondary,#7f8ea3);--theme-ui-colors-toggleIcon:var(--theme-ui-colors-modes-dark-toggleIcon,#cbd5e0);--theme-ui-colors-background:var(--theme-ui-colors-modes-dark-background,#1A202C);--theme-ui-colors-heading:var(--theme-ui-colors-modes-dark-heading,#fff);--theme-ui-colors-divide:var(--theme-ui-colors-modes-dark-divide,#2d3748);--theme-ui-colors-muted:var(--theme-ui-colors-modes-dark-muted,#2d3748);}&lt;/style&gt;&lt;style data-emotion-css=&quot;1bkk5q4&quot;&gt;.css-1bkk5q4{font-size:1rem;-webkit-letter-spacing:-0.003em;-moz-letter-spacing:-0.003em;-ms-letter-spacing:-0.003em;letter-spacing:-0.003em;line-height:1.625;--baseline-multiplier:0.179;--x-height-multiplier:0.35;}@media screen and (min-width:640px){.css-1bkk5q4{font-size:1rem;}}@media screen and (min-width:768px){.css-1bkk5q4{font-size:1.25rem;}}&lt;/style&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;We recently attended the all remote &lt;style data-emotion-css=&quot;1od09yo&quot;&gt;.css-1od09yo{color:var(--theme-ui-colors-primary,#6b46c1);-webkit-text-decoration:none;text-decoration:none;}.css-1od09yo:hover{-webkit-text-decoration:underline;text-decoration:underline;}&lt;/style&gt;&lt;a href=&quot;http://www.interspeech2020.org/&quot; class=&quot;css-1od09yo&quot;&gt;Interspeech
2020&lt;/a&gt;. Each of us made notes on what they did
overall. But instead of posting those or going with a
what-we-think-about-the-conference style post, we thought to just ask the team
what interested them the most in a few sentences. Here are the individual
responses:&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://lepisma.xyz/&quot; class=&quot;css-1od09yo&quot;&gt;Abhinav&lt;/a&gt; says&lt;/p&gt;&lt;style data-emotion-css=&quot;1gtwvjp&quot;&gt;.css-1gtwvjp{border-left-color:var(--theme-ui-colors-primary,#6b46c1);border-left-style:solid;border-left-width:6px;margin-left:0;margin-right:0;padding-left:2rem;}.css-1gtwvjp p{font-style:italic;}&lt;/style&gt;&lt;blockquote class=&quot;css-1gtwvjp&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;I really liked the &lt;a href=&quot;https://zerospeech.com/&quot; class=&quot;css-1od09yo&quot;&gt;ZeroSpeech&lt;/a&gt; challenge. As usual,
they had few really interesting unsupervised problems and solutions. I find
their tracks really ambitious as evident by this statement on their website
&amp;quot;... infants learn to speak their native language, spontaneously, from raw
sensory input, without supervision from text or linguists. It should be
possible to do the same in machines&amp;quot;.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Next year, 2021, the &lt;a href=&quot;https://zerospeech.com/2021/news.html&quot; class=&quot;css-1od09yo&quot;&gt;target is Spoken Language
Modeling&lt;/a&gt;. Looking forward to that too.&lt;/p&gt;&lt;/blockquote&gt;&lt;style data-emotion-css=&quot;1ldi06f&quot;&gt;.css-1ldi06f{background-color:var(--theme-ui-colors-muted,#e2e8f0);border:0;height:1px;margin:1rem;}&lt;/style&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://ltbringer.github.io/blog/&quot; class=&quot;css-1od09yo&quot;&gt;Amresh&lt;/a&gt; says&lt;/p&gt;&lt;blockquote class=&quot;css-1gtwvjp&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;The Meta Learning Tutorial on day 1 was a detailed session on the topic. The
promise of performing well on a set of task(s) with less amount of data had my
attention. The authors take care of introduction, utility and comparison of
this approach and its impact on tasks like speaker verification, keyword
spotting, Emotion Recognition and my special interest conversational AI.&lt;/p&gt;&lt;/blockquote&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://github.com/janaab11/&quot; class=&quot;css-1od09yo&quot;&gt;Manas&lt;/a&gt; says&lt;/p&gt;&lt;blockquote class=&quot;css-1gtwvjp&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;A new thing here was Computational Paralinguistics, that covers the
non-content parts of speech. Given my interest in the stylistic parts of
speech, this was particularly interesting. Papers presented many ideas
relevant to building a better voicebot, like - uncertainty aware methods for
multiple labels, Autism Quotient as a perception feature, and predicting CSAT
scores from sentiment.&lt;/p&gt;&lt;/blockquote&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://github.com/pskrunner14&quot; class=&quot;css-1od09yo&quot;&gt;Prabhsimran&lt;/a&gt; says&lt;/p&gt;&lt;blockquote class=&quot;css-1gtwvjp&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Interspeech had some great sessions, from discussions on more fundamental
concepts related to Speech Processing in the Brain, Phonetics and Phonology to
novel ideas on Training Strategies for ASR like Semantic Word Masking,
Efficient Vocoder implementations for faster Neural Waveform Synthesis and
Automatic Prosody Analysis for Non-Semantic Speech Representations. It helped
me connect alot of dots and exposed me to some great ideas we should be
exploring in our work.&lt;/p&gt;&lt;/blockquote&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://www.linkedin.com/in/kaustavtamuly/&quot; class=&quot;css-1od09yo&quot;&gt;Kaustav&lt;/a&gt; says&lt;/p&gt;&lt;blockquote class=&quot;css-1gtwvjp&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;I really liked attending the Speech Emotion Recognition tracks. The tracks
covered a multitude of topics including self-supervised learning methods,
non-semantic representations, etc. It was overall, a very balanced track with
a lot of interaction among the attendees and the presenters. The speech signal
representation track was pretty fun too with some really interesting papers on
voice casting, universal non-semantic representations.&lt;/p&gt;&lt;/blockquote&gt;</content:encoded></item><item><title><![CDATA[Reading Sessions]]></title><link>https://vernacular-ai.github.io/ml/reading-sessions</link><guid isPermaLink="false">https://vernacular-ai.github.io/ml/reading-sessions</guid><pubDate>Sun, 29 Nov 2020 18:30:00 GMT</pubDate><content:encoded>&lt;style data-emotion-css=&quot;1xz4htx&quot;&gt;body{--theme-ui-colors-transparent:var(--theme-ui-colors-transparent,transparent);--theme-ui-colors-black:var(--theme-ui-colors-black,#000);--theme-ui-colors-white:var(--theme-ui-colors-white,#fff);--theme-ui-colors-gray-0:var(--theme-ui-colors-gray-0,null);--theme-ui-colors-gray-1:var(--theme-ui-colors-gray-1,#f7fafc);--theme-ui-colors-gray-2:var(--theme-ui-colors-gray-2,#edf2f7);--theme-ui-colors-gray-3:var(--theme-ui-colors-gray-3,#e2e8f0);--theme-ui-colors-gray-4:var(--theme-ui-colors-gray-4,#cbd5e0);--theme-ui-colors-gray-5:var(--theme-ui-colors-gray-5,#a0aec0);--theme-ui-colors-gray-6:var(--theme-ui-colors-gray-6,#718096);--theme-ui-colors-gray-7:var(--theme-ui-colors-gray-7,#4a5568);--theme-ui-colors-gray-8:var(--theme-ui-colors-gray-8,#2d3748);--theme-ui-colors-gray-9:var(--theme-ui-colors-gray-9,#1a202c);--theme-ui-colors-red-0:var(--theme-ui-colors-red-0,null);--theme-ui-colors-red-1:var(--theme-ui-colors-red-1,#fff5f5);--theme-ui-colors-red-2:var(--theme-ui-colors-red-2,#fed7d7);--theme-ui-colors-red-3:var(--theme-ui-colors-red-3,#feb2b2);--theme-ui-colors-red-4:var(--theme-ui-colors-red-4,#fc8181);--theme-ui-colors-red-5:var(--theme-ui-colors-red-5,#f56565);--theme-ui-colors-red-6:var(--theme-ui-colors-red-6,#e53e3e);--theme-ui-colors-red-7:var(--theme-ui-colors-red-7,#c53030);--theme-ui-colors-red-8:var(--theme-ui-colors-red-8,#9b2c2c);--theme-ui-colors-red-9:var(--theme-ui-colors-red-9,#742a2a);--theme-ui-colors-orange-0:var(--theme-ui-colors-orange-0,null);--theme-ui-colors-orange-1:var(--theme-ui-colors-orange-1,#fffaf0);--theme-ui-colors-orange-2:var(--theme-ui-colors-orange-2,#feebc8);--theme-ui-colors-orange-3:var(--theme-ui-colors-orange-3,#fbd38d);--theme-ui-colors-orange-4:var(--theme-ui-colors-orange-4,#f6ad55);--theme-ui-colors-orange-5:var(--theme-ui-colors-orange-5,#ed8936);--theme-ui-colors-orange-6:var(--theme-ui-colors-orange-6,#dd6b20);--theme-ui-colors-orange-7:var(--theme-ui-colors-orange-7,#c05621);--theme-ui-colors-orange-8:var(--theme-ui-colors-orange-8,#9c4221);--theme-ui-colors-orange-9:var(--theme-ui-colors-orange-9,#7b341e);--theme-ui-colors-yellow-0:var(--theme-ui-colors-yellow-0,null);--theme-ui-colors-yellow-1:var(--theme-ui-colors-yellow-1,#fffff0);--theme-ui-colors-yellow-2:var(--theme-ui-colors-yellow-2,#fefcbf);--theme-ui-colors-yellow-3:var(--theme-ui-colors-yellow-3,#faf089);--theme-ui-colors-yellow-4:var(--theme-ui-colors-yellow-4,#f6e05e);--theme-ui-colors-yellow-5:var(--theme-ui-colors-yellow-5,#ecc94b);--theme-ui-colors-yellow-6:var(--theme-ui-colors-yellow-6,#d69e2e);--theme-ui-colors-yellow-7:var(--theme-ui-colors-yellow-7,#b7791f);--theme-ui-colors-yellow-8:var(--theme-ui-colors-yellow-8,#975a16);--theme-ui-colors-yellow-9:var(--theme-ui-colors-yellow-9,#744210);--theme-ui-colors-green-0:var(--theme-ui-colors-green-0,null);--theme-ui-colors-green-1:var(--theme-ui-colors-green-1,#f0fff4);--theme-ui-colors-green-2:var(--theme-ui-colors-green-2,#c6f6d5);--theme-ui-colors-green-3:var(--theme-ui-colors-green-3,#9ae6b4);--theme-ui-colors-green-4:var(--theme-ui-colors-green-4,#68d391);--theme-ui-colors-green-5:var(--theme-ui-colors-green-5,#48bb78);--theme-ui-colors-green-6:var(--theme-ui-colors-green-6,#38a169);--theme-ui-colors-green-7:var(--theme-ui-colors-green-7,#2f855a);--theme-ui-colors-green-8:var(--theme-ui-colors-green-8,#276749);--theme-ui-colors-green-9:var(--theme-ui-colors-green-9,#22543d);--theme-ui-colors-teal-0:var(--theme-ui-colors-teal-0,null);--theme-ui-colors-teal-1:var(--theme-ui-colors-teal-1,#e6fffa);--theme-ui-colors-teal-2:var(--theme-ui-colors-teal-2,#b2f5ea);--theme-ui-colors-teal-3:var(--theme-ui-colors-teal-3,#81e6d9);--theme-ui-colors-teal-4:var(--theme-ui-colors-teal-4,#4fd1c5);--theme-ui-colors-teal-5:var(--theme-ui-colors-teal-5,#38b2ac);--theme-ui-colors-teal-6:var(--theme-ui-colors-teal-6,#319795);--theme-ui-colors-teal-7:var(--theme-ui-colors-teal-7,#2c7a7b);--theme-ui-colors-teal-8:var(--theme-ui-colors-teal-8,#285e61);--theme-ui-colors-teal-9:var(--theme-ui-colors-teal-9,#234e52);--theme-ui-colors-blue-0:var(--theme-ui-colors-blue-0,null);--theme-ui-colors-blue-1:var(--theme-ui-colors-blue-1,#ebf8ff);--theme-ui-colors-blue-2:var(--theme-ui-colors-blue-2,#bee3f8);--theme-ui-colors-blue-3:var(--theme-ui-colors-blue-3,#90cdf4);--theme-ui-colors-blue-4:var(--theme-ui-colors-blue-4,#63b3ed);--theme-ui-colors-blue-5:var(--theme-ui-colors-blue-5,#4299e1);--theme-ui-colors-blue-6:var(--theme-ui-colors-blue-6,#3182ce);--theme-ui-colors-blue-7:var(--theme-ui-colors-blue-7,#2b6cb0);--theme-ui-colors-blue-8:var(--theme-ui-colors-blue-8,#2c5282);--theme-ui-colors-blue-9:var(--theme-ui-colors-blue-9,#2a4365);--theme-ui-colors-indigo-0:var(--theme-ui-colors-indigo-0,null);--theme-ui-colors-indigo-1:var(--theme-ui-colors-indigo-1,#ebf4ff);--theme-ui-colors-indigo-2:var(--theme-ui-colors-indigo-2,#c3dafe);--theme-ui-colors-indigo-3:var(--theme-ui-colors-indigo-3,#a3bffa);--theme-ui-colors-indigo-4:var(--theme-ui-colors-indigo-4,#7f9cf5);--theme-ui-colors-indigo-5:var(--theme-ui-colors-indigo-5,#667eea);--theme-ui-colors-indigo-6:var(--theme-ui-colors-indigo-6,#5a67d8);--theme-ui-colors-indigo-7:var(--theme-ui-colors-indigo-7,#4c51bf);--theme-ui-colors-indigo-8:var(--theme-ui-colors-indigo-8,#434190);--theme-ui-colors-indigo-9:var(--theme-ui-colors-indigo-9,#3c366b);--theme-ui-colors-purple-0:var(--theme-ui-colors-purple-0,null);--theme-ui-colors-purple-1:var(--theme-ui-colors-purple-1,#faf5ff);--theme-ui-colors-purple-2:var(--theme-ui-colors-purple-2,#e9d8fd);--theme-ui-colors-purple-3:var(--theme-ui-colors-purple-3,#d6bcfa);--theme-ui-colors-purple-4:var(--theme-ui-colors-purple-4,#b794f4);--theme-ui-colors-purple-5:var(--theme-ui-colors-purple-5,#9f7aea);--theme-ui-colors-purple-6:var(--theme-ui-colors-purple-6,#805ad5);--theme-ui-colors-purple-7:var(--theme-ui-colors-purple-7,#6b46c1);--theme-ui-colors-purple-8:var(--theme-ui-colors-purple-8,#553c9a);--theme-ui-colors-purple-9:var(--theme-ui-colors-purple-9,#44337a);--theme-ui-colors-pink-0:var(--theme-ui-colors-pink-0,null);--theme-ui-colors-pink-1:var(--theme-ui-colors-pink-1,#fff5f7);--theme-ui-colors-pink-2:var(--theme-ui-colors-pink-2,#fed7e2);--theme-ui-colors-pink-3:var(--theme-ui-colors-pink-3,#fbb6ce);--theme-ui-colors-pink-4:var(--theme-ui-colors-pink-4,#f687b3);--theme-ui-colors-pink-5:var(--theme-ui-colors-pink-5,#ed64a6);--theme-ui-colors-pink-6:var(--theme-ui-colors-pink-6,#d53f8c);--theme-ui-colors-pink-7:var(--theme-ui-colors-pink-7,#b83280);--theme-ui-colors-pink-8:var(--theme-ui-colors-pink-8,#97266d);--theme-ui-colors-pink-9:var(--theme-ui-colors-pink-9,#702459);--theme-ui-colors-grayDark:var(--theme-ui-colors-grayDark,#2d3748);--theme-ui-colors-text:var(--theme-ui-colors-text,#2d3748);--theme-ui-colors-background:var(--theme-ui-colors-background,#fff);--theme-ui-colors-primary:var(--theme-ui-colors-primary,#6b46c1);--theme-ui-colors-primaryHover:var(--theme-ui-colors-primaryHover,#2c5282);--theme-ui-colors-secondary:var(--theme-ui-colors-secondary,#5f6c80);--theme-ui-colors-muted:var(--theme-ui-colors-muted,#e2e8f0);--theme-ui-colors-success:var(--theme-ui-colors-success,#9ae6b4);--theme-ui-colors-info:var(--theme-ui-colors-info,#63b3ed);--theme-ui-colors-warning:var(--theme-ui-colors-warning,#faf089);--theme-ui-colors-danger:var(--theme-ui-colors-danger,#feb2b2);--theme-ui-colors-light:var(--theme-ui-colors-light,#f7fafc);--theme-ui-colors-dark:var(--theme-ui-colors-dark,#2d3748);--theme-ui-colors-textMuted:var(--theme-ui-colors-textMuted,#718096);--theme-ui-colors-toggleIcon:var(--theme-ui-colors-toggleIcon,#2d3748);--theme-ui-colors-heading:var(--theme-ui-colors-heading,#000);--theme-ui-colors-divide:var(--theme-ui-colors-divide,#cbd5e0);color:var(--theme-ui-colors-text,var(--theme-ui-colors-text,#2d3748));background-color:var(--theme-ui-colors-background,var(--theme-ui-colors-background,#fff));}body.theme-ui-dark{--theme-ui-colors-text:var(--theme-ui-colors-modes-dark-text,#cbd5e0);--theme-ui-colors-primary:var(--theme-ui-colors-modes-dark-primary,#9f7aea);--theme-ui-colors-secondary:var(--theme-ui-colors-modes-dark-secondary,#7f8ea3);--theme-ui-colors-toggleIcon:var(--theme-ui-colors-modes-dark-toggleIcon,#cbd5e0);--theme-ui-colors-background:var(--theme-ui-colors-modes-dark-background,#1A202C);--theme-ui-colors-heading:var(--theme-ui-colors-modes-dark-heading,#fff);--theme-ui-colors-divide:var(--theme-ui-colors-modes-dark-divide,#2d3748);--theme-ui-colors-muted:var(--theme-ui-colors-modes-dark-muted,#2d3748);}&lt;/style&gt;&lt;style data-emotion-css=&quot;1bkk5q4&quot;&gt;.css-1bkk5q4{font-size:1rem;-webkit-letter-spacing:-0.003em;-moz-letter-spacing:-0.003em;-ms-letter-spacing:-0.003em;letter-spacing:-0.003em;line-height:1.625;--baseline-multiplier:0.179;--x-height-multiplier:0.35;}@media screen and (min-width:640px){.css-1bkk5q4{font-size:1rem;}}@media screen and (min-width:768px){.css-1bkk5q4{font-size:1.25rem;}}&lt;/style&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Studying researches and building on top of them is an important part of
what a team of ML Engineers do on a regular basis. Usually, teams do
this by organizing periodic, often weekly, paper reading sessions. Here
is a snippet from an internal work memo by
&lt;style data-emotion-css=&quot;1od09yo&quot;&gt;.css-1od09yo{color:var(--theme-ui-colors-primary,#6b46c1);-webkit-text-decoration:none;text-decoration:none;}.css-1od09yo:hover{-webkit-text-decoration:underline;text-decoration:underline;}&lt;/style&gt;&lt;a href=&quot;https://github.com/janaab11/&quot; class=&quot;css-1od09yo&quot;&gt;Manas&lt;/a&gt; explaining how
&lt;a href=&quot;https://vernacular-ai.github.io/ml/&quot; class=&quot;css-1od09yo&quot;&gt;we&lt;/a&gt; look at these sessions:&lt;/p&gt;&lt;style data-emotion-css=&quot;1gtwvjp&quot;&gt;.css-1gtwvjp{border-left-color:var(--theme-ui-colors-primary,#6b46c1);border-left-style:solid;border-left-width:6px;margin-left:0;margin-right:0;padding-left:2rem;}.css-1gtwvjp p{font-style:italic;}&lt;/style&gt;&lt;blockquote class=&quot;css-1gtwvjp&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Lets start with the basic motivation behind these sessions - we want
to read more papers. But beyond this individual goal, there is also
the simpler driving force of enthusiasm - we read something we like,
and we want to share it. It is the same instinct that drives us to
talk about books we read, movies we watch, and podcasts we listen to.
...&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;There are also secondary benefits, like knowledge transfer - both
speaker and audience will understand the topic better after a good
presentation - and discovering shared interests within a larger group,
etc.&lt;/p&gt;&lt;/blockquote&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;But it&amp;#x27;s not that easy to bring this in practice. Specially in a startup, where
processes and structures are constantly in flux. As the team size keeps growing,
different kinds of diversities start interfering. Diversities in interests,
reading styles, and even bandwidth.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;This post covers how we organize reading sessions in the &lt;a href=&quot;https://vernacular-ai.github.io/ml/team&quot; class=&quot;css-1od09yo&quot;&gt;ML
team&lt;/a&gt; at
&lt;a href=&quot;https://vernacular.ai/&quot; class=&quot;css-1od09yo&quot;&gt;Vernacular.ai&lt;/a&gt;. It might be helpful if you are
trying to do the same in your group.&lt;/p&gt;&lt;style data-emotion-css=&quot;1ldi06f&quot;&gt;.css-1ldi06f{background-color:var(--theme-ui-colors-muted,#e2e8f0);border:0;height:1px;margin:1rem;}&lt;/style&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;The very first thing that we did was to start asking people for research
papers that they like, weekly. After voting on one, the proposer of the
paper presented it on a predetermined day. This lost steam away after a
while because of various reasons. One of them being bandwidth crunch for
everyone that time. We were just 3 people.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;We revived paper reading after a while. This time everyone picked and
presented a paper of their own liking. This wasn&amp;#x27;t supposed to scale up
with team size, but we went with this for a decent while. While we were
free to choose and read whatever we wanted, lack of continuity in
readings, practical disconnects and difference in interests started to
reduce the overall engagement.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;After lockdown, the engagement level dropped further. On video calls,
you have to upgrade the quality of meetings if you want to maintain the
same level of participation. The missing modalities hurt significantly.
We spent inordinate amount of time trying to get to one single view on
how to go about these sessions. We tried experimenting with various
aspects like paper selection, accountability, presentation
accessibility, etc.&lt;/p&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Rather than going in those experiments in chronological order, it makes
sense to think about the problems from two angles based on what we know
now. You can say that the &lt;em class=&quot;css-0&quot;&gt;sessions&lt;/em&gt; are having certain issues, or
alternatively you can say that the &lt;em class=&quot;css-0&quot;&gt;people&lt;/em&gt; are having issues with the
sessions. While both feed on each other and are cyclic, it helps to look
at them separately.&lt;/p&gt;&lt;style data-emotion-css=&quot;1bzbprl&quot;&gt;.css-1bzbprl{font-family:inherit;font-weight:700;line-height:1.25;margin:0;margin-bottom:0.25rem;font-size:1.875rem;margin-top:0.5rem;color:var(--theme-ui-colors-heading,#000);}@media screen and (min-width:640px){.css-1bzbprl{font-size:2.25rem;}}@media screen and (min-width:768px){.css-1bzbprl{font-size:3rem;}}&lt;/style&gt;&lt;h2 class=&quot;css-1bzbprl&quot;&gt;Sessions&lt;/h2&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;We can break down sessions temporarily in the following three acts.&lt;/p&gt;&lt;style data-emotion-css=&quot;1u9n620&quot;&gt;.css-1u9n620{font-family:inherit;font-weight:700;line-height:1.25;margin:0;margin-bottom:0.25rem;font-size:1.5rem;margin-top:1rem;color:var(--theme-ui-colors-heading,#000);}@media screen and (min-width:640px){.css-1u9n620{font-size:1.875rem;}}@media screen and (min-width:768px){.css-1u9n620{font-size:2.25rem;}}&lt;/style&gt;&lt;h3 class=&quot;css-1u9n620&quot;&gt;1. Pre Session&lt;/h3&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Here it&amp;#x27;s known that a certain session is supposed to happen. You can
do the following in preparation:&lt;/p&gt;&lt;style data-emotion-css=&quot;15rlv7r&quot;&gt;.css-15rlv7r li{font-size:1rem;-webkit-letter-spacing:-0.003em;-moz-letter-spacing:-0.003em;-ms-letter-spacing:-0.003em;letter-spacing:-0.003em;line-height:1.625;--baseline-multiplier:0.179;--x-height-multiplier:0.35;}@media screen and (min-width:640px){.css-15rlv7r li{font-size:1rem;}}@media screen and (min-width:768px){.css-15rlv7r li{font-size:1.25rem;}}&lt;/style&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;Set clear &lt;em class=&quot;css-0&quot;&gt;expectations&lt;/em&gt;. What is supposed to be covered? How it&amp;#x27;s
supposed to be covered? Who should come? What will be the outcome?
etc.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;em class=&quot;css-0&quot;&gt;Excite&lt;/em&gt; the potential audience. If the audience is not really aware
of the topic, some amount of pre-work needs to be done to pull them
in.&lt;/li&gt;&lt;/ul&gt;&lt;h3 class=&quot;css-1u9n620&quot;&gt;2. Session&lt;/h3&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;During the session, you want to:&lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;Make the presentation &lt;em class=&quot;css-0&quot;&gt;stimulating and engaging&lt;/em&gt;.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Keep the presentation &lt;em class=&quot;css-0&quot;&gt;accessible&lt;/em&gt; while not being superficial.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Develop &lt;em class=&quot;css-0&quot;&gt;practical connections&lt;/em&gt; between the audience and content.&lt;/li&gt;&lt;/ul&gt;&lt;h3 class=&quot;css-1u9n620&quot;&gt;3. Post Session&lt;/h3&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Since you want the next sessions to be successful too, you would like
to:&lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;Make sure people are going away with a healthy amount of &lt;em class=&quot;css-0&quot;&gt;thought
food&lt;/em&gt;.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Nudge towards the &lt;em class=&quot;css-0&quot;&gt;utilitarian aspects&lt;/em&gt; of concepts discussed so that
audience have a few threads of experimentation to follow in their day
to day work.&lt;/li&gt;&lt;/ul&gt;&lt;h2 class=&quot;css-1bzbprl&quot;&gt;People&lt;/h2&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;For people, we can think along the following lines&lt;sup id=&quot;fnref-1&quot;&gt;&lt;a href=&quot;#fn-1&quot; class=&quot;footnote-ref css-1od09yo&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;Resourcefulness.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Motivation.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Interests, their depths, and varieties.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Style and method of working with new knowledge.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Level of comfort with group sessions. Both for presentation and
discussion.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Bandwidth. Specially considering industrial settings like ours.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Structural assistance and pushes.&lt;/li&gt;&lt;/ul&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Acting on all these factors to deliver a single style of session that
works for everyone is impossible. Not all factors might be important for
a team at a given moment of time, but even a reasonably small set is
sufficiently diverse. The key idea is accept a pluralistic view on the
issue. There is no &lt;em class=&quot;css-0&quot;&gt;single&lt;/em&gt; fundamentally correct way of doing these
sessions, and it&amp;#x27;s better to pick a digestible subset and solve for that.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Going ahead with this realization, we started doing &lt;em class=&quot;css-0&quot;&gt;seminars&lt;/em&gt;.&lt;/p&gt;&lt;h2 class=&quot;css-1bzbprl&quot;&gt;Seminars&lt;/h2&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Reading Seminars are very similar to seminar courses in Universities.
From another internal memo:&lt;/p&gt;&lt;blockquote class=&quot;css-1gtwvjp&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;These [Seminars] exist to complement the world of &lt;em class=&quot;css-0&quot;&gt;paper readings&lt;/em&gt;.
While &lt;em class=&quot;css-0&quot;&gt;Paper Reading&lt;/em&gt; sessions are about reading more papers and
sharing what we like, &lt;em class=&quot;css-0&quot;&gt;Reading Seminars&lt;/em&gt; are about learning something
specific. These are much more structured and pointed towards a goal.
The idea is to have deeper discussions, over longer periods of time,
about topics that might interest you. Either directly or indirectly,
this will lead to a better output (from the speaker) and experience
(for the audience) in the &lt;em class=&quot;css-0&quot;&gt;Paper Reading&lt;/em&gt; sessions that follow.&lt;/p&gt;&lt;/blockquote&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Seminars cover many of the issues nicely and they clearly don&amp;#x27;t touch
a few others. For example you can&amp;#x27;t just bring in any new paper and
discuss that in a session without setting up a seminar for that field.
And that&amp;#x27;s okay. There are other ways of handling that case.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;At the moment, we have the following parallel seminars running:&lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;Multi-Style TTS&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;End-to-End ASR&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Speech Representation Learning&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Dialog State Trackers&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Computational Paralinguistics&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Learning Theory&lt;/li&gt;&lt;/ul&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Each of these has a list of papers or topics to be discussed over a period of
1-2 months. While not perfect, these are turning out to be decent reading
roadmaps for these topics. Something we would like to open out after a couple of
months, similar to the old style
&lt;a href=&quot;https://backyard.vernacular.ai/paper-reading/&quot; class=&quot;css-1od09yo&quot;&gt;paper reading&lt;/a&gt; sessions.&lt;/p&gt;&lt;div class=&quot;footnotes css-0&quot;&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;ol class=&quot;css-15rlv7r&quot;&gt;&lt;li id=&quot;fn-1&quot; class=&quot;css-0&quot;&gt;Many are derived from an internal note by
&lt;a href=&quot;https://github.com/janaab11/&quot; class=&quot;css-1od09yo&quot;&gt;Manas&lt;/a&gt;&lt;a href=&quot;#fnref-1&quot; class=&quot;footnote-backref css-1od09yo&quot;&gt;↩&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Bad Audio Detection]]></title><link>https://vernacular-ai.github.io/ml/bad-audio-detection</link><guid isPermaLink="false">https://vernacular-ai.github.io/ml/bad-audio-detection</guid><pubDate>Tue, 28 Jul 2020 18:30:00 GMT</pubDate><content:encoded>&lt;style data-emotion-css=&quot;1xz4htx&quot;&gt;body{--theme-ui-colors-transparent:var(--theme-ui-colors-transparent,transparent);--theme-ui-colors-black:var(--theme-ui-colors-black,#000);--theme-ui-colors-white:var(--theme-ui-colors-white,#fff);--theme-ui-colors-gray-0:var(--theme-ui-colors-gray-0,null);--theme-ui-colors-gray-1:var(--theme-ui-colors-gray-1,#f7fafc);--theme-ui-colors-gray-2:var(--theme-ui-colors-gray-2,#edf2f7);--theme-ui-colors-gray-3:var(--theme-ui-colors-gray-3,#e2e8f0);--theme-ui-colors-gray-4:var(--theme-ui-colors-gray-4,#cbd5e0);--theme-ui-colors-gray-5:var(--theme-ui-colors-gray-5,#a0aec0);--theme-ui-colors-gray-6:var(--theme-ui-colors-gray-6,#718096);--theme-ui-colors-gray-7:var(--theme-ui-colors-gray-7,#4a5568);--theme-ui-colors-gray-8:var(--theme-ui-colors-gray-8,#2d3748);--theme-ui-colors-gray-9:var(--theme-ui-colors-gray-9,#1a202c);--theme-ui-colors-red-0:var(--theme-ui-colors-red-0,null);--theme-ui-colors-red-1:var(--theme-ui-colors-red-1,#fff5f5);--theme-ui-colors-red-2:var(--theme-ui-colors-red-2,#fed7d7);--theme-ui-colors-red-3:var(--theme-ui-colors-red-3,#feb2b2);--theme-ui-colors-red-4:var(--theme-ui-colors-red-4,#fc8181);--theme-ui-colors-red-5:var(--theme-ui-colors-red-5,#f56565);--theme-ui-colors-red-6:var(--theme-ui-colors-red-6,#e53e3e);--theme-ui-colors-red-7:var(--theme-ui-colors-red-7,#c53030);--theme-ui-colors-red-8:var(--theme-ui-colors-red-8,#9b2c2c);--theme-ui-colors-red-9:var(--theme-ui-colors-red-9,#742a2a);--theme-ui-colors-orange-0:var(--theme-ui-colors-orange-0,null);--theme-ui-colors-orange-1:var(--theme-ui-colors-orange-1,#fffaf0);--theme-ui-colors-orange-2:var(--theme-ui-colors-orange-2,#feebc8);--theme-ui-colors-orange-3:var(--theme-ui-colors-orange-3,#fbd38d);--theme-ui-colors-orange-4:var(--theme-ui-colors-orange-4,#f6ad55);--theme-ui-colors-orange-5:var(--theme-ui-colors-orange-5,#ed8936);--theme-ui-colors-orange-6:var(--theme-ui-colors-orange-6,#dd6b20);--theme-ui-colors-orange-7:var(--theme-ui-colors-orange-7,#c05621);--theme-ui-colors-orange-8:var(--theme-ui-colors-orange-8,#9c4221);--theme-ui-colors-orange-9:var(--theme-ui-colors-orange-9,#7b341e);--theme-ui-colors-yellow-0:var(--theme-ui-colors-yellow-0,null);--theme-ui-colors-yellow-1:var(--theme-ui-colors-yellow-1,#fffff0);--theme-ui-colors-yellow-2:var(--theme-ui-colors-yellow-2,#fefcbf);--theme-ui-colors-yellow-3:var(--theme-ui-colors-yellow-3,#faf089);--theme-ui-colors-yellow-4:var(--theme-ui-colors-yellow-4,#f6e05e);--theme-ui-colors-yellow-5:var(--theme-ui-colors-yellow-5,#ecc94b);--theme-ui-colors-yellow-6:var(--theme-ui-colors-yellow-6,#d69e2e);--theme-ui-colors-yellow-7:var(--theme-ui-colors-yellow-7,#b7791f);--theme-ui-colors-yellow-8:var(--theme-ui-colors-yellow-8,#975a16);--theme-ui-colors-yellow-9:var(--theme-ui-colors-yellow-9,#744210);--theme-ui-colors-green-0:var(--theme-ui-colors-green-0,null);--theme-ui-colors-green-1:var(--theme-ui-colors-green-1,#f0fff4);--theme-ui-colors-green-2:var(--theme-ui-colors-green-2,#c6f6d5);--theme-ui-colors-green-3:var(--theme-ui-colors-green-3,#9ae6b4);--theme-ui-colors-green-4:var(--theme-ui-colors-green-4,#68d391);--theme-ui-colors-green-5:var(--theme-ui-colors-green-5,#48bb78);--theme-ui-colors-green-6:var(--theme-ui-colors-green-6,#38a169);--theme-ui-colors-green-7:var(--theme-ui-colors-green-7,#2f855a);--theme-ui-colors-green-8:var(--theme-ui-colors-green-8,#276749);--theme-ui-colors-green-9:var(--theme-ui-colors-green-9,#22543d);--theme-ui-colors-teal-0:var(--theme-ui-colors-teal-0,null);--theme-ui-colors-teal-1:var(--theme-ui-colors-teal-1,#e6fffa);--theme-ui-colors-teal-2:var(--theme-ui-colors-teal-2,#b2f5ea);--theme-ui-colors-teal-3:var(--theme-ui-colors-teal-3,#81e6d9);--theme-ui-colors-teal-4:var(--theme-ui-colors-teal-4,#4fd1c5);--theme-ui-colors-teal-5:var(--theme-ui-colors-teal-5,#38b2ac);--theme-ui-colors-teal-6:var(--theme-ui-colors-teal-6,#319795);--theme-ui-colors-teal-7:var(--theme-ui-colors-teal-7,#2c7a7b);--theme-ui-colors-teal-8:var(--theme-ui-colors-teal-8,#285e61);--theme-ui-colors-teal-9:var(--theme-ui-colors-teal-9,#234e52);--theme-ui-colors-blue-0:var(--theme-ui-colors-blue-0,null);--theme-ui-colors-blue-1:var(--theme-ui-colors-blue-1,#ebf8ff);--theme-ui-colors-blue-2:var(--theme-ui-colors-blue-2,#bee3f8);--theme-ui-colors-blue-3:var(--theme-ui-colors-blue-3,#90cdf4);--theme-ui-colors-blue-4:var(--theme-ui-colors-blue-4,#63b3ed);--theme-ui-colors-blue-5:var(--theme-ui-colors-blue-5,#4299e1);--theme-ui-colors-blue-6:var(--theme-ui-colors-blue-6,#3182ce);--theme-ui-colors-blue-7:var(--theme-ui-colors-blue-7,#2b6cb0);--theme-ui-colors-blue-8:var(--theme-ui-colors-blue-8,#2c5282);--theme-ui-colors-blue-9:var(--theme-ui-colors-blue-9,#2a4365);--theme-ui-colors-indigo-0:var(--theme-ui-colors-indigo-0,null);--theme-ui-colors-indigo-1:var(--theme-ui-colors-indigo-1,#ebf4ff);--theme-ui-colors-indigo-2:var(--theme-ui-colors-indigo-2,#c3dafe);--theme-ui-colors-indigo-3:var(--theme-ui-colors-indigo-3,#a3bffa);--theme-ui-colors-indigo-4:var(--theme-ui-colors-indigo-4,#7f9cf5);--theme-ui-colors-indigo-5:var(--theme-ui-colors-indigo-5,#667eea);--theme-ui-colors-indigo-6:var(--theme-ui-colors-indigo-6,#5a67d8);--theme-ui-colors-indigo-7:var(--theme-ui-colors-indigo-7,#4c51bf);--theme-ui-colors-indigo-8:var(--theme-ui-colors-indigo-8,#434190);--theme-ui-colors-indigo-9:var(--theme-ui-colors-indigo-9,#3c366b);--theme-ui-colors-purple-0:var(--theme-ui-colors-purple-0,null);--theme-ui-colors-purple-1:var(--theme-ui-colors-purple-1,#faf5ff);--theme-ui-colors-purple-2:var(--theme-ui-colors-purple-2,#e9d8fd);--theme-ui-colors-purple-3:var(--theme-ui-colors-purple-3,#d6bcfa);--theme-ui-colors-purple-4:var(--theme-ui-colors-purple-4,#b794f4);--theme-ui-colors-purple-5:var(--theme-ui-colors-purple-5,#9f7aea);--theme-ui-colors-purple-6:var(--theme-ui-colors-purple-6,#805ad5);--theme-ui-colors-purple-7:var(--theme-ui-colors-purple-7,#6b46c1);--theme-ui-colors-purple-8:var(--theme-ui-colors-purple-8,#553c9a);--theme-ui-colors-purple-9:var(--theme-ui-colors-purple-9,#44337a);--theme-ui-colors-pink-0:var(--theme-ui-colors-pink-0,null);--theme-ui-colors-pink-1:var(--theme-ui-colors-pink-1,#fff5f7);--theme-ui-colors-pink-2:var(--theme-ui-colors-pink-2,#fed7e2);--theme-ui-colors-pink-3:var(--theme-ui-colors-pink-3,#fbb6ce);--theme-ui-colors-pink-4:var(--theme-ui-colors-pink-4,#f687b3);--theme-ui-colors-pink-5:var(--theme-ui-colors-pink-5,#ed64a6);--theme-ui-colors-pink-6:var(--theme-ui-colors-pink-6,#d53f8c);--theme-ui-colors-pink-7:var(--theme-ui-colors-pink-7,#b83280);--theme-ui-colors-pink-8:var(--theme-ui-colors-pink-8,#97266d);--theme-ui-colors-pink-9:var(--theme-ui-colors-pink-9,#702459);--theme-ui-colors-grayDark:var(--theme-ui-colors-grayDark,#2d3748);--theme-ui-colors-text:var(--theme-ui-colors-text,#2d3748);--theme-ui-colors-background:var(--theme-ui-colors-background,#fff);--theme-ui-colors-primary:var(--theme-ui-colors-primary,#6b46c1);--theme-ui-colors-primaryHover:var(--theme-ui-colors-primaryHover,#2c5282);--theme-ui-colors-secondary:var(--theme-ui-colors-secondary,#5f6c80);--theme-ui-colors-muted:var(--theme-ui-colors-muted,#e2e8f0);--theme-ui-colors-success:var(--theme-ui-colors-success,#9ae6b4);--theme-ui-colors-info:var(--theme-ui-colors-info,#63b3ed);--theme-ui-colors-warning:var(--theme-ui-colors-warning,#faf089);--theme-ui-colors-danger:var(--theme-ui-colors-danger,#feb2b2);--theme-ui-colors-light:var(--theme-ui-colors-light,#f7fafc);--theme-ui-colors-dark:var(--theme-ui-colors-dark,#2d3748);--theme-ui-colors-textMuted:var(--theme-ui-colors-textMuted,#718096);--theme-ui-colors-toggleIcon:var(--theme-ui-colors-toggleIcon,#2d3748);--theme-ui-colors-heading:var(--theme-ui-colors-heading,#000);--theme-ui-colors-divide:var(--theme-ui-colors-divide,#cbd5e0);color:var(--theme-ui-colors-text,var(--theme-ui-colors-text,#2d3748));background-color:var(--theme-ui-colors-background,var(--theme-ui-colors-background,#fff));}body.theme-ui-dark{--theme-ui-colors-text:var(--theme-ui-colors-modes-dark-text,#cbd5e0);--theme-ui-colors-primary:var(--theme-ui-colors-modes-dark-primary,#9f7aea);--theme-ui-colors-secondary:var(--theme-ui-colors-modes-dark-secondary,#7f8ea3);--theme-ui-colors-toggleIcon:var(--theme-ui-colors-modes-dark-toggleIcon,#cbd5e0);--theme-ui-colors-background:var(--theme-ui-colors-modes-dark-background,#1A202C);--theme-ui-colors-heading:var(--theme-ui-colors-modes-dark-heading,#fff);--theme-ui-colors-divide:var(--theme-ui-colors-modes-dark-divide,#2d3748);--theme-ui-colors-muted:var(--theme-ui-colors-modes-dark-muted,#2d3748);}&lt;/style&gt;&lt;style data-emotion-css=&quot;1bkk5q4&quot;&gt;.css-1bkk5q4{font-size:1rem;-webkit-letter-spacing:-0.003em;-moz-letter-spacing:-0.003em;-ms-letter-spacing:-0.003em;letter-spacing:-0.003em;line-height:1.625;--baseline-multiplier:0.179;--x-height-multiplier:0.35;}@media screen and (min-width:640px){.css-1bkk5q4{font-size:1rem;}}@media screen and (min-width:768px){.css-1bkk5q4{font-size:1.25rem;}}&lt;/style&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;This blog will be a short one, where we&amp;#x27;ll talk about our approach on filtering out inscrutable audios from &lt;style data-emotion-css=&quot;1od09yo&quot;&gt;.css-1od09yo{color:var(--theme-ui-colors-primary,#6b46c1);-webkit-text-decoration:none;text-decoration:none;}.css-1od09yo:hover{-webkit-text-decoration:underline;text-decoration:underline;}&lt;/style&gt;&lt;a href=&quot;https://vernacular.ai/vasr&quot; class=&quot;css-1od09yo&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;VASR&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;There are situations in Call Center Automation (CCA) pipeline where user utterances are bad. &lt;strong class=&quot;css-0&quot;&gt;Bad&lt;/strong&gt; here is defined by things like noise, static, silences or background murmur etc. rendering the downstream SLU systems helpless. We started with a proposal and prepare a dataset for making an ML system learn to reject these audios.&lt;/p&gt;&lt;style data-emotion-css=&quot;1u9n620&quot;&gt;.css-1u9n620{font-family:inherit;font-weight:700;line-height:1.25;margin:0;margin-bottom:0.25rem;font-size:1.5rem;margin-top:1rem;color:var(--theme-ui-colors-heading,#000);}@media screen and (min-width:640px){.css-1u9n620{font-size:1.875rem;}}@media screen and (min-width:768px){.css-1u9n620{font-size:2.25rem;}}&lt;/style&gt;&lt;h3 class=&quot;css-1u9n620&quot;&gt;Benefits&lt;/h3&gt;&lt;style data-emotion-css=&quot;15rlv7r&quot;&gt;.css-15rlv7r li{font-size:1rem;-webkit-letter-spacing:-0.003em;-moz-letter-spacing:-0.003em;-ms-letter-spacing:-0.003em;letter-spacing:-0.003em;line-height:1.625;--baseline-multiplier:0.179;--x-height-multiplier:0.35;}@media screen and (min-width:640px){.css-15rlv7r li{font-size:1rem;}}@media screen and (min-width:768px){.css-15rlv7r li{font-size:1.25rem;}}&lt;/style&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;No more misfires from SLU side which ultimately leads to a better user experience.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Save compute and time by skipping bad audios.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;The whole system can be used for all our audio based tasks to predict and filter out the poor ones, hence avoiding sample noise for these tasks.&lt;/li&gt;&lt;/ul&gt;&lt;h3 class=&quot;css-1u9n620&quot;&gt;Dataset&lt;/h3&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;We prepared a dataset of intent tagged conversations with specially marked intents which tell us that these utterances are bad and them going further in SLU will result in errors. Also we have a sampling of non-bad utterances (tagged with regular intents) to make this a classification problem.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;There are total 9928 samples of audios labelled as bad and 20000 samples labeled as good.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;All the raw labels were not very useful, hence we clean and preprocess the data to finally create 2 broad categories with sub-classes.&lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;code class=&quot;css-0&quot;&gt;audio-bad&lt;/code&gt;&lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;code class=&quot;css-0&quot;&gt;audio-noisy&lt;/code&gt;: Noisy audio.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;code class=&quot;css-0&quot;&gt;audio-silent&lt;/code&gt;: Silent audio.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;code class=&quot;css-0&quot;&gt;audio-talking&lt;/code&gt;: Background talking.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;code class=&quot;css-0&quot;&gt;hold-phone&lt;/code&gt;: Music from keeping on hold.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;code class=&quot;css-0&quot;&gt;audio-good&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3 class=&quot;css-1u9n620&quot;&gt;Exploratory Data Analysis&lt;/h3&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;We needed to understand the class imbalance and hence we plot a histogram representing number of samples for each class.&lt;/p&gt;&lt;figure&gt;
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position:relative;display:block;margin-left:auto;margin-right:auto;max-width:960px&quot;&gt;
      &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom:66.66666666666666%;position:relative;bottom:0;left:0;background-image:url(&amp;#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACDklEQVQ4y42Tz2sTQRTHV9D26t2jF/Wsf0jrL9CbWiyCeuml7UGk/gBvSmsVpR5qQKsgpqF6CPUH7VZRT5qapFrQrBWXtknc37sz+3XeS7Js2gQceOzM7JvPfN+P0eI4Bo0oimC7Pixlnh+odYgwDGGaJgzDQKVSYbNtm33pX9qklMzRWjDHcXDu4UfsHc5hYr7MP8NIYOsgAXS4ZbQWQjA0AYomsP/2IrTTj3Elt9xQLWM+kLZOg8AkioFEty0Lvu/j+B0dPYNPcH3ua0OhkE3IdnD6AgImCj0FMowKbxydXMTOswRcTsJLfzuFvw0YNBMfBEECvNYE1t2QVXaDdgT6rNDgkAnYo4BjuYIq0CfsGcpiamG1LXwhGyZTF7QDlTJSSEk9QkCVw7HZgprr0E49ws18uatCgsZbgeQXqYXrujimitI7+FRVuYAT95awS6kdn19hx3XLhxNEeFsy8eLzGn5V3VTosr1tpBTwPA99E6ptzszgUvYLDpNC1UI3XhZZ7e4LzzD5+hsOXc1jx8AMMu9+MGDTUXmOUm3TKj8pPD/9HvtHshjPF3Ex8wH7hp/j/psVDDxYwoHRWUzrqzh5dwEHL88ho39n/75br6CXfnNrUQq0dE+5no+Nak3dGPF8s1bnZ/hTPbliqYxqrcb79b8W7/9Zr2LN3IDtuEmeNfzH4CfGT0109WkV7R+rXrPRhrvTTAAAAABJRU5ErkJggg==&amp;#x27;);background-size:cover;display:block&quot;&gt;&lt;/span&gt;
  &lt;img class=&quot;gatsby-resp-image-image css-0&quot; alt=&quot;Can&amp;#x27;t See? Something went wrong!&quot; title=&quot;Can&amp;#x27;t See? Something went wrong!&quot; src=&quot;/ml/static/4c9d8fd5fbd1edecb4f5774a630bdafa/7d769/Class_Distribution.png&quot; srcSet=&quot;/ml/static/4c9d8fd5fbd1edecb4f5774a630bdafa/5243c/Class_Distribution.png 240w,/ml/static/4c9d8fd5fbd1edecb4f5774a630bdafa/ab158/Class_Distribution.png 480w,/ml/static/4c9d8fd5fbd1edecb4f5774a630bdafa/7d769/Class_Distribution.png 960w,/ml/static/4c9d8fd5fbd1edecb4f5774a630bdafa/5ece7/Class_Distribution.png 1200w&quot; sizes=&quot;(max-width: 960px) 100vw, 960px&quot; style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0&quot; loading=&quot;lazy&quot;/&gt;
    &lt;/span&gt;&lt;/figure&gt;&lt;figure&gt;
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position:relative;display:block;margin-left:auto;margin-right:auto;max-width:960px&quot;&gt;
      &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom:66.66666666666666%;position:relative;bottom:0;left:0;background-image:url(&amp;#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABxUlEQVQ4y32Tz07CQBDGeR/fwLfwRTz5DMZgvGiURJ7FmydvniBCAgJtTUpLS4GWtruf800tUEQ3md1mOvObPzvbgqw8z7Fer1GWJRaLBcbjMVzXFfEwm80wnbrwPFfOqeo9z0MYhvpdFIX6G2OIQstaC8p2u1Xg8XIcoNtd67eYqS2DEpgkCeI4Vj9CFciNCmZYO8kuBlZ0BUYjg5ublegMGI+BB4MB+v0+JpOJVsAgOyBhm81GU2faFRBSjsHT00rP29s9kHbz+VwlCAKF0W8HzLJMe8PIh0DHsbi/r4DtdgVkm2jf6/UwHA4l+5H6NIAEMRIzPQY+PBwCLeoWV3a2cTYydKTzpzI8Bkq1CjhevzL0ff/PDB1nD6RPPRW1/AJyY6N5MTQoSxoafH1ZvZQgsLseErqH/APkjyzbqiKKgE4nkaaXuL5e4fU1xd0dh77Ay0vlFMemUXJjbOooaZrKKCR4f09weRng4mKO83MfZ2chrq5CvL0FeHxcyg1HeH5eCCCRwU619xRW+QPcNzZNcx3mKKIYLJe5PEMPHx8zfH56Ol6+H4odbTOBlCJ544W12JdKTi9jCimJQ185n7rlw9K/AXuL3rElE+jjAAAAAElFTkSuQmCC&amp;#x27;);background-size:cover;display:block&quot;&gt;&lt;/span&gt;
  &lt;img class=&quot;gatsby-resp-image-image css-0&quot; alt=&quot;Can&amp;#x27;t See? Something went wrong!&quot; title=&quot;Can&amp;#x27;t See? Something went wrong!&quot; src=&quot;/ml/static/2f8f7d0a4f9b03b7fb35684a894573af/7d769/EDA.png&quot; srcSet=&quot;/ml/static/2f8f7d0a4f9b03b7fb35684a894573af/5243c/EDA.png 240w,/ml/static/2f8f7d0a4f9b03b7fb35684a894573af/ab158/EDA.png 480w,/ml/static/2f8f7d0a4f9b03b7fb35684a894573af/7d769/EDA.png 960w,/ml/static/2f8f7d0a4f9b03b7fb35684a894573af/5ece7/EDA.png 1200w&quot; sizes=&quot;(max-width: 960px) 100vw, 960px&quot; style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0&quot; loading=&quot;lazy&quot;/&gt;
    &lt;/span&gt;&lt;/figure&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;We also plot the frequency vs duration histogram plot to understand the general distribution of audio durations in the dataset.
Based on the mean duration of 5.26 seconds and the peaks in the histogram, we decided to threshold our audios to 6.5 seconds.
Anything less than that will be padded to 6.5 seconds and anything greater than that duration will be truncated to 6.5 seconds.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Even though we have sub-classes for &lt;code class=&quot;css-0&quot;&gt;audio-bad&lt;/code&gt; spanning different areas of what &amp;quot;bad&amp;quot; could be, we decided to focus only on the &lt;strong class=&quot;css-0&quot;&gt;noisy audios&lt;/strong&gt;. Silent Audios can be treated separately, since they do not actually require something as complex as an ML model to classify them. We can simply use the age-old powerful signal processing methods to filter those out with some good confidence.&lt;/p&gt;&lt;h3 class=&quot;css-1u9n620&quot;&gt;Model&lt;/h3&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;If we are going to reject these bad audios then we need to do so with:&lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;High Precision&lt;/strong&gt;: We should not be rejecting good audios which are perfectly interpretable and understandable. &lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Low Latency:&lt;/strong&gt; This system should have little to no latency, otherwise it will just slow down our whole VASR flow after being deployed and integrated.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Online:&lt;/strong&gt; The model should be capable of running in an online setting where continuous chunks of audios are fed into the system.&lt;/li&gt;&lt;/ul&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;We used a standard audio classification pipeline to train our binary classification task.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;This involves generating log-mel spectrograms and then running a Convolution Neural Network (CNN) based feature extractor on top of this fixed size spectrogram image.&lt;/p&gt;&lt;figure&gt;
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position:relative;display:block;margin-left:auto;margin-right:auto;max-width:960px&quot;&gt;
      &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom:40%;position:relative;bottom:0;left:0;background-image:url(&amp;#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAAB8UlEQVQoz2NgZGBgYmBg4AFiQSBm4YbwGZQl5Rn0/DoYGaDAIKif0Sx6NliOkYlVjFdMjc8yaZWOReIKZpCYiJI1TGkMM6danZCEf40DT8L2KIbk81IMSMAobCqLRfxSbhDbNn1ziGXiqmAQ2zh8Oqdt5jYP69T1PAwooPrqcY6iC6/Vmk/+Fuq48Z+h6aGDe86uHof8A0dsM7eL22ftUHTI2fPeLmunk4nDJAb77F1T7LN364K02qRvdrDP2qljl7ldR9E8HmQwOwPDtIv/2Kac/a/Ze/S/5Jxj/xnmH3d2zdpz0q/x/n+7tE3+II1AQ7c5Zu/cDWIbhkxWs03f0u6UvYvdJn2TsG3GVjm7zG1q8saRHEBpVgaGtef+s6w6/9+yZf1/hdkbfjIs3uzs4j3TwjpiepNl2DRlkCGiStZSup51BjLGUZwgvrCChZK0XoAo0IWWpnHLmFG9vHRvD+uiXbkG+e0hRk0N2gwe8fxIskysHPxCQJoLFBdAzMfKwccHpLk5BWTYLROWKdqmrOFzyNjIKapsywhVgwqAIqIcwgq8////Z+AWlGMDCokJyZnCXAEynBdJORvQAj0hWUMOhPa+pSwsLbNY3VdfYzJevoGRgYlZBCgBU8AKNYQFyueDJjEGVk4BcPqBysNcxggA0RCD68nDpSUAAAAASUVORK5CYII=&amp;#x27;);background-size:cover;display:block&quot;&gt;&lt;/span&gt;
  &lt;img class=&quot;gatsby-resp-image-image css-0&quot; alt=&quot;Can&amp;#x27;t See? Something went wrong!&quot; title=&quot;Can&amp;#x27;t See? Something went wrong!&quot; src=&quot;/ml/static/0b32021223e2be0de46b206960080fe7/7d769/model_architecture.png&quot; srcSet=&quot;/ml/static/0b32021223e2be0de46b206960080fe7/5243c/model_architecture.png 240w,/ml/static/0b32021223e2be0de46b206960080fe7/ab158/model_architecture.png 480w,/ml/static/0b32021223e2be0de46b206960080fe7/7d769/model_architecture.png 960w,/ml/static/0b32021223e2be0de46b206960080fe7/5ece7/model_architecture.png 1200w&quot; sizes=&quot;(max-width: 960px) 100vw, 960px&quot; style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0&quot; loading=&quot;lazy&quot;/&gt;
    &lt;/span&gt;
  &lt;figcaption&gt;&lt;b class=&quot;css-0&quot;&gt;&lt;center&gt;Binary Audio Classification based on Log-Mel Spectrograms&lt;/center&gt;&lt;/b&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;While these features (spectrograms) can be generated once after processing all the audios in the dataset, this feature generation needs to be done on the fly to make a model that can be used in deployment i.e given raw audios as input, it should be able to predict the class, that was easily incorporated through a few transforms done within the model using &lt;code class=&quot;css-0&quot;&gt;torch-audio&lt;/code&gt;.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Even though this architecture is simple, it got us an &lt;strong class=&quot;css-0&quot;&gt;accuracy of about 87%&lt;/strong&gt;. But it is not the &lt;code class=&quot;css-0&quot;&gt;accuracy&lt;/code&gt; we need to see, our choice of metric to measure the performance is &lt;strong class=&quot;css-0&quot;&gt;precision&lt;/strong&gt; as explained earlier. We are still in the process improving these initial baseline numbers of the model. One simple approach for increasing the precision is to increase the threshold, trading-off some coverage in the form of support.&lt;/p&gt;&lt;h3 class=&quot;css-1u9n620&quot;&gt;Misclassification Analysis&lt;/h3&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;We also do a post prediction analysis on the misclassified audios, which revealed an interesting pattern in the dataset and in the kind of audios that the model was finding hard to make predictions on.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Briefly these errors followed 3 major types which now helps to understand the places where we can make improvements.&lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Type 1 (Very Short Utterance)&lt;/strong&gt; : say 0.2 seconds in audio of 6 seconds. Due to noise in most part of such short utterance audios, our model predicts it to be noisy and not good in some occasions. This can probably be fixed with VAD which can trim the non speech segments in such short utterance audios.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Type 2 (Long audios)&lt;/strong&gt; : Audio duration is longer than 6.5 seconds with the speaker in latter half. Since we chose to threshold our features (log-mels) at 6.5 seconds, the latter part of the audio is basically truncated and hence such errors.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Type 3 (Ambiguous / Wrongly Labeled)&lt;/strong&gt; : There are samples in the dataset which are not perfectly labelled. One may say these audios are debatablem, some may find them to be bad others may think that they are ok. This type of label noise is something which needs to be tackled.&lt;/li&gt;&lt;/ul&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Needless to say, there are places where we can improve these results, but having a solid baseline model initially is important for incremental improvements over time and after a few iterations we finally see these models in our production systems. &lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;That&amp;#x27;s all for now. Stay tuned to our &lt;a href=&quot;https://vernacular-ai.github.io/ml/rss.xml&quot; class=&quot;css-1od09yo&quot;&gt;rss feed&lt;/a&gt; for updates and more.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Speaker Diarization]]></title><link>https://vernacular-ai.github.io/ml/speaker-diarization</link><guid isPermaLink="false">https://vernacular-ai.github.io/ml/speaker-diarization</guid><pubDate>Mon, 20 Jul 2020 18:30:00 GMT</pubDate><content:encoded>&lt;style data-emotion-css=&quot;1xz4htx&quot;&gt;body{--theme-ui-colors-transparent:var(--theme-ui-colors-transparent,transparent);--theme-ui-colors-black:var(--theme-ui-colors-black,#000);--theme-ui-colors-white:var(--theme-ui-colors-white,#fff);--theme-ui-colors-gray-0:var(--theme-ui-colors-gray-0,null);--theme-ui-colors-gray-1:var(--theme-ui-colors-gray-1,#f7fafc);--theme-ui-colors-gray-2:var(--theme-ui-colors-gray-2,#edf2f7);--theme-ui-colors-gray-3:var(--theme-ui-colors-gray-3,#e2e8f0);--theme-ui-colors-gray-4:var(--theme-ui-colors-gray-4,#cbd5e0);--theme-ui-colors-gray-5:var(--theme-ui-colors-gray-5,#a0aec0);--theme-ui-colors-gray-6:var(--theme-ui-colors-gray-6,#718096);--theme-ui-colors-gray-7:var(--theme-ui-colors-gray-7,#4a5568);--theme-ui-colors-gray-8:var(--theme-ui-colors-gray-8,#2d3748);--theme-ui-colors-gray-9:var(--theme-ui-colors-gray-9,#1a202c);--theme-ui-colors-red-0:var(--theme-ui-colors-red-0,null);--theme-ui-colors-red-1:var(--theme-ui-colors-red-1,#fff5f5);--theme-ui-colors-red-2:var(--theme-ui-colors-red-2,#fed7d7);--theme-ui-colors-red-3:var(--theme-ui-colors-red-3,#feb2b2);--theme-ui-colors-red-4:var(--theme-ui-colors-red-4,#fc8181);--theme-ui-colors-red-5:var(--theme-ui-colors-red-5,#f56565);--theme-ui-colors-red-6:var(--theme-ui-colors-red-6,#e53e3e);--theme-ui-colors-red-7:var(--theme-ui-colors-red-7,#c53030);--theme-ui-colors-red-8:var(--theme-ui-colors-red-8,#9b2c2c);--theme-ui-colors-red-9:var(--theme-ui-colors-red-9,#742a2a);--theme-ui-colors-orange-0:var(--theme-ui-colors-orange-0,null);--theme-ui-colors-orange-1:var(--theme-ui-colors-orange-1,#fffaf0);--theme-ui-colors-orange-2:var(--theme-ui-colors-orange-2,#feebc8);--theme-ui-colors-orange-3:var(--theme-ui-colors-orange-3,#fbd38d);--theme-ui-colors-orange-4:var(--theme-ui-colors-orange-4,#f6ad55);--theme-ui-colors-orange-5:var(--theme-ui-colors-orange-5,#ed8936);--theme-ui-colors-orange-6:var(--theme-ui-colors-orange-6,#dd6b20);--theme-ui-colors-orange-7:var(--theme-ui-colors-orange-7,#c05621);--theme-ui-colors-orange-8:var(--theme-ui-colors-orange-8,#9c4221);--theme-ui-colors-orange-9:var(--theme-ui-colors-orange-9,#7b341e);--theme-ui-colors-yellow-0:var(--theme-ui-colors-yellow-0,null);--theme-ui-colors-yellow-1:var(--theme-ui-colors-yellow-1,#fffff0);--theme-ui-colors-yellow-2:var(--theme-ui-colors-yellow-2,#fefcbf);--theme-ui-colors-yellow-3:var(--theme-ui-colors-yellow-3,#faf089);--theme-ui-colors-yellow-4:var(--theme-ui-colors-yellow-4,#f6e05e);--theme-ui-colors-yellow-5:var(--theme-ui-colors-yellow-5,#ecc94b);--theme-ui-colors-yellow-6:var(--theme-ui-colors-yellow-6,#d69e2e);--theme-ui-colors-yellow-7:var(--theme-ui-colors-yellow-7,#b7791f);--theme-ui-colors-yellow-8:var(--theme-ui-colors-yellow-8,#975a16);--theme-ui-colors-yellow-9:var(--theme-ui-colors-yellow-9,#744210);--theme-ui-colors-green-0:var(--theme-ui-colors-green-0,null);--theme-ui-colors-green-1:var(--theme-ui-colors-green-1,#f0fff4);--theme-ui-colors-green-2:var(--theme-ui-colors-green-2,#c6f6d5);--theme-ui-colors-green-3:var(--theme-ui-colors-green-3,#9ae6b4);--theme-ui-colors-green-4:var(--theme-ui-colors-green-4,#68d391);--theme-ui-colors-green-5:var(--theme-ui-colors-green-5,#48bb78);--theme-ui-colors-green-6:var(--theme-ui-colors-green-6,#38a169);--theme-ui-colors-green-7:var(--theme-ui-colors-green-7,#2f855a);--theme-ui-colors-green-8:var(--theme-ui-colors-green-8,#276749);--theme-ui-colors-green-9:var(--theme-ui-colors-green-9,#22543d);--theme-ui-colors-teal-0:var(--theme-ui-colors-teal-0,null);--theme-ui-colors-teal-1:var(--theme-ui-colors-teal-1,#e6fffa);--theme-ui-colors-teal-2:var(--theme-ui-colors-teal-2,#b2f5ea);--theme-ui-colors-teal-3:var(--theme-ui-colors-teal-3,#81e6d9);--theme-ui-colors-teal-4:var(--theme-ui-colors-teal-4,#4fd1c5);--theme-ui-colors-teal-5:var(--theme-ui-colors-teal-5,#38b2ac);--theme-ui-colors-teal-6:var(--theme-ui-colors-teal-6,#319795);--theme-ui-colors-teal-7:var(--theme-ui-colors-teal-7,#2c7a7b);--theme-ui-colors-teal-8:var(--theme-ui-colors-teal-8,#285e61);--theme-ui-colors-teal-9:var(--theme-ui-colors-teal-9,#234e52);--theme-ui-colors-blue-0:var(--theme-ui-colors-blue-0,null);--theme-ui-colors-blue-1:var(--theme-ui-colors-blue-1,#ebf8ff);--theme-ui-colors-blue-2:var(--theme-ui-colors-blue-2,#bee3f8);--theme-ui-colors-blue-3:var(--theme-ui-colors-blue-3,#90cdf4);--theme-ui-colors-blue-4:var(--theme-ui-colors-blue-4,#63b3ed);--theme-ui-colors-blue-5:var(--theme-ui-colors-blue-5,#4299e1);--theme-ui-colors-blue-6:var(--theme-ui-colors-blue-6,#3182ce);--theme-ui-colors-blue-7:var(--theme-ui-colors-blue-7,#2b6cb0);--theme-ui-colors-blue-8:var(--theme-ui-colors-blue-8,#2c5282);--theme-ui-colors-blue-9:var(--theme-ui-colors-blue-9,#2a4365);--theme-ui-colors-indigo-0:var(--theme-ui-colors-indigo-0,null);--theme-ui-colors-indigo-1:var(--theme-ui-colors-indigo-1,#ebf4ff);--theme-ui-colors-indigo-2:var(--theme-ui-colors-indigo-2,#c3dafe);--theme-ui-colors-indigo-3:var(--theme-ui-colors-indigo-3,#a3bffa);--theme-ui-colors-indigo-4:var(--theme-ui-colors-indigo-4,#7f9cf5);--theme-ui-colors-indigo-5:var(--theme-ui-colors-indigo-5,#667eea);--theme-ui-colors-indigo-6:var(--theme-ui-colors-indigo-6,#5a67d8);--theme-ui-colors-indigo-7:var(--theme-ui-colors-indigo-7,#4c51bf);--theme-ui-colors-indigo-8:var(--theme-ui-colors-indigo-8,#434190);--theme-ui-colors-indigo-9:var(--theme-ui-colors-indigo-9,#3c366b);--theme-ui-colors-purple-0:var(--theme-ui-colors-purple-0,null);--theme-ui-colors-purple-1:var(--theme-ui-colors-purple-1,#faf5ff);--theme-ui-colors-purple-2:var(--theme-ui-colors-purple-2,#e9d8fd);--theme-ui-colors-purple-3:var(--theme-ui-colors-purple-3,#d6bcfa);--theme-ui-colors-purple-4:var(--theme-ui-colors-purple-4,#b794f4);--theme-ui-colors-purple-5:var(--theme-ui-colors-purple-5,#9f7aea);--theme-ui-colors-purple-6:var(--theme-ui-colors-purple-6,#805ad5);--theme-ui-colors-purple-7:var(--theme-ui-colors-purple-7,#6b46c1);--theme-ui-colors-purple-8:var(--theme-ui-colors-purple-8,#553c9a);--theme-ui-colors-purple-9:var(--theme-ui-colors-purple-9,#44337a);--theme-ui-colors-pink-0:var(--theme-ui-colors-pink-0,null);--theme-ui-colors-pink-1:var(--theme-ui-colors-pink-1,#fff5f7);--theme-ui-colors-pink-2:var(--theme-ui-colors-pink-2,#fed7e2);--theme-ui-colors-pink-3:var(--theme-ui-colors-pink-3,#fbb6ce);--theme-ui-colors-pink-4:var(--theme-ui-colors-pink-4,#f687b3);--theme-ui-colors-pink-5:var(--theme-ui-colors-pink-5,#ed64a6);--theme-ui-colors-pink-6:var(--theme-ui-colors-pink-6,#d53f8c);--theme-ui-colors-pink-7:var(--theme-ui-colors-pink-7,#b83280);--theme-ui-colors-pink-8:var(--theme-ui-colors-pink-8,#97266d);--theme-ui-colors-pink-9:var(--theme-ui-colors-pink-9,#702459);--theme-ui-colors-grayDark:var(--theme-ui-colors-grayDark,#2d3748);--theme-ui-colors-text:var(--theme-ui-colors-text,#2d3748);--theme-ui-colors-background:var(--theme-ui-colors-background,#fff);--theme-ui-colors-primary:var(--theme-ui-colors-primary,#6b46c1);--theme-ui-colors-primaryHover:var(--theme-ui-colors-primaryHover,#2c5282);--theme-ui-colors-secondary:var(--theme-ui-colors-secondary,#5f6c80);--theme-ui-colors-muted:var(--theme-ui-colors-muted,#e2e8f0);--theme-ui-colors-success:var(--theme-ui-colors-success,#9ae6b4);--theme-ui-colors-info:var(--theme-ui-colors-info,#63b3ed);--theme-ui-colors-warning:var(--theme-ui-colors-warning,#faf089);--theme-ui-colors-danger:var(--theme-ui-colors-danger,#feb2b2);--theme-ui-colors-light:var(--theme-ui-colors-light,#f7fafc);--theme-ui-colors-dark:var(--theme-ui-colors-dark,#2d3748);--theme-ui-colors-textMuted:var(--theme-ui-colors-textMuted,#718096);--theme-ui-colors-toggleIcon:var(--theme-ui-colors-toggleIcon,#2d3748);--theme-ui-colors-heading:var(--theme-ui-colors-heading,#000);--theme-ui-colors-divide:var(--theme-ui-colors-divide,#cbd5e0);color:var(--theme-ui-colors-text,var(--theme-ui-colors-text,#2d3748));background-color:var(--theme-ui-colors-background,var(--theme-ui-colors-background,#fff));}body.theme-ui-dark{--theme-ui-colors-text:var(--theme-ui-colors-modes-dark-text,#cbd5e0);--theme-ui-colors-primary:var(--theme-ui-colors-modes-dark-primary,#9f7aea);--theme-ui-colors-secondary:var(--theme-ui-colors-modes-dark-secondary,#7f8ea3);--theme-ui-colors-toggleIcon:var(--theme-ui-colors-modes-dark-toggleIcon,#cbd5e0);--theme-ui-colors-background:var(--theme-ui-colors-modes-dark-background,#1A202C);--theme-ui-colors-heading:var(--theme-ui-colors-modes-dark-heading,#fff);--theme-ui-colors-divide:var(--theme-ui-colors-modes-dark-divide,#2d3748);--theme-ui-colors-muted:var(--theme-ui-colors-modes-dark-muted,#2d3748);}&lt;/style&gt;&lt;style data-emotion-css=&quot;1gtwvjp&quot;&gt;.css-1gtwvjp{border-left-color:var(--theme-ui-colors-primary,#6b46c1);border-left-style:solid;border-left-width:6px;margin-left:0;margin-right:0;padding-left:2rem;}.css-1gtwvjp p{font-style:italic;}&lt;/style&gt;&lt;blockquote class=&quot;css-1gtwvjp&quot;&gt;&lt;style data-emotion-css=&quot;1bkk5q4&quot;&gt;.css-1bkk5q4{font-size:1rem;-webkit-letter-spacing:-0.003em;-moz-letter-spacing:-0.003em;-ms-letter-spacing:-0.003em;letter-spacing:-0.003em;line-height:1.625;--baseline-multiplier:0.179;--x-height-multiplier:0.35;}@media screen and (min-width:640px){.css-1bkk5q4{font-size:1rem;}}@media screen and (min-width:768px){.css-1bkk5q4{font-size:1.25rem;}}&lt;/style&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;This blog post is based on the work done by &lt;style data-emotion-css=&quot;1od09yo&quot;&gt;.css-1od09yo{color:var(--theme-ui-colors-primary,#6b46c1);-webkit-text-decoration:none;text-decoration:none;}.css-1od09yo:hover{-webkit-text-decoration:underline;text-decoration:underline;}&lt;/style&gt;&lt;a href=&quot;https://github.com/AnirudhDagar&quot; class=&quot;css-1od09yo&quot;&gt;Anirudh Dagar&lt;/a&gt; as an intern at
Vernacular.ai&lt;/p&gt;&lt;/blockquote&gt;&lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position:relative;display:block;margin-left:auto;margin-right:auto;max-width:711px&quot;&gt;
      &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom:64.99999999999999%;position:relative;bottom:0;left:0;background-image:url(&amp;#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAACp0lEQVQ4y1WTyW7TUBSG8x5s2MAKicdgw7JPwHMgISFYwAOwoytEJVQaOqBUVUuTCpJmbpqEZnImO3ZsZ56ciXzca5TQLH6f6+Nzz/3P/X97ptMxazjOaAvlUgOlqGHoNk3DxrbaW9/Xe+738NxPyji5h+ODGB8/XPLdG+Py7JZoKMdkMhS1suEQZzLY2ivhuc9uOZ/A0mEl4nTUpVGtYqgCRgO9adHpD2iImCuU6A2GrIDZfLrFcsNwJqLaapHWLQGT/XM/oYJCqqbRaeuoOT/ZyDG310dY1QhGOYxR+knXrjOdOf8ZysdYABbsRrI8F2Pu7AV49n6XnYMwL05SpOKnHL5+zJeXDzl584hvb59w8u4pX189IBv6zPwP7vgbhuPxANtuohsaSqVMLv+bcDRMpapQrVfo9dtUNJWarpLN3mA16vR0Daus4Izl6MvNtXlmswmtlklUNEgkoiQFopFrYuI9lUqIdYhCMU+i3OS2aqKoBvpNBi2ZRk+k0ZQSJaXAcNBF9vKsL3SxmLoJifnCwbJ0UZgXrFVMs4FaK7loNGq02xZ226TTawnBNMrlEsNhb1sUaYe5ULei1DnzBfGdBNj7dMSh94KD/TOUUpXVav7vwLmzwXI5E/mFu96IIhV2IYot2yaeyBC4uiYaT5PNFIlFUlimKaZwXBby8DUJyazf77hx48PeeERrOGQiLngpvGbXa1hKmWXTFp50hAOWjEY9crk7rq784r4jXFycEwqFiMdj4j1KMBhEUYp4RpMR0bpJWLUwDWHeqyTtQJLurzSddJGuppO9y5DJpLi8/IHX68Xn87nw+/0EAgFOT0/dfD5/h2csaDetJrZQWqrdkmtDxzYN2v0WTSGIISwix6vXqy4LKYIq/iBd2EjTaq4wcmxZ8xcNWrGMYgiupQAAAABJRU5ErkJggg==&amp;#x27;);background-size:cover;display:block&quot;&gt;&lt;/span&gt;
  &lt;img class=&quot;gatsby-resp-image-image css-0&quot; alt=&quot;Can&amp;#x27;t See? Something went wrong!&quot; title=&quot;Can&amp;#x27;t See? Something went wrong!&quot; src=&quot;/ml/static/6790fa68bbb7e4d7b9b0e169877242f1/76a04/speaker_diarization_vernacular.png&quot; srcSet=&quot;/ml/static/6790fa68bbb7e4d7b9b0e169877242f1/5243c/speaker_diarization_vernacular.png 240w,/ml/static/6790fa68bbb7e4d7b9b0e169877242f1/ab158/speaker_diarization_vernacular.png 480w,/ml/static/6790fa68bbb7e4d7b9b0e169877242f1/76a04/speaker_diarization_vernacular.png 711w&quot; sizes=&quot;(max-width: 711px) 100vw, 711px&quot; style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0&quot; loading=&quot;lazy&quot;/&gt;
    &lt;/span&gt;&lt;style data-emotion-css=&quot;1cr8ha5&quot;&gt;.css-1cr8ha5{font-family:inherit;font-weight:700;line-height:1.25;margin:0;margin-bottom:0.25rem;font-size:2.25rem;margin-top:0.5rem;color:var(--theme-ui-colors-heading,#000);}@media screen and (min-width:640px){.css-1cr8ha5{font-size:3rem;}}@media screen and (min-width:768px){.css-1cr8ha5{font-size:4rem;}}&lt;/style&gt;&lt;h1 class=&quot;css-1cr8ha5&quot;&gt;Contents&lt;/h1&gt;&lt;style data-emotion-css=&quot;15rlv7r&quot;&gt;.css-15rlv7r li{font-size:1rem;-webkit-letter-spacing:-0.003em;-moz-letter-spacing:-0.003em;-ms-letter-spacing:-0.003em;letter-spacing:-0.003em;line-height:1.625;--baseline-multiplier:0.179;--x-height-multiplier:0.35;}@media screen and (min-width:640px){.css-15rlv7r li{font-size:1rem;}}@media screen and (min-width:768px){.css-15rlv7r li{font-size:1.25rem;}}&lt;/style&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;a href=&quot;#intro&quot; class=&quot;css-1od09yo&quot;&gt;Diarization Introduction&lt;/a&gt; &lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;a href=&quot;#motivation&quot; class=&quot;css-1od09yo&quot;&gt;Motivation&lt;/a&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;a href=&quot;#dihard&quot; class=&quot;css-1od09yo&quot;&gt;DIHARD?&lt;/a&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;a href=&quot;#approach&quot; class=&quot;css-1od09yo&quot;&gt;Approaching the Problem&lt;/a&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;a href=&quot;#define&quot; class=&quot;css-1od09yo&quot;&gt;Defining Our Problem&lt;/a&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;a href=&quot;#method&quot; class=&quot;css-1od09yo&quot;&gt;Method&lt;/a&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;a href=&quot;#metric&quot; class=&quot;css-1od09yo&quot;&gt;Evaluation Metrics&lt;/a&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;a href=&quot;#resegmentation&quot; class=&quot;css-1od09yo&quot;&gt;Resegmentation&lt;/a&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;a href=&quot;#uis-rnn&quot; class=&quot;css-1od09yo&quot;&gt;UIS-RNN&lt;/a&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;a href=&quot;#simulated_data_gen&quot; class=&quot;css-1od09yo&quot;&gt;Simulated Data Generation&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;style data-emotion-css=&quot;1ldi06f&quot;&gt;.css-1ldi06f{background-color:var(--theme-ui-colors-muted,#e2e8f0);border:0;height:1px;margin:1rem;}&lt;/style&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;style data-emotion-css=&quot;1slx2ud&quot;&gt;.css-1slx2ud{font-family:inherit;font-weight:700;line-height:1.25;margin:0;margin-bottom:0.25rem;font-size:1.25rem;color:var(--theme-ui-colors-heading,#000);}@media screen and (min-width:640px){.css-1slx2ud{font-size:1.5rem;}}@media screen and (min-width:768px){.css-1slx2ud{font-size:1.875rem;}}&lt;/style&gt;&lt;h4 class=&quot;css-1slx2ud&quot;&gt;&lt;a name=&quot;intro&quot; class=&quot;css-1od09yo&quot;&gt;&lt;/a&gt; Diarization Introduction - Who spoke when?&lt;/h4&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Speaker diarisation (or diarization) is the process of partitioning an input audio stream into homogeneous segments according to the speaker identity.&lt;/p&gt;&lt;blockquote class=&quot;css-1gtwvjp&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Speaker diarization is the process of recognizing “who spoke when.” &lt;/p&gt;&lt;/blockquote&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;In an audio conversation with multiple speakers (phone calls, conference calls, dialogs etc.), the Diarization API identifies the speaker at precisely the time they spoke during the conversation.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Below is an example audio from calls recorded at a customer care center, where the agent is involved in a one-to-one dialog with the customer.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;This can be particularly hard sometimes as we&amp;#x27;ll discuss later in the blog. Just to give an example, this audio below seems to have a lot of background talking and noise making it difficult even for a human to accurately understand speaker timestamps.&lt;/p&gt;&lt;audio controls=&quot;&quot;&gt;&lt;source src=&quot;https://vai-diarization.s3.ap-south-1.amazonaws.com/1573539785.2420125.002.wav&quot;/&gt;&lt;/audio&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Below we have an example of an audio along with its transcription and speech timestamp tags.&lt;/p&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;audio controls=&quot;&quot;&gt;&lt;source src=&quot;https://vai-diarization.s3.ap-south-1.amazonaws.com/1573539792.52506.003.wav&quot;/&gt;&lt;/audio&gt;&lt;br/&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Transcription&lt;/strong&gt;: &amp;quot;Barbeque nation mei naa wo book kia tha ok table book kia tha han toh abhi na uske baad ek phone aaya tha toh wo barbeque nation se hi phone aaya tha mai receive nhi kar paaya toh yehi&amp;quot;&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Diarization Tag&lt;/strong&gt;: AGENT: [(0, 5.376), (8.991, 12.213)], CUSTOMER: [(6.951, 7.554)]&lt;/p&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;style data-emotion-css=&quot;1g1owk0&quot;&gt;.css-1g1owk0{font-family:inherit;font-weight:700;line-height:1.25;margin:0;margin-bottom:0.25rem;font-size:1rem;color:var(--theme-ui-colors-heading,#000);}@media screen and (min-width:640px){.css-1g1owk0{font-size:1.25rem;}}@media screen and (min-width:768px){.css-1g1owk0{font-size:1.5rem;}}&lt;/style&gt;&lt;h5 class=&quot;css-1g1owk0&quot;&gt;What Diarization is NOT ?&lt;/h5&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;There is a fine line between speaker diarization and other related speech processing tasks.&lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Diarization != Speaker Change Detection&lt;/strong&gt; : Diarization systems spit a label, whenever a new speaker appears and if the same speaker comes again, it provides the same label. However, in speaker change detection no such labels are given, only the boundary of change is considered for prediction.&lt;/p&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Diarization != Speaker Identification&lt;/strong&gt; : The goal is not to learn the voice prints of any known speaker. Speakers&amp;#x27; are not registered before running the model.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;style data-emotion-css=&quot;1u9n620&quot;&gt;.css-1u9n620{font-family:inherit;font-weight:700;line-height:1.25;margin:0;margin-bottom:0.25rem;font-size:1.5rem;margin-top:1rem;color:var(--theme-ui-colors-heading,#000);}@media screen and (min-width:640px){.css-1u9n620{font-size:1.875rem;}}@media screen and (min-width:768px){.css-1u9n620{font-size:2.25rem;}}&lt;/style&gt;&lt;h3 class=&quot;css-1u9n620&quot;&gt;&lt;a name=&quot;motivation&quot; class=&quot;css-1od09yo&quot;&gt;&lt;/a&gt; Motivation?&lt;/h3&gt;&lt;figure&gt;
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position:relative;display:block;margin-left:auto;margin-right:auto;max-width:711px&quot;&gt;
      &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom:64.99999999999999%;position:relative;bottom:0;left:0;background-image:url(&amp;#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAACp0lEQVQ4y1WTyW7TUBSG8x5s2MAKicdgw7JPwHMgISFYwAOwoytEJVQaOqBUVUuTCpJmbpqEZnImO3ZsZ56ciXzca5TQLH6f6+Nzz/3P/X97ptMxazjOaAvlUgOlqGHoNk3DxrbaW9/Xe+738NxPyji5h+ODGB8/XPLdG+Py7JZoKMdkMhS1suEQZzLY2ivhuc9uOZ/A0mEl4nTUpVGtYqgCRgO9adHpD2iImCuU6A2GrIDZfLrFcsNwJqLaapHWLQGT/XM/oYJCqqbRaeuoOT/ZyDG310dY1QhGOYxR+knXrjOdOf8ZysdYABbsRrI8F2Pu7AV49n6XnYMwL05SpOKnHL5+zJeXDzl584hvb59w8u4pX189IBv6zPwP7vgbhuPxANtuohsaSqVMLv+bcDRMpapQrVfo9dtUNJWarpLN3mA16vR0Daus4Izl6MvNtXlmswmtlklUNEgkoiQFopFrYuI9lUqIdYhCMU+i3OS2aqKoBvpNBi2ZRk+k0ZQSJaXAcNBF9vKsL3SxmLoJifnCwbJ0UZgXrFVMs4FaK7loNGq02xZ226TTawnBNMrlEsNhb1sUaYe5ULei1DnzBfGdBNj7dMSh94KD/TOUUpXVav7vwLmzwXI5E/mFu96IIhV2IYot2yaeyBC4uiYaT5PNFIlFUlimKaZwXBby8DUJyazf77hx48PeeERrOGQiLngpvGbXa1hKmWXTFp50hAOWjEY9crk7rq784r4jXFycEwqFiMdj4j1KMBhEUYp4RpMR0bpJWLUwDWHeqyTtQJLurzSddJGuppO9y5DJpLi8/IHX68Xn87nw+/0EAgFOT0/dfD5/h2csaDetJrZQWqrdkmtDxzYN2v0WTSGIISwix6vXqy4LKYIq/iBd2EjTaq4wcmxZ8xcNWrGMYgiupQAAAABJRU5ErkJggg==&amp;#x27;);background-size:cover;display:block&quot;&gt;&lt;/span&gt;
  &lt;img class=&quot;gatsby-resp-image-image css-0&quot; alt=&quot;Can&amp;#x27;t See? Something went wrong!&quot; title=&quot;Can&amp;#x27;t See? Something went wrong!&quot; src=&quot;/ml/static/6790fa68bbb7e4d7b9b0e169877242f1/76a04/speaker_diarization_vernacular.png&quot; srcSet=&quot;/ml/static/6790fa68bbb7e4d7b9b0e169877242f1/5243c/speaker_diarization_vernacular.png 240w,/ml/static/6790fa68bbb7e4d7b9b0e169877242f1/ab158/speaker_diarization_vernacular.png 480w,/ml/static/6790fa68bbb7e4d7b9b0e169877242f1/76a04/speaker_diarization_vernacular.png 711w&quot; sizes=&quot;(max-width: 711px) 100vw, 711px&quot; style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0&quot; loading=&quot;lazy&quot;/&gt;
    &lt;/span&gt;
  &lt;figcaption&gt;&lt;b class=&quot;css-0&quot;&gt;&lt;center&gt;Fig 1.: ASR using Diarization tags to understand and segregate transcription.&lt;/center&gt;&lt;/b&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;With the rise of speech recognition systems both in terms of scale and accuracy, the ability to process audio of multiple speakers is crucial and has become quintessential to understand speech today.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;As illustrated in &lt;strong class=&quot;css-0&quot;&gt;Fig 1.&lt;/strong&gt; above, information gained through diarization helps in enriching and improving Spoken Language Understanding (SLU) based on the Automatic Speech Recognition (ASR) transcription. It can enhance the readability of the transcription by structuring the audio stream into speaker turns and, when used together with speaker recognition systems, by providing the speaker’s true identity. This can be valuable for downstream applications such as analytics for call-center transcription and meeting transcription etc.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Other than this, we at &lt;a href=&quot;https://vernacular.ai/&quot; class=&quot;css-1od09yo&quot;&gt;Vernacular.ai&lt;/a&gt; work on &lt;strong class=&quot;css-0&quot;&gt;&lt;em class=&quot;css-0&quot;&gt;Call Center Automation (CCA)&lt;/em&gt;&lt;/strong&gt; among many other speech domains, and, at the very core this is powered by our products &lt;a href=&quot;https://vernacular.ai/viva&quot; class=&quot;css-1od09yo&quot;&gt;VIVA&lt;/a&gt; and &lt;a href=&quot;https://vernacular.ai/vasr&quot; class=&quot;css-1od09yo&quot;&gt;VASR&lt;/a&gt;. Information gained through diarization can be used to strengthen the VASR engine. &lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;How?&lt;/strong&gt;&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Let me explain the goal of every customer care call support service, if you are not already aware of. The ultimate aim is to provide best in class service to the customers of the respective company. Quantitatively, measure of the service quality is based on the assessment of the &lt;em class=&quot;css-0&quot;&gt;AGENT&amp;#x27;s&lt;/em&gt; (Call representative at customer care center) ability to disseminate relevant information to the &lt;em class=&quot;css-0&quot;&gt;CUSTOMER&lt;/em&gt;.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;During the quality check phase, an &lt;em class=&quot;css-0&quot;&gt;AGENT&amp;#x27;s&lt;/em&gt; performance is scored on mutiple parameters, such as (but not limited to):&lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;Whether the agent was patient enough listening to the customer or was rushing on the call&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Whether she/he was rude to the lead at any time or not&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Whether she/he used the proper language to communicate.&lt;/li&gt;&lt;/ul&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;For such occasions, identifying different speakers in a call (&lt;em class=&quot;css-0&quot;&gt;&amp;quot;AGENT&amp;quot;&lt;/em&gt; or &lt;em class=&quot;css-0&quot;&gt;&amp;quot;CUSTOMER&amp;quot;&lt;/em&gt;) and finally connecting different sentences under the same speaker is a critical task for the assessment quality.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Speaker Diarization is the solution for those problems.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Other applications involve&lt;/strong&gt;:&lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;Information retrieval from broadcast news.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Generating notes/minutes of meetings.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Turn-taking analysis of telephone conversations.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Call center Data analysis&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Court houses &amp;amp; Parliaments.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Broadcast News(TV and Radio)&lt;/li&gt;&lt;/ul&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;h3 class=&quot;css-1u9n620&quot;&gt;&lt;a name=&quot;dihard&quot; class=&quot;css-1od09yo&quot;&gt;&lt;/a&gt; DIHARD?&lt;/h3&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;This is not &lt;u&gt;2x2=4&lt;/u&gt;. This is &lt;strong class=&quot;css-0&quot;&gt;Diarization&lt;/strong&gt; and &lt;strong class=&quot;css-0&quot;&gt;&lt;em class=&quot;css-0&quot;&gt;IT IS HARD&lt;/em&gt;&lt;/strong&gt;. One can say that it is one of the toughest ML problems intrinsically high on complexity, even for a human-being, in certain conditions. &lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;But Why???&lt;/strong&gt;&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Real world audios are not always &lt;em class=&quot;css-0&quot;&gt;sunshine and rainbows&lt;/em&gt;. They come with infinite complexities.
To name a few:&lt;/p&gt;&lt;ol class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;In most of the conversations, people will interrupt each other, overtalk etc., and, cutting the audio between sentences won’t be a trivial task due to this highly interactive nature.&lt;/p&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Speakers are discovered dynamically. Although as you&amp;#x27;ll see later, in our case we only have 2 speakers, a fixed number.&lt;/p&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Sometimes the &lt;strong class=&quot;css-0&quot;&gt;audio is noisy&lt;/strong&gt;:&lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;People &lt;strong class=&quot;css-0&quot;&gt;talking&lt;/strong&gt; in the &lt;strong class=&quot;css-0&quot;&gt;background&lt;/strong&gt;.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;The microphone picking up speakers&amp;#x27; &lt;strong class=&quot;css-0&quot;&gt;environment noises&lt;/strong&gt; (roadside noises, industrial machinery noise, music in the background etc.).&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;For telephony based audios, &lt;strong class=&quot;css-0&quot;&gt;connection may be weak&lt;/strong&gt; at times, leading to:&lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;Audio being &lt;strong class=&quot;css-0&quot;&gt;dropped/corrupted&lt;/strong&gt; in some parts.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Static&lt;/strong&gt;  or just some &lt;strong class=&quot;css-0&quot;&gt;buzzing&lt;/strong&gt; noise creeping in the conversation and finding it&amp;#x27;s way into the audio recording.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Believe me&lt;/strong&gt;, this is not the end of many problems for diarization!&lt;/p&gt;&lt;ol start=&quot;5&quot; class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;Maybe in a conference call with multiple speakers, even if the audio is clear, the &lt;strong class=&quot;css-0&quot;&gt;difference can be very subtle&lt;/strong&gt; between the speakers, and it is not always possible to identify/label the correct speaker for a particular timestamp/duration. &lt;/li&gt;&lt;/ol&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Ok, so that&amp;#x27;s it?&lt;/strong&gt;&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;If I have not made my point clear about the complexity of the problem, yet, then I&amp;#x27;ll express my message through this legendary meme.&lt;/p&gt;&lt;figure&gt;
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position:relative;display:block;margin-left:auto;margin-right:auto;max-width:648px&quot;&gt;
      &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom:56.25%;position:relative;bottom:0;left:0;background-image:url(&amp;#x27;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAQCAwX/xAAWAQEBAQAAAAAAAAAAAAAAAAADAQL/2gAMAwEAAhADEAAAAU2qHCWRkGL/AP/EABoQAAMAAwEAAAAAAAAAAAAAAAACAwEEERL/2gAIAQEAAQUCnRhn8t1WNTHSsZrM/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAEREv/aAAgBAwEBPwGpGj//xAAWEQEBAQAAAAAAAAAAAAAAAAAAERL/2gAIAQIBAT8BlYf/xAAdEAACAQQDAAAAAAAAAAAAAAAAARECECIxMkGR/9oACAEBAAY/At4o5Ykz4Q9Dap6t/8QAGxABAQEAAgMAAAAAAAAAAAAAAREAIUFxscH/2gAIAQEAAT8hTI6czGbdDB97sBfLE5VPzAaEo03/2gAMAwEAAgADAAAAEHj/AP/EABgRAAMBAQAAAAAAAAAAAAAAAAABESFx/9oACAEDAQE/EJI1rOT/xAAZEQACAwEAAAAAAAAAAAAAAAAAAREhMXH/2gAIAQIBAT8Qm20jo//EABwQAQEAAgIDAAAAAAAAAAAAAAERACFBUTGBsf/aAAgBAQABPxCOlBqAHzHIbLg0PFTe8Uz0AB7e8TiRon1xhKTpVjTtxFz/2Q==&amp;#x27;);background-size:cover;display:block&quot;&gt;&lt;/span&gt;
  &lt;img class=&quot;gatsby-resp-image-image css-0&quot; alt=&quot;Can&amp;#x27;t See? Something went wrong!&quot; title=&quot;Can&amp;#x27;t See? Something went wrong!&quot; src=&quot;/ml/static/411499dae7959f9f0715210b35ddbefc/1f16e/diarization_hard.jpg&quot; srcSet=&quot;/ml/static/411499dae7959f9f0715210b35ddbefc/46946/diarization_hard.jpg 240w,/ml/static/411499dae7959f9f0715210b35ddbefc/55489/diarization_hard.jpg 480w,/ml/static/411499dae7959f9f0715210b35ddbefc/1f16e/diarization_hard.jpg 648w&quot; sizes=&quot;(max-width: 648px) 100vw, 648px&quot; style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0&quot; loading=&quot;lazy&quot;/&gt;
    &lt;/span&gt;
  &lt;figcaption&gt;&lt;b class=&quot;css-0&quot;&gt;&lt;center&gt;Fig 2.: Diarization is hard!&lt;/center&gt;&lt;/b&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;More Problems?&lt;/strong&gt;&lt;/p&gt;&lt;ol start=&quot;6&quot; class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;All the problems stated above are considering that preprocessing steps like VAD/SAD worked perfectly, which you may have guessed, are obviously not 100% accurate.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;What is this &lt;strong class=&quot;css-0&quot;&gt;&amp;quot;preprocessing step&amp;quot;&lt;/strong&gt;?&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Voice Activity Detection (VAD) or Speech Activity Detection (SAD) is a widely used audio preprocessing technique, before running a typical diariaztion api based on the clustering of speaker embeddings. The objective of VAD/SAD is to get rid of all non-speech regions.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;h3 class=&quot;css-1u9n620&quot;&gt;&lt;a name=&quot;approach&quot; class=&quot;css-1od09yo&quot;&gt;&lt;/a&gt; Approaching the problem&lt;/h3&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Keeping in mind the complexity and hardness of the problem, multiple approaches have been devised over the years to tackle diarization. Some earlier approaches were based on Hidden Markov Models (HMMs)/ Gaussian Mixture Models (GMMs). More recently, Neural Embedding (x-vectors/d-vectors) + Clustering and End2End Neural methods have demonstrated their power.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;As stated in &lt;a href=&quot;https://arxiv.org/pdf/1909.06247.pdf&quot; class=&quot;css-1od09yo&quot;&gt;this&lt;/a&gt; paper by Fujita et al., a x-vector/d-vector clustering-based system is commonly used for speaker diarization and most of our experiments are based around this approach.&lt;/p&gt;&lt;figure&gt;
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position:relative;display:block;margin-left:auto;margin-right:auto;max-width:960px&quot;&gt;
      &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom:52.916666666666664%;position:relative;bottom:0;left:0;background-image:url(&amp;#x27;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe6qC2D/xAAXEAADAQAAAAAAAAAAAAAAAAAAARIg/9oACAEBAAEFAqyj/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFhAAAwAAAAAAAAAAAAAAAAAAASAx/9oACAEBAAY/AoW//8QAGxAAAQQDAAAAAAAAAAAAAAAAAQARITEQQaH/2gAIAQEAAT8hDi3BOd1kzBVF/9oADAMBAAIAAwAAABBjD//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABsQAQACAgMAAAAAAAAAAAAAAAEAESExEEFh/9oACAEBAAE/ECMBfbQgCOBNwbLOMTkJu8Z//9k=&amp;#x27;);background-size:cover;display:block&quot;&gt;&lt;/span&gt;
  &lt;img class=&quot;gatsby-resp-image-image css-0&quot; alt=&quot;Can&amp;#x27;t See? Something went wrong!&quot; title=&quot;Can&amp;#x27;t See? Something went wrong!&quot; src=&quot;/ml/static/b0953ef725f55cde8323b0f4848e0cef/18e3b/diarization_clustering.jpg&quot; srcSet=&quot;/ml/static/b0953ef725f55cde8323b0f4848e0cef/46946/diarization_clustering.jpg 240w,/ml/static/b0953ef725f55cde8323b0f4848e0cef/55489/diarization_clustering.jpg 480w,/ml/static/b0953ef725f55cde8323b0f4848e0cef/18e3b/diarization_clustering.jpg 960w,/ml/static/b0953ef725f55cde8323b0f4848e0cef/86f92/diarization_clustering.jpg 1325w&quot; sizes=&quot;(max-width: 960px) 100vw, 960px&quot; style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0&quot; loading=&quot;lazy&quot;/&gt;
    &lt;/span&gt;
  &lt;figcaption&gt;&lt;b class=&quot;css-0&quot;&gt;&lt;center&gt;Fig 3.: The image shows the cluster generated based on the speech pattern and precise time the speaker participated in the conversation.&lt;/center&gt;&lt;/b&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;The aim of speaker clustering is to put together all the segments that belong to the same acoustic source in a recording. These don&amp;#x27;t utilize any prior information of the speaker ID or the number of speakers in the recording. We&amp;#x27;ll be covering a typical embedding-clustering based approach in detail in the latter sections of the blog.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;However, speaker diarization systems which combine the two tasks in a unified framework are gaining popularity in recent times. &lt;strong class=&quot;css-0&quot;&gt;Fig 4&lt;/strong&gt; visually summarizes the End2End idea. Due to the increased amounts of data being avaialable, joint End2End modeling methods are slowly taking over older approaches across ML domains, alleviating the complex preparation processes involved earlier.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;One example is &lt;strong class=&quot;css-0&quot;&gt;&lt;em class=&quot;css-0&quot;&gt;&lt;a href=&quot;https://arxiv.org/abs/1909.06247&quot; class=&quot;css-1od09yo&quot;&gt;EEND: End2End Neural Diarization&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt; by Fujita et al. proposed recently showing some promise in regards to solving these complex steps jointly.&lt;/p&gt;&lt;figure&gt;
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position:relative;display:block;margin-left:auto;margin-right:auto;max-width:637px&quot;&gt;
      &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom:33.75%;position:relative;bottom:0;left:0;background-image:url(&amp;#x27;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAHABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAIF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB3oCwf//EABYQAQEBAAAAAAAAAAAAAAAAAAAhAf/aAAgBAQABBQKsV//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABUQAQEAAAAAAAAAAAAAAAAAABAx/9oACAEBAAY/Ao//xAAZEAACAwEAAAAAAAAAAAAAAAAAARExUfH/2gAIAQEAAT8hnoO6snCP/9oADAMBAAIAAwAAABBwD//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABoQAAICAwAAAAAAAAAAAAAAAAEhABExYYH/2gAIAQEAAT8Q0IaBrtnEDbF2f//Z&amp;#x27;);background-size:cover;display:block&quot;&gt;&lt;/span&gt;
  &lt;img class=&quot;gatsby-resp-image-image css-0&quot; alt=&quot;Can&amp;#x27;t See? Something went wrong!&quot; title=&quot;Can&amp;#x27;t See? Something went wrong!&quot; src=&quot;/ml/static/0f5c773e8a5432d2c2d4489de1a698e1/60f36/EEND.jpg&quot; srcSet=&quot;/ml/static/0f5c773e8a5432d2c2d4489de1a698e1/46946/EEND.jpg 240w,/ml/static/0f5c773e8a5432d2c2d4489de1a698e1/55489/EEND.jpg 480w,/ml/static/0f5c773e8a5432d2c2d4489de1a698e1/60f36/EEND.jpg 637w&quot; sizes=&quot;(max-width: 637px) 100vw, 637px&quot; style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0&quot; loading=&quot;lazy&quot;/&gt;
    &lt;/span&gt;
  &lt;figcaption&gt;&lt;b class=&quot;css-0&quot;&gt;&lt;center&gt;Fig 4.: An End to End approach diarization system.&lt;/center&gt;&lt;/b&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;h3 class=&quot;css-1u9n620&quot;&gt;&lt;a name=&quot;define&quot; class=&quot;css-1od09yo&quot;&gt;&lt;/a&gt; Defining Our Problem&lt;/h3&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;We need to answer the question &lt;em class=&quot;css-0&quot;&gt;&amp;quot;What should be a robust diarization system?&amp;quot;&lt;/em&gt; before moving forward. We decided to try out multiple approaches and model experiments explained in the sections below.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Our model should be powerful enough to capture global speaker characteristics in addition to local speech activity dynamics.
A systems, that is able to accurately handle &lt;strong class=&quot;css-0&quot;&gt;highly interactive&lt;/strong&gt; and &lt;strong class=&quot;css-0&quot;&gt;overlapping speech&lt;/strong&gt; specifically in the telephony call audios conversational domain, while being resilient to variation in mobile microphones, recording environment, reverberation, ambient noise, speaker demographics. Since we have a more focused problem, for evaluating customer care center call audios, the number of speakers for our use case is fixed at two i.e &amp;quot;AGENT&amp;quot; and &amp;quot;CUSTOMER&amp;quot; for each call, we need to tune our model for the same.&lt;/p&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;h3 class=&quot;css-1u9n620&quot;&gt;&lt;a name=&quot;method&quot; class=&quot;css-1od09yo&quot;&gt;&lt;/a&gt; Method&lt;/h3&gt;&lt;figure&gt;
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position:relative;display:block;margin-left:auto;margin-right:auto;max-width:960px&quot;&gt;
      &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom:19.166666666666664%;position:relative;bottom:0;left:0;background-image:url(&amp;#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABcSAAAXEgFnn9JSAAAAqUlEQVQY022P2wqEMAxE/f8/6ZN/0gdBpWC9Q71bQVDwMpIsfVh3B0IGcjIkHl66rgv3fbPf9x1hGEJKiXVdfxhXTuQ93/dRVRWapkFd17xIPcsyLMuCsix5bq2F1hppmmKeZ/R9j3EcmaF5URTYtg2eEIJBF0iwUgpRFGGaJobzPMcwDEiShNm2bbm6rmOGwo0xn8D3y3S2e+k8T8RxjCAIcBzHF/PPkx7Eci+mJ4wOoAAAAABJRU5ErkJggg==&amp;#x27;);background-size:cover;display:block&quot;&gt;&lt;/span&gt;
  &lt;img class=&quot;gatsby-resp-image-image css-0&quot; alt=&quot;Can&amp;#x27;t See? Something went wrong!&quot; title=&quot;Can&amp;#x27;t See? Something went wrong!&quot; src=&quot;/ml/static/d55bc75c1898ac3e97f1fe28ea3d1834/7d769/diarization_pipeline.png&quot; srcSet=&quot;/ml/static/d55bc75c1898ac3e97f1fe28ea3d1834/5243c/diarization_pipeline.png 240w,/ml/static/d55bc75c1898ac3e97f1fe28ea3d1834/ab158/diarization_pipeline.png 480w,/ml/static/d55bc75c1898ac3e97f1fe28ea3d1834/7d769/diarization_pipeline.png 960w,/ml/static/d55bc75c1898ac3e97f1fe28ea3d1834/acdd1/diarization_pipeline.png 1150w&quot; sizes=&quot;(max-width: 960px) 100vw, 960px&quot; style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0&quot; loading=&quot;lazy&quot;/&gt;
    &lt;/span&gt;
  &lt;figcaption&gt;&lt;b class=&quot;css-0&quot;&gt;&lt;center&gt;Fig 5.: A typical diarization pipeline.&lt;/center&gt;&lt;/b&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;VAD&lt;/strong&gt; — We employ &lt;a href=&quot;https://github.com/wiseman/py-webrtcvad&quot; class=&quot;css-1od09yo&quot;&gt;WebRTC VAD&lt;/a&gt; to remove noise and non speech regions during our experiments. Raw audios are split into frames with specific duration (30 ms in our case). For each input frame, WebRTC generates output 1 or 0, where 1 denotes speech and 0 denotes nonspeech. An optional setting of WebRTC is the aggressive mode, an integer between 0 and 3. 0 is the least aggressive about filtering out nonspeech while 3 is the most aggressive. These VAD/SAD models have their own respective struggles with and set of problems.&lt;/li&gt;&lt;/ul&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Embedder&lt;/strong&gt; — &lt;a href=&quot;https://github.com/resemble-ai/Resemblyzer&quot; class=&quot;css-1od09yo&quot;&gt;Resemblyzer&lt;/a&gt; allows you to derive a high-level representation of a voice through a deep learning model (referred to as the voice encoder). Given an audio file of speech, it creates a summary vector of size 256 (embedding) that summarizes the characteristics of the voice spoken.&lt;/p&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Clustering&lt;/strong&gt; — We cluster the segment wise embedding using a simple &lt;strong class=&quot;css-0&quot;&gt;K-Means&lt;/strong&gt; to produce diarization results and determine the number of speakers with each speakers time stamps.&lt;/p&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Resegmentation&lt;/strong&gt; - Finally, an optional supervised classification step may be applied to actually identity every speaker cluster in a supervised way.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;h4 class=&quot;css-1slx2ud&quot;&gt;&lt;a name=&quot;metric&quot; class=&quot;css-1od09yo&quot;&gt;&lt;/a&gt; Evaluation Metrics (Diarization Error Rate)&lt;/h4&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;To evaluate the performance or to estimate the influence of errors on the complete pipeline, we use the standard metrics implemented in &lt;a href=&quot;https://pyannote.github.io/pyannote-metrics/reference.html&quot; class=&quot;css-1od09yo&quot;&gt;&lt;code class=&quot;css-0&quot;&gt;pyannote-metrics&lt;/code&gt;&lt;/a&gt;. We also need to account for the fact that these time-stamps are manually annotated by data-annotators and hence cannot be precise at the audio sample level. It is a common practice in speaker diarization research to remove a fixed collar around each speaker turn boundary from being evaluated using our metric of choice. A 0.4sec collar would exclude 200ms before and after the boundary.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Diarization error rate (DER) is the &lt;strong class=&quot;css-0&quot;&gt;de facto&lt;/strong&gt; standard metric for evaluating and comparing speaker diarization systems. It is measured as the fraction of time that is not attributed correctly to a speaker or non-speech.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;The DER is composed of the following three errors:&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;False Alarm&lt;/strong&gt;: It is the percentage of scored time that a hypothesized speaker is labelled as a non-speech in the reference. The false alarm error occurs mainly due to the the speech/non-speech detection error (i.e., the speech/non-speech detection considers a non-speech segment as a speech segment). Hence, false alarm error is not related to segmentation and clustering errors.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Missed Detection&lt;/strong&gt;: It is the percentage of scored time that a hypothesized non-speech segment corresponds to a reference speaker segment. The missed speech occurs mainly due to the the speech/non-speech detection error (i.e., the speech segment is considered as a non-speech segment). Hence, missed speech is not related to segmentation and clustering errors.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Confusion&lt;/strong&gt;: It is the percentage of scored time that a speaker ID is assigned to the wrong speaker. Confusion error is mainly a diarization system error (i.e., it is not related to speech/non-speech detection.) It also does not take into account the overlap speeches not detected.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;$$
\text{DER} = \frac{\text{false alarm} + \text{missed detection} + \text{confusion}}{\text{total}}
$$&lt;/p&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;h4 class=&quot;css-1slx2ud&quot;&gt;&lt;a name=&quot;resegmentation&quot; class=&quot;css-1od09yo&quot;&gt;&lt;/a&gt; Resegmentation&lt;/h4&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;As stated earlier, speaker diarization consists of automatically partitioning an input audio stream into homogeneous segments (segmentation) and assigning these segments to the same speaker (speaker clustering). Read more about segmentation &lt;a href=&quot;https://pyannote.github.io/pyannote-metrics/reference.html#segmentation&quot; class=&quot;css-1od09yo&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Is it possible to &lt;strong class=&quot;css-0&quot;&gt;resegment&lt;/strong&gt; these assignments, &lt;strong class=&quot;css-0&quot;&gt;post clustering&lt;/strong&gt;, to achieve an improved lower DER?&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;This is exactly the job of a &lt;em class=&quot;css-0&quot;&gt;resegmentation&lt;/em&gt; module. Simply put, we had a condition to be improved, a difficulty to be eliminated, and a troubling question that existed.&lt;/p&gt;&lt;blockquote class=&quot;css-1gtwvjp&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;If yes, in what scenarios this optional (Resegmentation) module helps?&lt;/p&gt;&lt;/blockquote&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Before going ahead with resegmentation, we needed meaningful understanding and deliberate investigation of the predictions to answer the above question.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;We brainstormed on this particular section involving post-processing of predictions in the diarization pipeline. After analysis and comparisons of predicted annotations made to the true annotations, our system, though good (with DER=0.05), was possibly facing an issue.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;We were hit by something called &lt;code class=&quot;css-0&quot;&gt;oversegmentation&lt;/code&gt;, which can be seen in figure 6 below.&lt;/p&gt;&lt;figure&gt;
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position:relative;display:block;margin-left:auto;margin-right:auto;max-width:960px&quot;&gt;
      &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom:33.33333333333333%;position:relative;bottom:0;left:0;background-image:url(&amp;#x27;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAHABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAdsRAf/EABQQAQAAAAAAAAAAAAAAAAAAABD/2gAIAQEAAQUCf//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABQQAQAAAAAAAAAAAAAAAAAAABD/2gAIAQEABj8Cf//EABkQAAEFAAAAAAAAAAAAAAAAABEAARAhUf/aAAgBAQABPyEXAfF//9oADAMBAAIAAwAAABAIL//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABsQAQACAgMAAAAAAAAAAAAAAAEAMREhUYGh/9oACAEBAAE/EFFG+ZvFPkcuk9k//9k=&amp;#x27;);background-size:cover;display:block&quot;&gt;&lt;/span&gt;
  &lt;img class=&quot;gatsby-resp-image-image css-0&quot; alt=&quot;Can&amp;#x27;t See? Something went wrong!&quot; title=&quot;Can&amp;#x27;t See? Something went wrong!&quot; src=&quot;/ml/static/57066ab89aead8965892d063417ac082/18e3b/resegmentation.jpg&quot; srcSet=&quot;/ml/static/57066ab89aead8965892d063417ac082/46946/resegmentation.jpg 240w,/ml/static/57066ab89aead8965892d063417ac082/55489/resegmentation.jpg 480w,/ml/static/57066ab89aead8965892d063417ac082/18e3b/resegmentation.jpg 960w,/ml/static/57066ab89aead8965892d063417ac082/60e21/resegmentation.jpg 1440w,/ml/static/57066ab89aead8965892d063417ac082/799c0/resegmentation.jpg 1855w&quot; sizes=&quot;(max-width: 960px) 100vw, 960px&quot; style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0&quot; loading=&quot;lazy&quot;/&gt;
    &lt;/span&gt;
  &lt;figcaption&gt;&lt;b class=&quot;css-0&quot;&gt;&lt;center&gt;Fig 6.: Oversegmentation. Need for resegmentation?&lt;/center&gt;&lt;/b&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;To fix this problem and in the process making our system more robust, we tried multiple experiments tweaking the resegmentation module.&lt;/p&gt;&lt;ol class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Standard Smoothing&lt;/strong&gt;: This is a simple annotation post processing &lt;code class=&quot;css-0&quot;&gt;smoothing function&lt;/code&gt; to solve the abrupt annotated segments (oversegmented regions) by merging these items smaller than or equal to the threshold (duration less than 0.2 seconds) with neighbouring annotation. We instantly got a 1% boost in DER (0.04) after smoothing.&lt;/li&gt;&lt;/ol&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Our initial hunch about oversegmentation based on the analysis was now supported by results from this simple exercise. This made us think about a few more questions:&lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;Can we do even better?&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Can we use the labels and supervise the resegmentation module learning this smoothing function at the very least?&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Are there some other errors in the predictions which we may have overlooked, but probably a learned resegmentation model captures?&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Can we leverage clustering confidences to improve the resegmentation module?&lt;/li&gt;&lt;/ul&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Aiming to answer the above questions, we came up with a &lt;em class=&quot;css-0&quot;&gt;Supervised Resegmentation Sequence2Sequence model&lt;/em&gt;.&lt;/p&gt;&lt;ol start=&quot;2&quot; class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Supervised Seq2Seq Resegmentation&lt;/strong&gt;: The goal of the model as shown below is to learn a mapping from the initial predictions to the ground truth sequence based on supervised training.&lt;/p&gt;&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;python&quot;&gt;&lt;pre class=&quot;prism-code language-python&quot; style=&quot;color:#d6deeb;background-color:#011627&quot; data-linenumber=&quot;true&quot;&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;line-number-style&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;Resegmentation Goal&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;line-number-style&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;line-number-style&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;            PREDICTIONS                         GROUND TRUTH&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;line-number-style&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; A&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; A&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; A&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; B&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; A&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; A&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; B&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; B&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; B &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token operator&quot; style=&quot;color:rgb(127, 219, 202)&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token operator&quot; style=&quot;color:rgb(127, 219, 202)&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; A&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; A&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; A&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; A&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; A&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; A&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; B&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; B&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; B &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;line-number-style&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;line-number-style&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;where A &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; Speaker &lt;/span&gt;&lt;span class=&quot;token number&quot; style=&quot;color:rgb(247, 140, 108)&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;line-number-style&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      B &lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; Speaker &lt;/span&gt;&lt;span class=&quot;token number&quot; style=&quot;color:rgb(247, 140, 108)&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; &lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;line-number-style&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;token plain&quot; style=&quot;display:inline-block&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;token-line&quot; style=&quot;color:#d6deeb&quot;&gt;&lt;span class=&quot;line-number-style&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt;      each label represents fixed duration of 400ms &lt;/span&gt;&lt;span class=&quot;token keyword&quot; style=&quot;color:rgb(127, 219, 202)&quot;&gt;in&lt;/span&gt;&lt;span class=&quot;token plain&quot;&gt; our annotations&lt;/span&gt;&lt;span class=&quot;token punctuation&quot; style=&quot;color:rgb(199, 146, 234)&quot;&gt;.&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;To achieve such a mapping we worked on a simple Seq2Seq LSTM based model. We also enriched this model with information of cluster confidences after tweaking our Embedding+Clustering pipeline to do a soft clustering, i.e. return cluster scores based on the distance of each point in the cluster from the centroid along with the clustered predictions.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Overall all the above steps regarding a supervised resegmentation model were completely experimental and based on a few ideas. We are yet to achieve convincing results based on this approach but I thought it would be nice to mention this cool experiment :). Providing more resegmentation sequences for training could definitely and we also try to tackle diarization with limited data. See &lt;a href=&quot;####simulated-data-generation&quot; class=&quot;css-1od09yo&quot;&gt;here&lt;/a&gt;&lt;/p&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;h4 class=&quot;css-1slx2ud&quot;&gt;&lt;a name=&quot;uis-rnn&quot; class=&quot;css-1od09yo&quot;&gt;&lt;/a&gt; UIS-RNN&lt;/h4&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;To explore more supervised methods, we also experimented with &lt;a href=&quot;https://arxiv.org/abs/1810.04719&quot; class=&quot;css-1od09yo&quot;&gt;Fully Supervised Speaker Diarization&lt;/a&gt; or the UIS-RNN model, the current state of the art neural system for Speaker Diarization. Converting data to UIS Style format involves a set of preprocessing steps similar to what we had to for our supervised resegmentation model. More on the official &lt;a href=&quot;https://github.com/google/uis-rnn&quot; class=&quot;css-1od09yo&quot;&gt;UIS-RNN Repo&lt;/a&gt;.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;But a caveat with UIS-RNN is that it requires huge amounts of data to form a convincing hypothesis after training. On realizing the limited amount of tagged data we had, we worked on simulating datasets for Speaker Diarization which in itself comes with some challenges. &lt;/p&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;h4 class=&quot;css-1slx2ud&quot;&gt;&lt;a name=&quot;simulated_data_gen&quot; class=&quot;css-1od09yo&quot;&gt;&lt;/a&gt; Simulated Data Generation&lt;/h4&gt;&lt;figure&gt;
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position:relative;display:block;margin-left:auto;margin-right:auto;max-width:960px&quot;&gt;
      &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom:75%;position:relative;bottom:0;left:0;background-image:url(&amp;#x27;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAdykVFf/xAAZEAACAwEAAAAAAAAAAAAAAAAAARESIQL/2gAIAQEAAQUCb6NgrqVVEH//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAYEAACAwAAAAAAAAAAAAAAAAAQEQABIf/aAAgBAQAGPwLKLiH/xAAbEAEAAwEAAwAAAAAAAAAAAAABABEhQVFxgf/aAAgBAQABPyEiUP2NMFvuF1psQnohgLo8sNq63s//2gAMAwEAAgADAAAAEEgP/8QAFxEBAAMAAAAAAAAAAAAAAAAAARARMf/aAAgBAwEBPxBLNj//xAAWEQADAAAAAAAAAAAAAAAAAAABEBH/2gAIAQIBAT8QFX//xAAcEAEAAwACAwAAAAAAAAAAAAABABEhQcFRcZH/2gAIAQEAAT8QAzG7unqO4fix1HXlTS7mkSznNjkoKFF+sJNOysu9T//Z&amp;#x27;);background-size:cover;display:block&quot;&gt;&lt;/span&gt;
  &lt;img class=&quot;gatsby-resp-image-image css-0&quot; alt=&quot;Can&amp;#x27;t See? Something went wrong!&quot; title=&quot;Can&amp;#x27;t See? Something went wrong!&quot; src=&quot;/ml/static/7bc05ae08733afa6331002fe26497714/18e3b/sim_dia_data_generator_flow.jpg&quot; srcSet=&quot;/ml/static/7bc05ae08733afa6331002fe26497714/46946/sim_dia_data_generator_flow.jpg 240w,/ml/static/7bc05ae08733afa6331002fe26497714/55489/sim_dia_data_generator_flow.jpg 480w,/ml/static/7bc05ae08733afa6331002fe26497714/18e3b/sim_dia_data_generator_flow.jpg 960w,/ml/static/7bc05ae08733afa6331002fe26497714/60e21/sim_dia_data_generator_flow.jpg 1440w,/ml/static/7bc05ae08733afa6331002fe26497714/69b48/sim_dia_data_generator_flow.jpg 1920w,/ml/static/7bc05ae08733afa6331002fe26497714/7a411/sim_dia_data_generator_flow.jpg 2048w&quot; sizes=&quot;(max-width: 960px) 100vw, 960px&quot; style=&quot;width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0&quot; loading=&quot;lazy&quot;/&gt;
    &lt;/span&gt;
  &lt;figcaption&gt;&lt;b class=&quot;css-0&quot;&gt;&lt;center&gt;Fig 7.: Diarization Data Simulation&lt;/center&gt;&lt;/b&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;We started with a large number of dual channel audio calls as a requirement for generating this Speaker Diarization Dataset.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;These dual channel audios were then split and saved into mono channel audio files. The key idea is that each mono channel contains one speaker and if we are able to combine these mono channeled audios compunded with known timestamps of speakers, we can then possibly recreate the audios which are potentially useful for Supervised Speaker Diarization.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Steps as shown in Fig 7:&lt;/strong&gt;&lt;/p&gt;&lt;ol class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Split dual channel audio calls&lt;/strong&gt; into mono channel audios.&lt;/p&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Running Webrtc VAD on the mono channels&lt;/strong&gt;:&lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Aggressive&lt;/strong&gt; : Speech Regions.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Mild&lt;/strong&gt; : Invert to get Gap Regions&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Compute statistics in real audios&lt;/strong&gt;: This step is required for us to understand the dynamics of overlaps and silences in a call on avergae. We compute the following ratios:&lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;$ \text{Silence Ratio} = \frac{\text{Duration of Silences}}{\text{Total Duration}} $&lt;/p&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;$ \text{Overlap Ratio} = \frac{\text{Duration of Overlapping Utterances}}{\text{Total Duration}} $&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Combination of Speech from A and B with timestamps.&lt;/strong&gt; At the same time we needed to add &lt;strong class=&quot;css-0&quot;&gt;real Gaps/Silence fills&lt;/strong&gt; and &lt;strong class=&quot;css-0&quot;&gt;Overlaps (interrupts and overtalking)&lt;/strong&gt; to mimic real world call audios which are highly interactive.
To control the amount of overlap in data-generation, we used 2 parameters mainly.&lt;/p&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;code class=&quot;css-0&quot;&gt;scale_overlap&lt;/code&gt; : This allowed us to control the maximum possible duration of overlap and was set based on the stats gathered in step 3.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;code class=&quot;css-0&quot;&gt;bias_overlap&lt;/code&gt; : This allowed us to control the percentage or probability if there is an overlapping segment. Eg: setting bias_overlap to 0.75 will give 33% chance each time to add overlap. &lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;strong class=&quot;css-0&quot;&gt;Dump tagged speaker timestamps and simulated audios.&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;That&amp;#x27;s all for now, and we&amp;#x27;ll end this blog here. Stay tuned to our &lt;a href=&quot;https://vernacular-ai.github.io/ml/rss.xml&quot; class=&quot;css-1od09yo&quot;&gt;rss feed&lt;/a&gt; for updates.&lt;/p&gt;&lt;br/&gt;&lt;hr class=&quot;css-1ldi06f&quot;/&gt;&lt;br/&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Until next time, Signing Off!&lt;/p&gt;&lt;style data-emotion-css=&quot;1bzbprl&quot;&gt;.css-1bzbprl{font-family:inherit;font-weight:700;line-height:1.25;margin:0;margin-bottom:0.25rem;font-size:1.875rem;margin-top:0.5rem;color:var(--theme-ui-colors-heading,#000);}@media screen and (min-width:640px){.css-1bzbprl{font-size:2.25rem;}}@media screen and (min-width:768px){.css-1bzbprl{font-size:3rem;}}&lt;/style&gt;&lt;h2 class=&quot;css-1bzbprl&quot;&gt;References&lt;/h2&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;http://leap.ee.iisc.ac.in/sriram/publications/papers/Deep_Self_Supervised_Hierarchical_Clustering_for_Speaker_Diarization.pdf&quot; class=&quot;css-1od09yo&quot;&gt;Deep Self-Supervised Hierarchical Clustering for Speaker Diarization&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://ai.googleblog.com/2019/08/joint-speech-recognition-and-speaker.html&quot; class=&quot;css-1od09yo&quot;&gt;Joint Speech Recognition and Speaker Diarization via Sequence Transduction&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://github.com/wiseman/py-webrtcvad&quot; class=&quot;css-1od09yo&quot;&gt;WebRTC VAD&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/2002.12761.pdf&quot; class=&quot;css-1od09yo&quot;&gt;DIHARD II is Still Hard: Experimental Results and Discussions
from the DKU-LENOVO Team&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://github.com/pyannote/pyannote-audio&quot; class=&quot;css-1od09yo&quot;&gt;PyAnnote Audio&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://github.com/resemble-ai/Resemblyzer&quot; class=&quot;css-1od09yo&quot;&gt;Resemblyzer&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://github.com/wq2012/awesome-diarization&quot; class=&quot;css-1od09yo&quot;&gt;Awesome Diarization&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=kEcUcfLmIS0&quot; class=&quot;css-1od09yo&quot;&gt;Robust Speaker Diarization for Meetings&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1710.10467.pdf&quot; class=&quot;css-1od09yo&quot;&gt;Generalized End-To-End Loss For Speaker Verification&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;&lt;a href=&quot;https://arxiv.org/abs/1810.04719&quot; class=&quot;css-1od09yo&quot;&gt;Fully Supervised Speaker Diarization&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;</content:encoded></item><item><title><![CDATA[Initiating our team blog]]></title><link>https://vernacular-ai.github.io/ml/initiating-our-team-blog</link><guid isPermaLink="false">https://vernacular-ai.github.io/ml/initiating-our-team-blog</guid><pubDate>Wed, 20 May 2020 18:30:00 GMT</pubDate><content:encoded>&lt;style data-emotion-css=&quot;1xz4htx&quot;&gt;body{--theme-ui-colors-transparent:var(--theme-ui-colors-transparent,transparent);--theme-ui-colors-black:var(--theme-ui-colors-black,#000);--theme-ui-colors-white:var(--theme-ui-colors-white,#fff);--theme-ui-colors-gray-0:var(--theme-ui-colors-gray-0,null);--theme-ui-colors-gray-1:var(--theme-ui-colors-gray-1,#f7fafc);--theme-ui-colors-gray-2:var(--theme-ui-colors-gray-2,#edf2f7);--theme-ui-colors-gray-3:var(--theme-ui-colors-gray-3,#e2e8f0);--theme-ui-colors-gray-4:var(--theme-ui-colors-gray-4,#cbd5e0);--theme-ui-colors-gray-5:var(--theme-ui-colors-gray-5,#a0aec0);--theme-ui-colors-gray-6:var(--theme-ui-colors-gray-6,#718096);--theme-ui-colors-gray-7:var(--theme-ui-colors-gray-7,#4a5568);--theme-ui-colors-gray-8:var(--theme-ui-colors-gray-8,#2d3748);--theme-ui-colors-gray-9:var(--theme-ui-colors-gray-9,#1a202c);--theme-ui-colors-red-0:var(--theme-ui-colors-red-0,null);--theme-ui-colors-red-1:var(--theme-ui-colors-red-1,#fff5f5);--theme-ui-colors-red-2:var(--theme-ui-colors-red-2,#fed7d7);--theme-ui-colors-red-3:var(--theme-ui-colors-red-3,#feb2b2);--theme-ui-colors-red-4:var(--theme-ui-colors-red-4,#fc8181);--theme-ui-colors-red-5:var(--theme-ui-colors-red-5,#f56565);--theme-ui-colors-red-6:var(--theme-ui-colors-red-6,#e53e3e);--theme-ui-colors-red-7:var(--theme-ui-colors-red-7,#c53030);--theme-ui-colors-red-8:var(--theme-ui-colors-red-8,#9b2c2c);--theme-ui-colors-red-9:var(--theme-ui-colors-red-9,#742a2a);--theme-ui-colors-orange-0:var(--theme-ui-colors-orange-0,null);--theme-ui-colors-orange-1:var(--theme-ui-colors-orange-1,#fffaf0);--theme-ui-colors-orange-2:var(--theme-ui-colors-orange-2,#feebc8);--theme-ui-colors-orange-3:var(--theme-ui-colors-orange-3,#fbd38d);--theme-ui-colors-orange-4:var(--theme-ui-colors-orange-4,#f6ad55);--theme-ui-colors-orange-5:var(--theme-ui-colors-orange-5,#ed8936);--theme-ui-colors-orange-6:var(--theme-ui-colors-orange-6,#dd6b20);--theme-ui-colors-orange-7:var(--theme-ui-colors-orange-7,#c05621);--theme-ui-colors-orange-8:var(--theme-ui-colors-orange-8,#9c4221);--theme-ui-colors-orange-9:var(--theme-ui-colors-orange-9,#7b341e);--theme-ui-colors-yellow-0:var(--theme-ui-colors-yellow-0,null);--theme-ui-colors-yellow-1:var(--theme-ui-colors-yellow-1,#fffff0);--theme-ui-colors-yellow-2:var(--theme-ui-colors-yellow-2,#fefcbf);--theme-ui-colors-yellow-3:var(--theme-ui-colors-yellow-3,#faf089);--theme-ui-colors-yellow-4:var(--theme-ui-colors-yellow-4,#f6e05e);--theme-ui-colors-yellow-5:var(--theme-ui-colors-yellow-5,#ecc94b);--theme-ui-colors-yellow-6:var(--theme-ui-colors-yellow-6,#d69e2e);--theme-ui-colors-yellow-7:var(--theme-ui-colors-yellow-7,#b7791f);--theme-ui-colors-yellow-8:var(--theme-ui-colors-yellow-8,#975a16);--theme-ui-colors-yellow-9:var(--theme-ui-colors-yellow-9,#744210);--theme-ui-colors-green-0:var(--theme-ui-colors-green-0,null);--theme-ui-colors-green-1:var(--theme-ui-colors-green-1,#f0fff4);--theme-ui-colors-green-2:var(--theme-ui-colors-green-2,#c6f6d5);--theme-ui-colors-green-3:var(--theme-ui-colors-green-3,#9ae6b4);--theme-ui-colors-green-4:var(--theme-ui-colors-green-4,#68d391);--theme-ui-colors-green-5:var(--theme-ui-colors-green-5,#48bb78);--theme-ui-colors-green-6:var(--theme-ui-colors-green-6,#38a169);--theme-ui-colors-green-7:var(--theme-ui-colors-green-7,#2f855a);--theme-ui-colors-green-8:var(--theme-ui-colors-green-8,#276749);--theme-ui-colors-green-9:var(--theme-ui-colors-green-9,#22543d);--theme-ui-colors-teal-0:var(--theme-ui-colors-teal-0,null);--theme-ui-colors-teal-1:var(--theme-ui-colors-teal-1,#e6fffa);--theme-ui-colors-teal-2:var(--theme-ui-colors-teal-2,#b2f5ea);--theme-ui-colors-teal-3:var(--theme-ui-colors-teal-3,#81e6d9);--theme-ui-colors-teal-4:var(--theme-ui-colors-teal-4,#4fd1c5);--theme-ui-colors-teal-5:var(--theme-ui-colors-teal-5,#38b2ac);--theme-ui-colors-teal-6:var(--theme-ui-colors-teal-6,#319795);--theme-ui-colors-teal-7:var(--theme-ui-colors-teal-7,#2c7a7b);--theme-ui-colors-teal-8:var(--theme-ui-colors-teal-8,#285e61);--theme-ui-colors-teal-9:var(--theme-ui-colors-teal-9,#234e52);--theme-ui-colors-blue-0:var(--theme-ui-colors-blue-0,null);--theme-ui-colors-blue-1:var(--theme-ui-colors-blue-1,#ebf8ff);--theme-ui-colors-blue-2:var(--theme-ui-colors-blue-2,#bee3f8);--theme-ui-colors-blue-3:var(--theme-ui-colors-blue-3,#90cdf4);--theme-ui-colors-blue-4:var(--theme-ui-colors-blue-4,#63b3ed);--theme-ui-colors-blue-5:var(--theme-ui-colors-blue-5,#4299e1);--theme-ui-colors-blue-6:var(--theme-ui-colors-blue-6,#3182ce);--theme-ui-colors-blue-7:var(--theme-ui-colors-blue-7,#2b6cb0);--theme-ui-colors-blue-8:var(--theme-ui-colors-blue-8,#2c5282);--theme-ui-colors-blue-9:var(--theme-ui-colors-blue-9,#2a4365);--theme-ui-colors-indigo-0:var(--theme-ui-colors-indigo-0,null);--theme-ui-colors-indigo-1:var(--theme-ui-colors-indigo-1,#ebf4ff);--theme-ui-colors-indigo-2:var(--theme-ui-colors-indigo-2,#c3dafe);--theme-ui-colors-indigo-3:var(--theme-ui-colors-indigo-3,#a3bffa);--theme-ui-colors-indigo-4:var(--theme-ui-colors-indigo-4,#7f9cf5);--theme-ui-colors-indigo-5:var(--theme-ui-colors-indigo-5,#667eea);--theme-ui-colors-indigo-6:var(--theme-ui-colors-indigo-6,#5a67d8);--theme-ui-colors-indigo-7:var(--theme-ui-colors-indigo-7,#4c51bf);--theme-ui-colors-indigo-8:var(--theme-ui-colors-indigo-8,#434190);--theme-ui-colors-indigo-9:var(--theme-ui-colors-indigo-9,#3c366b);--theme-ui-colors-purple-0:var(--theme-ui-colors-purple-0,null);--theme-ui-colors-purple-1:var(--theme-ui-colors-purple-1,#faf5ff);--theme-ui-colors-purple-2:var(--theme-ui-colors-purple-2,#e9d8fd);--theme-ui-colors-purple-3:var(--theme-ui-colors-purple-3,#d6bcfa);--theme-ui-colors-purple-4:var(--theme-ui-colors-purple-4,#b794f4);--theme-ui-colors-purple-5:var(--theme-ui-colors-purple-5,#9f7aea);--theme-ui-colors-purple-6:var(--theme-ui-colors-purple-6,#805ad5);--theme-ui-colors-purple-7:var(--theme-ui-colors-purple-7,#6b46c1);--theme-ui-colors-purple-8:var(--theme-ui-colors-purple-8,#553c9a);--theme-ui-colors-purple-9:var(--theme-ui-colors-purple-9,#44337a);--theme-ui-colors-pink-0:var(--theme-ui-colors-pink-0,null);--theme-ui-colors-pink-1:var(--theme-ui-colors-pink-1,#fff5f7);--theme-ui-colors-pink-2:var(--theme-ui-colors-pink-2,#fed7e2);--theme-ui-colors-pink-3:var(--theme-ui-colors-pink-3,#fbb6ce);--theme-ui-colors-pink-4:var(--theme-ui-colors-pink-4,#f687b3);--theme-ui-colors-pink-5:var(--theme-ui-colors-pink-5,#ed64a6);--theme-ui-colors-pink-6:var(--theme-ui-colors-pink-6,#d53f8c);--theme-ui-colors-pink-7:var(--theme-ui-colors-pink-7,#b83280);--theme-ui-colors-pink-8:var(--theme-ui-colors-pink-8,#97266d);--theme-ui-colors-pink-9:var(--theme-ui-colors-pink-9,#702459);--theme-ui-colors-grayDark:var(--theme-ui-colors-grayDark,#2d3748);--theme-ui-colors-text:var(--theme-ui-colors-text,#2d3748);--theme-ui-colors-background:var(--theme-ui-colors-background,#fff);--theme-ui-colors-primary:var(--theme-ui-colors-primary,#6b46c1);--theme-ui-colors-primaryHover:var(--theme-ui-colors-primaryHover,#2c5282);--theme-ui-colors-secondary:var(--theme-ui-colors-secondary,#5f6c80);--theme-ui-colors-muted:var(--theme-ui-colors-muted,#e2e8f0);--theme-ui-colors-success:var(--theme-ui-colors-success,#9ae6b4);--theme-ui-colors-info:var(--theme-ui-colors-info,#63b3ed);--theme-ui-colors-warning:var(--theme-ui-colors-warning,#faf089);--theme-ui-colors-danger:var(--theme-ui-colors-danger,#feb2b2);--theme-ui-colors-light:var(--theme-ui-colors-light,#f7fafc);--theme-ui-colors-dark:var(--theme-ui-colors-dark,#2d3748);--theme-ui-colors-textMuted:var(--theme-ui-colors-textMuted,#718096);--theme-ui-colors-toggleIcon:var(--theme-ui-colors-toggleIcon,#2d3748);--theme-ui-colors-heading:var(--theme-ui-colors-heading,#000);--theme-ui-colors-divide:var(--theme-ui-colors-divide,#cbd5e0);color:var(--theme-ui-colors-text,var(--theme-ui-colors-text,#2d3748));background-color:var(--theme-ui-colors-background,var(--theme-ui-colors-background,#fff));}body.theme-ui-dark{--theme-ui-colors-text:var(--theme-ui-colors-modes-dark-text,#cbd5e0);--theme-ui-colors-primary:var(--theme-ui-colors-modes-dark-primary,#9f7aea);--theme-ui-colors-secondary:var(--theme-ui-colors-modes-dark-secondary,#7f8ea3);--theme-ui-colors-toggleIcon:var(--theme-ui-colors-modes-dark-toggleIcon,#cbd5e0);--theme-ui-colors-background:var(--theme-ui-colors-modes-dark-background,#1A202C);--theme-ui-colors-heading:var(--theme-ui-colors-modes-dark-heading,#fff);--theme-ui-colors-divide:var(--theme-ui-colors-modes-dark-divide,#2d3748);--theme-ui-colors-muted:var(--theme-ui-colors-modes-dark-muted,#2d3748);}&lt;/style&gt;&lt;style data-emotion-css=&quot;1bkk5q4&quot;&gt;.css-1bkk5q4{font-size:1rem;-webkit-letter-spacing:-0.003em;-moz-letter-spacing:-0.003em;-ms-letter-spacing:-0.003em;letter-spacing:-0.003em;line-height:1.625;--baseline-multiplier:0.179;--x-height-multiplier:0.35;}@media screen and (min-width:640px){.css-1bkk5q4{font-size:1rem;}}@media screen and (min-width:768px){.css-1bkk5q4{font-size:1.25rem;}}&lt;/style&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;At Vernacular.ai we work on a lot of interesting problems in speech tech. Many
of these have potential to come out in the form of articles which might be
interesting and valuable for other people working in the field. With this blog
we are trying to experiment in that direction by committing to a more active
involvement with the community.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;A post here will mostly be of one of the following, non-exhaustive, kinds:&lt;/p&gt;&lt;style data-emotion-css=&quot;15rlv7r&quot;&gt;.css-15rlv7r li{font-size:1rem;-webkit-letter-spacing:-0.003em;-moz-letter-spacing:-0.003em;-ms-letter-spacing:-0.003em;letter-spacing:-0.003em;line-height:1.625;--baseline-multiplier:0.179;--x-height-multiplier:0.35;}@media screen and (min-width:640px){.css-15rlv7r li{font-size:1rem;}}@media screen and (min-width:768px){.css-15rlv7r li{font-size:1.25rem;}}&lt;/style&gt;&lt;ul class=&quot;css-15rlv7r&quot;&gt;&lt;li class=&quot;css-0&quot;&gt;Journeys of systems, processes and people in the team.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Introductions to a new/old problem, tutorials etc.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Deeper posts, insightful explanations, research findings etc.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Opinion pieces on the technologies we work with.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;Notes on processes that we follow internally.&lt;/li&gt;&lt;li class=&quot;css-0&quot;&gt;News, releases etc.&lt;/li&gt;&lt;/ul&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Many of these might be syndicated, with original posts on authors&amp;#x27; personal
pages. We are also trying to set up a peer review protocol to help us decide
what qualifies to be published here along with a rough minimum frequency of
posts.&lt;/p&gt;&lt;p class=&quot;css-1bkk5q4&quot;&gt;Stay tuned to our &lt;style data-emotion-css=&quot;1od09yo&quot;&gt;.css-1od09yo{color:var(--theme-ui-colors-primary,#6b46c1);-webkit-text-decoration:none;text-decoration:none;}.css-1od09yo:hover{-webkit-text-decoration:underline;text-decoration:underline;}&lt;/style&gt;&lt;a href=&quot;https://vernacular-ai.github.io/ml/rss.xml&quot; class=&quot;css-1od09yo&quot;&gt;rss feed&lt;/a&gt; for
updates.&lt;/p&gt;</content:encoded></item></channel></rss>